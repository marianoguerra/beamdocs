<!doctype html>
<html><head><meta charset="utf-8"><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.0/css/bootstrap.min.css"></head><body style="margin: 4em 10%"><h1>Mnesia User's Guide</h1><p>The Mnesia application is a distributed Database Management
System (DBMS), appropriate for telecommunications applications and other
Erlang applications, which require continuous operation and exhibit soft
real-time properties.</p><p>The Mnesia application provides a heavy duty real-time
distributed database.</p><h3>Scope</h3><p>This User's Guide describes how to
build Mnesia database applications, and how to integrate
and use the Mnesia database management system with
OTP. Programming constructs are described, and numerous
programming examples are included to illustrate the use of
Mnesia.</p><p>This User's Guide is organized as follows:</p><ul><li><a href="Mnesia_overview">Mnesia</a> provides an introduction to Mnesia. </li><li><a href="Mnesia_chap2">Getting Started</a> introduces Mnesia with an example database. Examples are included how to start an Erlang session, specify a Mnesia database directory, initialize a database schema, start Mnesia, and create tables. Initial prototyping of record definitions is also discussed. </li><li><a href="Mnesia_chap3">Build a Mnesia Database</a> more formally describes the steps introduced in the previous section, namely the Mnesia functions that define a database schema, start Mnesia, and create the required tables. </li><li><a href="Mnesia_chap4">Transactions and Other Access Contexts</a> describes the transactions properties that make Mnesia into a fault tolerant, real-time distributed database management system. This section also describes the concept of locking to ensure consistency in tables, and "dirty operations", or short cuts, which bypass the transaction system to improve speed and reduce overheads. </li><li><a href="Mnesia_chap5">Miscellaneous Mnesia Features</a> describes features that enable the construction of more complex database applications. These features include indexing, checkpoints, distribution and fault tolerance, disc-less nodes, replication manipulation, local content tables, concurrency, and object-based programming in Mnesia. </li><li><a href="Mnesia_chap7">Mnesia System Information</a> describes the files contained in the Mnesia database directory, database configuration data, core and table dumps, as well as the important subject of backup, fall-back, and disaster recovery principles. </li><li><a href="Mnesia_chap8">Combine Mnesia with SNMP</a> is a short section that outlines Mnesia integrated with SNMP. </li><li><a href="Mnesia_App_A">Appendix A: Backup Callback Interface</a> is a program listing of the default implementation of this facility. </li><li><a href="Mnesia_App_B">Appendix B: Activity Access Callback Interface</a> is a program outlining one possible implementation of this facility. </li><li><a href="Mnesia_App_C">Appendix C: Fragmented Table Hashing Callback Interface</a> is a program outlining one possible implementation of this facility. </li></ul><h3>Prerequisites</h3><p>It is assumed that the reader is familiar with the Erlang
programming language, system development principles, and
database management systems.</p><p>The management of data in telecommunications system has many
aspects, thereof some, but not all, are addressed by traditional
commercial Database Management Systems (DBMSs). In particular the
high level of fault tolerance that is required in many nonstop
systems, combined with requirements on the DBMS to run in the same
address space as the application, have led us to implement a new
DBMS, called Mnesia.</p><p>Mnesia is implemented in, and tightly connected to Erlang.
It provides the functionality that is necessary for the
implementation of fault tolerant telecommunications systems.</p><p>Mnesia is a multiuser distributed DBMS specially made for
industrial telecommunications applications written in Erlang,
which is also the intended target language.
Mnesia tries to address all the data
management issues required for typical telecommunications systems.
It has a number of features that are not normally found in traditional
databases.</p><p>In telecommunications applications, there are different needs
from the features provided by traditional DBMSs. The applications now
implemented in Erlang need a mixture of a broad range
of features, which generally are not satisfied by traditional DBMSs.
Mnesia is designed with requirements like the following in
mind:</p><ul><li>Fast real-time key/value lookup </li><li>Complicated non-real-time queries mainly for operation and maintenance </li><li>Distributed data because of distributed applications </li><li>High fault tolerance </li><li>Dynamic reconfiguration </li><li>Complex objects </li></ul><p>Mnesia is designed with the typical data management problems
of telecommunications applications in mind. This sets Mnesia
apart from most other DBMS. Hence Mnesia
combines many concepts found in traditional databases such as
transactions and queries with concepts found in data management
systems for telecommunications applications, for example:</p><ul><li>Fast real-time operations </li><li>Configurable degree of fault tolerance (by replication) </li><li>The ability to reconfigure the system without stopping or suspending it. </li></ul><p>Mnesia is also interesting because of its tight coupling to
Erlang, thus almost turning Erlang into a database programming
language. This has many benefits, the foremost is that
the impedance mismatch between the data format used by the DBMS
and the data format used by the programming language, which is used
to manipulate the data, completely disappears.</p><h3>Mnesia Database Management System (DBMS)</h3><h3>Features</h3><p>Mnesia contains the following features that combine to
produce a fault-tolerant, distributed DBMS written in Erlang:
</p><ul><li>Database schema can be dynamically reconfigured at runtime. </li><li>Tables can be declared to have properties such as location, replication, and persistence. </li><li>Tables can be moved or replicated to several nodes to improve fault tolerance. The rest of the system can still access the tables to read, write, and delete records. </li><li>Table locations are transparent to the programmer. Programs address table names and the system itself keeps track of table locations. </li><li>Database transactions can be distributed, and many functions can be called within one transaction. </li><li>Several transactions can run concurrently, and their execution is fully synchronized by the DBMS. Mnesia ensures that no two processes manipulate data simultaneously. </li><li>Transactions can be assigned the property of being executed on all nodes in the system, or on none. Transactions can also be bypassed in favor of running "dirty operations", which reduce overheads and run fast. </li></ul><p>Details of these features are described in the following sections.</p><h3>Add-On Application</h3><p>Query List Comprehension (QLC) can be used with Mnesia
to produce specialized functions that enhance the operational
ability of Mnesia. QLC has its own documentation as part
of the OTP documentation set. The main features of QLC
when used with Mnesia are as follows:</p><ul><li>QLC can optimize the query compiler for the Mnesia DBMS, essentially making the DBMS more efficient. </li><li>QLC can be used as a database programming language for Mnesia. It includes a notation called "list comprehensions" and can be used to make complex database queries over a set of tables. </li></ul><p>For information about QLC, see the
<a href="./qlc">qlc</a> manual page
in STDLIB.</p><h3>When to Use Mnesia</h3><p>Use Mnesia with the following types of applications:</p><ul><li>Applications that need to replicate data. </li><li>Applications that perform complicated searches on data. </li><li>Applications that need to use atomic transactions to update several records simultaneously. </li><li>Applications that use soft real-time characteristics. </li></ul><p>Mnesia is not as appropriate with the
following types of applications:</p><ul><li>Programs that process plain text or binary data files. </li><li>Applications that merely need a look-up dictionary that can be stored to disc. Those applications  use the standard library module <strong>dets</strong>, which is a disc-based version of the module <strong>ets</strong>. For information about <strong>dets</strong>, see the <a href="./dets">dets</a> manual page in STDLIB. </li><li>Applications that need disc logging facilities. Those applications can use the module <strong>disk_log</strong> by preference. For information about <strong>disk_log</strong>, see the <a href="./disk_log">disk_log</a> manual page in Kernel. </li><li>Hard real-time systems. </li></ul><a name="getting_started"></a><p>This section introduces <strong>Mnesia</strong> with an example database.
This example is referenced in the
following sections, where the example is modified to
illustrate various program constructs. This section illustrates
the following mandatory procedures through examples:</p><ul><li>Starting the Erlang session. </li><li>Specifying the <strong>Mnesia</strong> directory where the database is to be stored. </li><li>Initializing a new database schema with an attribute that specifies on which node, or nodes, that database is to operate. </li><li>Starting <strong>Mnesia</strong>. </li><li>Creating and populating the database tables. </li></ul><h3>Starting Mnesia for the First Time</h3><p>This section provides a simplified demonstration of a <strong>Mnesia</strong>
system startup. The dialogue from the Erlang shell is as follows:</p><pre>
        unix&gt;  erl -mnesia dir '"/tmp/funky"'
        Erlang (BEAM) emulator version 4.9
        
        Eshell V4.9  (abort with ^G)
        1&gt; 
        1&gt; mnesia:create_schema([node()]).
        ok
        2&gt; mnesia:start().
        ok
        3&gt; mnesia:create_table(funky, []).
        {atomic,ok}
        4&gt; mnesia:info().
        ---&gt; Processes holding locks &lt;--- 
        ---&gt; Processes waiting for locks &lt;--- 
        ---&gt; Pending (remote) transactions &lt;--- 
        ---&gt; Active (local) transactions &lt;---
        ---&gt; Uncertain transactions &lt;--- 
        ---&gt; Active tables &lt;--- 
        funky          : with 0 records occupying 269 words of mem 
        schema         : with 2 records occupying 353 words of mem 
        ===&gt; System info in version "1.0", debug level = none &lt;===
        opt_disc. Directory "/tmp/funky" is used.
        use fall-back at restart = false
        running db nodes = [nonode@nohost]
        stopped db nodes = [] 
        remote           = []
        ram_copies       = [funky]
        disc_copies      = [schema]
        disc_only_copies = []
        [{nonode@nohost,disc_copies}] = [schema]
        [{nonode@nohost,ram_copies}] = [funky]
        1 transactions committed, 0 aborted, 0 restarted, 1 logged to disc
        0 held locks, 0 in queue; 0 local transactions, 0 remote
        0 transactions waits for other nodes: []
        ok      
    </pre><p>In this example, the following actions are performed:</p><ul><li><em>Step 1:</em> The Erlang system is started from the UNIX prompt with a flag <strong>-mnesia dir '"/tmp/funky"'</strong>, which indicates in which directory to store the data. </li><li><em>Step 2:</em> A new empty schema is initialized on the local node by evaluating <a href="./mnesia#create_schema/1">mnesia:create_schema([node()])</a>. The schema contains information about the database in general. This is explained in detail later. </li><li><em>Step 3:</em> The DBMS is started by evaluating <a href="./mnesia#start/0">mnesia:start()</a>. </li><li><em>Step 4:</em> A first table is created, called <strong>funky</strong>, by evaluating the expression <strong>mnesia:create_table(funky, [])</strong>. The table is given default properties. </li><li><em>Step 5:</em> <a href="./mnesia#info/0">mnesia:info()</a> is evaluated to display information on the terminal about the status of the database. </li></ul><h3>Example</h3><p>A <strong>Mnesia</strong> database is organized as a set of tables.
Each table is populated with instances (Erlang records).
A table has also a number of properties, such as location and
persistence.</p><h3>Database</h3><p>This example shows how to create a database called <strong>Company</strong>
and the relationships shown in the following diagram:</p><img src="company.gif" title="Company Entity-Relation Diagram"></img><p>The database model is as follows:</p><ul><li>There are three entities: department, employee, and project. </li><li> <p>There are three relationships between these entities:</p> <ul><li>A department is managed by an employee, hence the <strong>manager</strong> relationship. </li><li>An employee works at a department, hence the <strong>at_dep</strong> relationship. </li><li>Each employee works on a number of projects, hence the <strong>in_proj</strong> relationship. </li></ul> </li></ul><h3>Defining Structure and Content</h3><p>First the record definitions are entered into a text file
named <strong>company.hrl</strong>. This file defines the following
structure for the example database: </p><pre><code class="">

-record(employee, {emp_no,
                   name,
                   salary,
                   sex,
                   phone,
                   room_no}).

-record(dept, {id, 
               name}).

-record(project, {name,
                  number}).


-record(manager, {emp,
                  dept}).

-record(at_dep, {emp,
                 dept_id}).

-record(in_proj, {emp,
                  proj_name}).
</code></pre><p>The structure defines six tables in the database. In <strong>Mnesia</strong>,
the function
<a href="./mnesia#create_table/2">mnesia:create_table(Name, ArgList)</a>
creates tables. <strong>Name</strong> is the table name.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>The current version of <strong>Mnesia</strong> does not require that
the name of the table is the same as the record name, see
<a href="./Mnesia_chap4#recordnames_tablenames">Record Names versus Table Names.</a>.</p></div><p>For example, the table for employees is created with the
function <strong>mnesia:create_table(employee, [{attributes, record_info(fields, employee)}])</strong>. The table
name <strong>employee</strong> matches the name for records specified
in <strong>ArgList</strong>. The expression
<strong>record_info(fields, RecordName)</strong> is processed by the Erlang
preprocessor and evaluates to a list containing the names of the
different fields for a record.</p><h3>Program</h3><p>The following shell interaction starts <strong>Mnesia</strong> and
initializes the schema for the <strong>Company</strong> database:</p><pre>
        % <span class="input">erl -mnesia dir '"/ldisc/scratch/Mnesia.Company"'</span>
         Erlang (BEAM) emulator version 4.9
          
          Eshell V4.9  (abort with ^G)
          1&gt; mnesia:create_schema([node()]).
          ok
          2&gt; mnesia:start().
          ok</pre><p>The following program module creates and populates previously
defined tables:</p><pre><code class="">


-include_lib("stdlib/include/qlc.hrl").
-include("company.hrl").

init() -&gt;
    mnesia:create_table(employee,
                        [{attributes, record_info(fields, employee)}]),
    mnesia:create_table(dept,
                        [{attributes, record_info(fields, dept)}]),
    mnesia:create_table(project,
                        [{attributes, record_info(fields, project)}]),
    mnesia:create_table(manager, [{type, bag}, 
                                  {attributes, record_info(fields, manager)}]),
    mnesia:create_table(at_dep,
                         [{attributes, record_info(fields, at_dep)}]),
    mnesia:create_table(in_proj, [{type, bag}, 
                                  {attributes, record_info(fields, in_proj)}]).
</code></pre><h3>Program Explained</h3><p>The following commands and functions are used to initiate the
<strong>Company</strong> database:</p><ul><li><strong>% erl -mnesia dir '"/ldisc/scratch/Mnesia.Company"'</strong>. This is a UNIX command-line entry that starts the Erlang system. The flag <strong>-mnesia dir Dir</strong> specifies the location of the database directory. The system responds and waits for further input with the prompt <strong>1&gt;</strong>. </li><li> <a href="./mnesia#create_schema/1">mnesia:create_schema([node()])</a>. This function has the format <strong>mnesia:create_schema(DiscNodeList)</strong> and initiates a new schema. In this example, a non-distributed system using only one node is created. Schemas are fully explained in <a href="./Mnesia_chap3#def_schema">Define a Schema</a>. </li><li><a href="./mnesia#start/0">mnesia:start()</a>. This function starts <strong>Mnesia</strong> and is fully explained in <a href="./Mnesia_chap3#start_mnesia">Start Mnesia</a>. </li></ul><p>Continuing the dialogue with the Erlang shell produces the
following:</p><pre>
        3&gt; company:init().
        {atomic,ok}
        4&gt; mnesia:info().
        ---&gt; Processes holding locks &lt;--- 
        ---&gt; Processes waiting for locks &lt;--- 
        ---&gt; Pending (remote) transactions &lt;--- 
        ---&gt; Active (local) transactions &lt;---
        ---&gt; Uncertain transactions &lt;--- 
        ---&gt; Active tables &lt;--- 
        in_proj        : with 0 records occuping 269 words of mem 
        at_dep         : with 0 records occuping 269 words of mem 
        manager        : with 0 records occuping 269 words of mem 
        project        : with 0 records occuping 269 words of mem 
        dept           : with 0 records occuping 269 words of mem 
        employee       : with 0 records occuping 269 words of mem 
        schema         : with 7 records occuping 571 words of mem 
        ===&gt; System info in version "1.0", debug level = none &lt;===
        opt_disc. Directory "/ldisc/scratch/Mnesia.Company" is used.
        use fall-back at restart = false
        running db nodes = [nonode@nohost]
        stopped db nodes = [] 
        remote           = []
        ram_copies       =
            [at_dep,dept,employee,in_proj,manager,project]
        disc_copies      = [schema]
        disc_only_copies = []
        [{nonode@nohost,disc_copies}] = [schema]
        [{nonode@nohost,ram_copies}] =
            [employee,dept,project,manager,at_dep,in_proj]
        6 transactions committed, 0 aborted, 0 restarted, 6 logged to disc
        0 held locks, 0 in queue; 0 local transactions, 0 remote
        0 transactions waits for other nodes: []
        ok
      </pre><p>A set of tables is created. The function
<a href="./mnesia#create_table/2">mnesia:create_table(Name, ArgList)</a>
creates the required database tables. The
options available with <strong>ArgList</strong> are explained in
<a href="./Mnesia_chap3#create_tables">Create New Tables</a>.</p><p>The function <strong>company:init/0</strong> creates the tables. Two tables
are of type <strong>bag</strong>. This is the <strong>manager</strong> relation as well
the <strong>in_proj</strong> relation. This is interpreted as: an
employee can be manager over several departments, and an employee
can participate in several projects. However, the <strong>at_dep</strong>
relation is <strong>set</strong>, as an employee can only work in one department.
In this data model, there are examples of relations that are 1-to-1
(<strong>set</strong>) and  1-to-many (<strong>bag</strong>).</p><p><a href="./mnesia#info/0">mnesia:info()</a>
now indicates that a database has seven
local tables, where six are the user-defined tables and one is
the schema. Six transactions have been committed, as six successful
transactions were run when creating the tables.</p><p>To write a function that inserts an employee record into the
database, there must be an <strong>at_dep</strong> record and a set of
<strong>in_proj</strong> records inserted. Examine the following
code used to complete this action:</p><pre><code class="">


insert_emp(Emp, DeptId, ProjNames) -&gt;
    Ename = Emp#employee.name,
    Fun = fun() -&gt;
                  mnesia:write(Emp),
                  AtDep = #at_dep{emp = Ename, dept_id = DeptId},
                  mnesia:write(AtDep),
                  mk_projs(Ename, ProjNames)
          end,
    mnesia:transaction(Fun).


mk_projs(Ename, [ProjName|Tail]) -&gt;
    mnesia:write(#in_proj{emp = Ename, proj_name = ProjName}),
    mk_projs(Ename, Tail);
mk_projs(_, []) -&gt; ok.
    
</code></pre><ul><li> <p>The <strong>insert_emp/3</strong> arguments are as follows:</p> <ul><li><strong>Emp</strong> is an employee record. </li><li><strong>DeptId</strong> is the identity of the department where the employee works. </li><li><strong>ProjNames</strong> is a list of the names of the projects where the employee works.</li></ul> </li></ul><p>The function <strong>insert_emp/3</strong> creates a Functional Object (Fun).
<strong>Fun</strong> is passed
as a single argument to the function
<a href="./mnesia#transaction/2">mnesia:transaction(Fun)</a>.
This means that <strong>Fun</strong> is
run as a transaction with the following properties:</p><ul><li>A <strong>Fun</strong> either succeeds or fails. </li><li>Code that manipulates the same data records can be run concurrently without the different processes interfering with each other.  </li></ul><p>The function can be used as follows:</p><pre><code class="">
          Emp  = #employee{emp_no= 104732,
                           name = klacke,
                           salary = 7,
                           sex = male,
                           phone = 98108,
                           room_no = {221, 015}},
        insert_emp(Emp, 'B/SFR', [Erlang, mnesia, otp]).</code></pre><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>For information about Funs, see "Fun Expressions" in
section <strong>Erlang Reference Manual</strong> in System
Documentation..</p></div><h3>Initial Database Content</h3><p>After the insertion of the  employee named <strong>klacke</strong>,
the database has the following records:</p><a name="table2_1"></a><table class="table table-bordered table-hover table-striped"><caption>employee Database Record</caption><tbody><tr><td>emp_no</td><td>name</td><td>salary</td><td>sex</td><td>phone</td><td>room_no</td></tr><tr><td>104732</td><td>klacke</td><td>7</td><td>male</td><td>98108</td><td>{221, 015}</td></tr></tbody></table><p>This <strong>employee</strong> record has the Erlang record/tuple
representation
<strong>{employee, 104732, klacke, 7, male, 98108, {221, 015}}</strong>.</p><a name="table2_2"></a><table class="table table-bordered table-hover table-striped"><caption>at_dep Database Record</caption><tbody><tr><td>emp</td><td>dept_name</td></tr><tr><td>klacke</td><td>B/SFR</td></tr></tbody></table><p>This <strong>at_dep</strong> record has the Erlang tuple representation
<strong>{at_dep, klacke, 'B/SFR'}</strong>.</p><a name="table3_3"></a><table class="table table-bordered table-hover table-striped"><caption>in_proj Database Record</caption><tbody><tr><td>emp</td><td>proj_name</td></tr><tr><td>klacke</td><td>Erlang</td></tr><tr><td>klacke</td><td>otp</td></tr><tr><td>klacke</td><td>mnesia</td></tr></tbody></table><p>This <strong>in_proj</strong> record has the Erlang tuple representation
<strong>{in_proj, klacke, 'Erlang', klacke, 'otp', klacke, 'mnesia'}</strong>.</p><p>There is no difference between rows in a table and <strong>Mnesia</strong>
records. Both concepts are the same and are used
interchangeably throughout this User's Guide.</p><p>A <strong>Mnesia</strong> table is populated by <strong>Mnesia</strong> records. For
example, the tuple <strong>{boss, klacke, bjarne}</strong> is a record. The
second element in this tuple is the key. To identify a table
uniquely, both the key and the table name is needed.
The term Object Identifier (OID) is
sometimes used for the arity two tuple {Tab, Key}. The OID for
the record <strong>{boss, klacke, bjarne}</strong> is the arity two
tuple <strong>{boss, klacke}</strong>. The first element of the tuple is
the type of the record and the second element is the key. An
OID can lead to zero, one, or more records depending on
whether the table type is <strong>set</strong> or <strong>bag</strong>.</p><p>The record <strong>{boss, klacke, bjarne}</strong> can also be inserted.
This record contains an implicit reference to
another employee that does not yet exist in the
database. <strong>Mnesia</strong> does not enforce this.</p><h3>Adding Records and Relationships to Database</h3><p>After adding more records to the <strong>Company</strong> database, the
result can be the following records:</p><p><strong>employees</strong>:</p><pre><code class="">
        {employee, 104465, "Johnson Torbjorn",   1, male,  99184, {242,038}}.
        {employee, 107912, "Carlsson Tuula",     2, female,94556, {242,056}}.
        {employee, 114872, "Dacker Bjarne",      3, male,  99415, {221,035}}.
        {employee, 104531, "Nilsson Hans",       3, male,  99495, {222,026}}.
        {employee, 104659, "Tornkvist Torbjorn", 2, male,  99514, {222,022}}.
        {employee, 104732, "Wikstrom Claes",     2, male,  99586, {221,015}}.
        {employee, 117716, "Fedoriw Anna",       1, female,99143, {221,031}}.
        {employee, 115018, "Mattsson Hakan",     3, male,  99251, {203,348}}.</code></pre><p><strong>dept</strong>:</p><pre><code class="">
        {dept, 'B/SF',  "Open Telecom Platform"}.
        {dept, 'B/SFP', "OTP - Product Development"}.
        {dept, 'B/SFR', "Computer Science Laboratory"}.</code></pre><p><strong>projects</strong>:</p><pre><code class="">
        %% projects
        {project, erlang, 1}.
        {project, otp, 2}.
        {project, beam, 3}.
        {project, mnesia, 5}.
        {project, wolf, 6}.
        {project, documentation, 7}.
        {project, www, 8}.</code></pre><p>These three tables, <strong>employees</strong>, <strong>dept</strong>, and
<strong>projects</strong>, are
made up of real records. The following database content is
stored in the tables and is built on
relationships. These tables are <strong>manager</strong>,
<strong>at_dep</strong>, and <strong>in_proj</strong>.</p><p><strong>manager</strong>:</p><pre><code class="">
        {manager, 104465, 'B/SF'}.
        {manager, 104465, 'B/SFP'}.
        {manager, 114872, 'B/SFR'}.</code></pre><p><strong>at_dep</strong>:</p><pre><code class="">
        {at_dep, 104465, 'B/SF'}.
        {at_dep, 107912, 'B/SF'}.
        {at_dep, 114872, 'B/SFR'}.
        {at_dep, 104531, 'B/SFR'}.
        {at_dep, 104659, 'B/SFR'}.
        {at_dep, 104732, 'B/SFR'}.
        {at_dep, 117716, 'B/SFP'}.
        {at_dep, 115018, 'B/SFP'}.</code></pre><p><strong>in_proj</strong>:</p><pre><code class="">
        {in_proj, 104465, otp}.
        {in_proj, 107912, otp}.
        {in_proj, 114872, otp}.
        {in_proj, 104531, otp}.
        {in_proj, 104531, mnesia}.
        {in_proj, 104545, wolf}.
        {in_proj, 104659, otp}.
        {in_proj, 104659, wolf}.
        {in_proj, 104732, otp}.
        {in_proj, 104732, mnesia}.
        {in_proj, 104732, erlang}.
        {in_proj, 117716, otp}.
        {in_proj, 117716, documentation}.
        {in_proj, 115018, otp}.
        {in_proj, 115018, mnesia}.</code></pre><p>The room number is an attribute of the employee
record. This is a structured attribute that consists of a
tuple. The first element of the tuple identifies a corridor,
and the second element identifies the room in that
corridor. An alternative is to represent this as a record
<strong>-record(room, {corr, no}).</strong> instead of an anonymous
tuple representation.</p><p>The <strong>Company</strong> database is now initialized and contains
data.</p><h3>Writing Queries</h3><p>Retrieving data from DBMS is usually to be done with the
functions
<a href="./mnesia#read/3">mnesia:read/3</a> or
<a href="./mnesia#read/2">mnesia:read/1</a>.
The following function raises the salary:</p><pre><code class="">

raise(Eno, Raise) -&gt;
    F = fun() -&gt;
                [E] = mnesia:read(employee, Eno, write),
                Salary = E#employee.salary + Raise,
                New = E#employee{salary = Salary},
                mnesia:write(New)
        end,
    mnesia:transaction(F).</code></pre><p>Since it is desired to update the record using the function
<a href="./mnesia#write/1">mnesia:write/1</a>
after the salary has been increased, a write
lock (third argument to <strong>read</strong>) is acquired when the record from
the table is read.</p><p>To read the values from the table directly is not always possible.
It can be needed to search one or more tables to get the
wanted data, and this is done by writing database queries. Queries
are always more expensive operations than direct lookups done with
<strong>mnesia:read</strong>. Therefore, avoid queries in
performance-critical code.</p><p>Two methods are available for writing database queries:</p><ul><li><strong>Mnesia</strong> functions</li><li>QLC</li></ul><h3>Using Mnesia Functions</h3><p>The following function extracts the names of the female employees
stored in the database:</p><pre>
mnesia:select(employee, [{#employee{sex = female, name = '$1', _ = '_'},[], ['$1']}]).</pre><p><strong>select</strong> must always run within an activity, such as a
transaction. The following function can be constructed to call
from the shell:</p><pre><code class="">

all_females() -&gt;
    F = fun() -&gt;
		Female = #employee{sex = female, name = '$1', _ = '_'},
		mnesia:select(employee, [{Female, [], ['$1']}])
        end,
    mnesia:transaction(F).</code></pre><p>The <strong>select</strong> expression matches all entries in table
employee with the field <strong>sex</strong> set to <strong>female</strong>.</p><p>This function can be called from the shell as follows:</p><pre>
          (klacke@gin)1&gt; <span class="input">company:all_females().</span>
          {atomic,  ["Carlsson Tuula", "Fedoriw Anna"]}</pre><p>For a description of <strong>select</strong> and its syntax, see
<a href="./Mnesia_chap4#matching">Pattern Matching</a>.
</p><h3>Using QLC</h3><p>This section contains simple introductory examples only. For
a full description of the QLC query language, see the
<a href="./qlc">qlc</a> manual page in
<strong>STDLIB</strong>.</p><p>Using QLC can be more expensive than using <strong>Mnesia</strong>
functions directly but offers a nice syntax.</p><p>The following function extracts a list of female employees
from the database:</p><pre>
          Q = qlc:q([E#employee.name || E &lt;- mnesia:table(employee),
                                E#employee.sex == female]),
          qlc:e(Q),</pre><p>Accessing <strong>Mnesia</strong> tables from a QLC list comprehension must
always be done within a transaction. Consider the following
function:</p><pre><code class="">

females() -&gt;
    F = fun() -&gt;
		Q = qlc:q([E#employee.name || E &lt;- mnesia:table(employee),
					      E#employee.sex == female]),
		qlc:e(Q)
	end,
    mnesia:transaction(F).</code></pre><p>This function can be called from the shell as follows:</p><pre>
          (klacke@gin)1&gt; <span class="input">company:females().</span>
          {atomic, ["Carlsson Tuula", "Fedoriw Anna"]}</pre><p>In traditional relational database terminology, this
operation is called a selection, followed by a projection.</p><p>The previous list comprehension expression contains a
number of syntactical elements:</p><ul><li>The first <strong>[</strong> bracket is read as "build the list". </li><li>The <strong>||</strong> "such that" and the arrow <strong>&lt;-</strong> is read as "taken from". </li></ul><p>Hence, the previous list comprehension demonstrates the
formation of the list <strong>E#employee.name</strong> such that <strong>E</strong> is
taken from the table of employees, and attribute <strong>sex</strong>
of each record is equal to the atom <strong>female</strong>.</p><p>The whole list comprehension must be given to the function
<strong>qlc:q/1</strong>.</p><p>List comprehensions with low-level <strong>Mnesia</strong> functions
can be combined in the same transaction. To raise the
salary of all female employees, execute the following:</p><pre><code class="">

raise_females(Amount) -&gt;
    F = fun() -&gt;
                Q = qlc:q([E || E &lt;- mnesia:table(employee),
                                E#employee.sex == female]),
		Fs = qlc:e(Q),
                over_write(Fs, Amount)
        end,
    mnesia:transaction(F).

over_write([E|Tail], Amount) -&gt;
    Salary = E#employee.salary + Amount,
    New = E#employee{salary = Salary},
    mnesia:write(New),
    1 + over_write(Tail, Amount);
over_write([], _) -&gt;
    0.</code></pre><p>The function <strong>raise_females/1</strong> returns the tuple
<strong>{atomic, Number}</strong>, where <strong>Number</strong> is the number of
female employees who received a salary increase. If an error
occurs, the value <strong>{aborted, Reason}</strong> is returned, and
<strong>Mnesia</strong> guarantees that the salary is not
raised for any employee.</p><p><em>Example:</em></p><pre>
          33&gt;<span class="input">company:raise_females(33).</span>
          {atomic,2}</pre><p>This section describes the basic steps when designing a
<strong>Mnesia</strong> database and the programming constructs that make different
solutions available to the programmer. The following topics are
included:</p><ul><li>Define a schema</li><li>Data model</li><li>Start <strong>Mnesia</strong></li><li>Create tables</li></ul><a name="def_schema"></a><h3>Define a Schema</h3><p>The configuration of a <strong>Mnesia</strong> system is described in a
schema. The schema is a special table that includes information
such as the table names and the storage type of each table
(that is, whether a table is to be stored in RAM,
on disc, or on both, as well as its location).</p><p>Unlike data tables, information in schema tables can only be
accessed and modified by using the schema-related functions
described in this section.</p><p><strong>Mnesia</strong> has various functions for defining the
database schema. Tables can be moved or deleted, and the
table layout can be reconfigured.</p><p>An important aspect of these functions is that the system can access
a table while it is being reconfigured. For example, it is possible
to move a
table and simultaneously perform write operations to the same
table. This feature is essential for applications that require
continuous service.</p><p>This section describes the functions available for schema management,
all which return either of the following tuples:</p><ul><li><strong>{atomic, ok}</strong> if successful</li><li><strong>{aborted, Reason}</strong> if unsuccessful</li></ul><h3>Schema Functions</h3><p>The schema functions are as follows:</p><ul><li><a href="./mnesia#create_schema/1">mnesia:create_schema(NodeList)</a> initializes a new, empty schema. This is a mandatory requirement before <strong>Mnesia</strong> can be started. <strong>Mnesia</strong> is a truly distributed DBMS and the schema is a system table that is replicated on all nodes in a <strong>Mnesia</strong> system. This function fails if a schema is already present on any of the nodes in <strong>NodeList</strong>. The function requires <strong>Mnesia</strong> to be stopped on the all <strong>db_nodes</strong> contained in parameter <strong>NodeList</strong>. Applications call this function only once, as it is usually a one-time activity to initialize a new database. </li><li><a href="./mnesia#delete_schema/1">mnesia:delete_schema(DiscNodeList)</a> erases any old schemas on the nodes in <strong>DiscNodeList</strong>. It also removes all old tables together with all data. This function requires <strong>Mnesia</strong> to be stopped on all <strong>db_nodes</strong>. </li><li><a href="./mnesia#delete_table/1">mnesia:delete_table(Tab)</a> permanently deletes all replicas of table <strong>Tab</strong>. </li><li><a href="./mnesia#clear_table/1">mnesia:clear_table(Tab)</a> permanently deletes all entries in table <strong>Tab</strong>. </li><li><a href="./mnesia#move_table_copy/3">mnesia:move_table_copy(Tab, From, To)</a> moves the copy of table <strong>Tab</strong> from node <strong>From</strong> to node <strong>To</strong>. The table storage type <strong>{type}</strong> is preserved, so if a RAM table is moved from one node to another, it remains a RAM table on the new node. Other transactions can still perform read and write operation to the table while it is being moved. </li><li><a href="./mnesia#add_table_copy/3">mnesia:add_table_copy(Tab, Node, Type)</a> creates a replica of table <strong>Tab</strong> at node <strong>Node</strong>. Argument <strong>Type</strong> must be either of the atoms <strong>ram_copies</strong>, <strong>disc_copies</strong>, or <strong>disc_only_copies</strong>. If you add a copy of the system table <strong>schema</strong> to a node, you want the <strong>Mnesia</strong> schema to reside there as well. This action extends the set of nodes that comprise this particular <strong>Mnesia</strong> system. </li><li><a href="./mnesia#del_table_copy/2">mnesia:del_table_copy(Tab, Node)</a> deletes the replica of table <strong>Tab</strong> at node <strong>Node</strong>. When the last replica of a table is removed, the table is deleted. </li><li> <p><a href="./mnesia#transform_table/4">mnesia:transform_table(Tab, Fun, NewAttributeList, NewRecordName)</a>
changes the format on all records in table
<strong>Tab</strong>. It applies argument <strong>Fun</strong> to all
records in the table. <strong>Fun</strong> must be a function that
takes a record of the old type, and returns the record of the
new type. The table key must not be changed.</p> <p><em>Example:</em></p> <pre><code class="">
-record(old, {key, val}).
-record(new, {key, val, extra}).

Transformer =
   fun(X) when record(X, old) -&gt;
      #new{key = X#old.key,
           val = X#old.val,
           extra = 42}
   end,
{atomic, ok} = mnesia:transform_table(foo, Transformer,
                                      record_info(fields, new),
                                      new),
</code></pre> <p>Argument <strong>Fun</strong> can also be the atom
<strong>ignore</strong>, which indicates that only the metadata about
the table is updated. Use of <strong>ignore</strong> is not recommended
(as it creates inconsistencies between the metadata and the
actual data) but it is included as a possibility for the user
do to an own (offline) transform.</p> </li><li><strong>change_table_copy_type(Tab, Node, ToType)</strong> changes the storage type of a table. For example, a RAM table is changed to a <strong>disc_table</strong> at the node specified as <strong>Node</strong>.</li></ul><h3>Data Model</h3><p>The data model employed by <strong>Mnesia</strong> is an extended
relational data model. Data is organized as a set of
tables and relations between different data records can
be modeled as more tables describing the relationships.
Each table contains instances of Erlang records.
The records are represented as Erlang tuples.</p><p>Each Object Identifier (OID) is made up of a table name and a key.
For example, if an employee record is represented by the tuple
<strong>{employee, 104732, klacke, 7, male, 98108, {221, 015}}</strong>,
this record has an OID, which is the tuple
<strong>{employee, 104732}</strong>.</p><p>Thus, each table is made up of records, where the first element
is a record name and the second element of the table is a key,
which identifies the particular record in that table. The
combination of the table name and a key is an arity two tuple
<strong>{Tab, Key}</strong> called the OID. For more information about
the relationship beween the record name and the table name, see
<a href="./Mnesia_chap4#recordnames_tablenames">Record Names versus Table Names</a>.
</p><p>What makes the <strong>Mnesia</strong> data model an extended relational model
is the ability to store arbitrary Erlang terms in the attribute
fields. One attribute value can, for example, be a whole tree of
OIDs leading to other terms in other tables. This type
of record is difficult to model in traditional relational DBMSs.</p><a name="start_mnesia"></a><h3>Start Mnesia</h3><p>Before starting <strong>Mnesia</strong>, the following must be done:
</p><ul><li>An empty schema must be initialized on all the participating nodes.</li><li>The Erlang system must be started.</li><li>Nodes with disc database schema must be defined and implemented with the function <a href="./mnesia#create_schema/1">mnesia:create_schema(NodeList)</a>.</li></ul><p>When running a distributed system with two or more
participating nodes, the function
<a href="./mnesia#start/0">mnesia:start()</a>
must be executed on each participating node. This would typically
be part of the boot script in an embedded environment.
In a test environment or an interactive environment,
<strong>mnesia:start()</strong> can also be used either from the
Erlang shell or another program.
</p><h3>Initialize a Schema and Start Mnesia</h3><p>Let us use the example database <strong>Company</strong>, described in
<a href="./Mnesia_chap2#getting_started">Getting Started</a> to
illustrate how to run a database on two separate nodes,
called <strong>a@gin</strong> and <strong>b@skeppet</strong>. Each of these
nodes must have a <strong>Mnesia</strong> directory and an
initialized schema before <strong>Mnesia</strong> can be started. There are
two ways to specify the <strong>Mnesia</strong> directory to be used:</p><ul><li> <p>Specify the <strong>Mnesia</strong> directory by providing an application
parameter either when starting the Erlang shell or in the
application script. Previously, the following example was used
to create the directory for the <strong>Company</strong> database:</p> <pre>
%<span class="input">erl -mnesia dir '"/ldisc/scratch/Mnesia.Company"'</span>
          </pre> </li><li>If no command-line flag is entered, the <strong>Mnesia</strong> directory becomes the current working directory on the node where the Erlang shell is started.</li></ul><p>To start the <strong>Company</strong> database and get it running on the two
specified nodes, enter the following commands:</p><ul><li> <p>On the node <strong>a@gin</strong>:</p> <pre>
 gin %<span class="input">erl -sname a  -mnesia dir '"/ldisc/scratch/Mnesia.company"'</span></pre> </li><li><p>On the node <strong>b@skeppet</strong>:</p> <pre>
skeppet %<span class="input">erl -sname b -mnesia dir '"/ldisc/scratch/Mnesia.company"'</span></pre> </li><li> <p>On one of the two nodes:</p> <pre>
(a@gin)1&gt;<span class="input">mnesia:create_schema([a@gin, b@skeppet]).</span></pre> </li><li>The function <a href="./mnesia#start/0">mnesia:start()</a> is called on both nodes. </li><li><p>To initialize the database, execute the following
code on one of the two nodes:</p> <pre><code class="">


dist_init() -&gt;
    mnesia:create_table(employee,
                         [{ram_copies, [a@gin, b@skeppet]},
                          {attributes, record_info(fields,
						   employee)}]),
    mnesia:create_table(dept,
                         [{ram_copies, [a@gin, b@skeppet]},
                          {attributes, record_info(fields, dept)}]),
    mnesia:create_table(project,
                         [{ram_copies, [a@gin, b@skeppet]},
                          {attributes, record_info(fields, project)}]),
    mnesia:create_table(manager, [{type, bag}, 
                                  {ram_copies, [a@gin, b@skeppet]},
                                  {attributes, record_info(fields,
							   manager)}]),
    mnesia:create_table(at_dep,
                         [{ram_copies, [a@gin, b@skeppet]},
                          {attributes, record_info(fields, at_dep)}]),
    mnesia:create_table(in_proj,
                        [{type, bag}, 
                         {ram_copies, [a@gin, b@skeppet]},
                         {attributes, record_info(fields, in_proj)}]).</code></pre>        </li></ul><p>As illustrated, the two directories reside on different nodes,
because <strong>/ldisc/scratch</strong> (the "local" disc) exists on
the two different nodes.</p><p>By executing these commands, two Erlang nodes are configured to
run the <strong>Company</strong> database, and therefore, initialize the
database. This is required only once when setting up. The next time
the system is started,
<a href="./mnesia#start/0">mnesia:start()</a>
is called
on both nodes, to initialize the system from disc.</p><p>In a system of <strong>Mnesia</strong> nodes, every node is aware of the
current location of all tables. In this example, data is
replicated on both nodes and functions that manipulate the
data in the tables can be executed on either of the two nodes.
Code that manipulate <strong>Mnesia</strong> data behaves identically
regardless of where the data resides.</p><p>The function <a href="./mnesia#stop/0">mnesia:stop()</a>
stops <strong>Mnesia</strong> on the node
where the function is executed. The functions <strong>mnesia:start/0</strong>
and <strong>mnesia:stop/0</strong> work on the "local" <strong>Mnesia</strong> system.
No functions start or stop a set of nodes.</p><h3>Startup Procedure</h3><p>Start <strong>Mnesia</strong> by calling the following function:</p><pre><code class="">
          mnesia:start().</code></pre><p>This function initiates the DBMS locally.</p><p>The choice of configuration alters the location and load
order of the tables. The alternatives are as follows:</p><ul><li>Tables that are only stored locally are initialized from the local <strong>Mnesia</strong> directory. </li><li>Replicated tables that reside locally as well as somewhere else are either initiated from disc or by copying the entire table from the other node, depending on which of the different replicas are the most recent. <strong>Mnesia</strong> determines which of the tables are the most recent. </li><li>Tables that reside on remote nodes are available to other nodes as soon as they are loaded.</li></ul><p>Table initialization is asynchronous. The function
call <a href="./mnesia#start/0">mnesia:start()</a>
returns the atom <strong>ok</strong> and
then starts to initialize the different tables. Depending on
the size of the database, this can take some time, and the
application programmer must wait for the tables that the
application needs before they can be used. This is achieved by
using the function
<a href="./mnesia#wait_for_tables/2">mnesia:wait_for_tables(TabList, Timeout)</a>,
which suspends the caller until all tables
specified in <strong>TabList</strong> are properly initiated.</p><p>A problem can arise if a replicated table on one node is
initiated, but <strong>Mnesia</strong> deduces that another (remote)
replica is more recent than the replica existing on the
local node, and the initialization procedure does not proceed.
In this situation, a call to
<a href="./mnesia#wait_for_tables/2">mnesia:wait_for_tables/2</a>,
suspends the caller until the
remote node has initialized the table from its local disc and
the node has copied the table over the network to the local node.</p><p>However, this procedure can be time-consuming, the shortcut function
<a href="./mnesia#force_load_table/1">mnesia:force_load_table(Tab)</a>
loads all the tables from disc at a faster rate. The function forces
tables to be loaded from disc regardless of the network
situation.</p><p>Thus, it can be assumed that if an application wants to use
tables <strong>a</strong> and <strong>b</strong>, the application must perform
some action similar to following before it can use the tables:</p><pre>
          case mnesia:wait_for_tables([a, b], 20000) of
            {timeout,   RemainingTabs} -&gt;
              panic(RemainingTabs);
            ok -&gt;
              synced
          end.</pre><div class="alert alert-warning"><h4 class="alert-heading">Warning</h4><p>When tables are forcefully loaded from the local disc,
all operations that were performed on the replicated table
while the local node was down, and the remote replica was
alive, are lost. This can cause the database to become
inconsistent.</p></div><p>If the startup procedure fails, the function
<a href="./mnesia#start/0">mnesia:start()</a>
returns the cryptic tuple
<strong>{error,{shutdown, {mnesia_sup,start_link,[normal,[]]}}}</strong>.
To get more information about the start failure, use
command-line arguments <strong>-boot start_sasl</strong> as argument to
the <strong>erl</strong> script.</p><a name="create_tables"></a><h3>Create Tables</h3><p>The function
<a href="./mnesia#create_table/2">mnesia:create_table(Name, ArgList)</a>
creates tables. When executing this function, it returns one of
the following responses:</p><ul><li><strong>{atomic, ok}</strong> if the function executes successfully </li><li><strong>{aborted, Reason}</strong> if the function fails </li></ul><p>The function arguments are as follows:</p><ul><li><strong>Name</strong> is the name of the table. It is usually the same name as the name of the records that constitute the table. For details, see <strong>record_name</strong>. </li><li> <p><strong>ArgList</strong> is a list of <strong>{Key,Value}</strong> tuples.
The following arguments are valid:</p> <ul><li> <p><strong>{type, Type}</strong>, where <strong>Type</strong> must be either of
the atoms <strong>set</strong>, <strong>ordered_set</strong>, or <strong>bag</strong>.
Default is <strong>set</strong>.</p> <p>Notice that currently <strong>ordered_set</strong> is not
supported for <strong>disc_only_copies</strong> tables.</p> <p>A table of type
<strong>set</strong> or <strong>ordered_set</strong> has either zero or
one record per key, whereas a table of type <strong>bag</strong> can
have an arbitrary number of records per key. The key for
each record is always the first attribute of the record.</p> <p>The following example illustrates the difference between
type <strong>set</strong> and <strong>bag</strong>:</p> <pre>
 f() -&gt;
    F = fun() -&gt;
          mnesia:write({foo, 1, 2}),
          mnesia:write({foo, 1, 3}),
          mnesia:read({foo, 1})
        end,
    mnesia:transaction(F).</pre> <p>This transaction returns the list <strong>[{foo,1,3}]</strong> if
table <strong>foo</strong> is of type <strong>set</strong>. However, the list
<strong>[{foo,1,2}, {foo,1,3}]</strong> is returned if the table is
of type <strong>bag</strong>.</p> <p><strong>Mnesia</strong> tables can never contain
duplicates of the same record in the same table. Duplicate
records have attributes with the same contents and key.</p> </li><li> <p><strong>{disc_copies, NodeList}</strong>, where <strong>NodeList</strong> is a
list of the nodes where this table is to reside on disc.</p> <p>Write operations to a table replica of type
<strong>disc_copies</strong> write data to the disc copy and
to the RAM copy of the table.</p> <p>It is possible to have a
replicated table of type <strong>disc_copies</strong> on one node, and
the same table stored as a different type on another node.
Default is <strong>[]</strong>. This arrangement is
desirable if the following operational
characteristics are required:</p> <ul><li>Read operations must be fast and performed in RAM.</li><li>All write operations must be written to persistent storage.</li></ul> <p>A write operation on a <strong>disc_copies</strong> table
replica is performed in two steps. First the write
operation is appended to a log file, then the actual
operation is performed in RAM.</p> </li><li> <p><strong>{ram_copies, NodeList}</strong>, where <strong>NodeList</strong> is a
list of the nodes where this table is stored in RAM.
Default is <strong>[node()]</strong>. If the default value is used
to create a table, it is located on the local node only.</p> <p>Table replicas of type
<strong>ram_copies</strong> can be dumped to disc with the function
<a href="./mnesia#dump_tables/1">mnesia:dump_tables(TabList)</a>.</p> </li><li><strong>{disc_only_copies, NodeList}</strong>. These table replicas are stored on disc only and are therefore slower to access. However, a disc-only replica consumes less memory than a table replica of the other two storage types. </li><li><p><strong>{index, AttributeNameList}</strong>, where
<strong>AttributeNameList</strong> is a list of atoms specifying the
names of the attributes <strong>Mnesia</strong> is to build and maintain.
An index table exists for every element in the list. The first
field of a <strong>Mnesia</strong> record is the key and thus need no
extra index.</p> <p>The first field of a record is the second element of the
tuple, which is the representation of the record.</p> </li><li><p><strong>{snmp, SnmpStruct}</strong>. <strong>SnmpStruct</strong> is
described in the
<a href="./index">SNMP</a> User's Guide.
Basically, if this attribute is present in <strong>ArgList</strong> of
<a href="./mnesia#create_table/2">mnesia:create_table/2</a>,
the table is immediately accessible the SNMP.</p> <p>It is easy to design applications that use SNMP to
manipulate and control the system. <strong>Mnesia</strong> provides a
direct mapping between the logical tables that make up an SNMP
control application and the physical data that makes up a
<strong>Mnesia</strong> table. The default value is <strong>[]</strong>.</p> </li><li><strong>{local_content, true}</strong>. When an application needs a table whose contents is to be locally unique on each node, <strong>local_content</strong> tables can be used. The name of the table is known to all <strong>Mnesia</strong> nodes, but its contents is unique for each node. Access to this type of table must be done locally.</li><li> <p><strong>{attributes, AtomList}</strong> is a list of the attribute
names for the records that are supposed to populate the
table. Default is the list <strong>[key, val]</strong>. The
table must at least have one extra attribute besides the
key. When accessing single attributes in a record, it is not
recommended to hard code the attribute names as atoms. Use
the construct <strong>record_info(fields, record_name)</strong>
instead.</p> <p>The expression
<strong>record_info(fields, record_name)</strong> is processed by the
Erlang preprocessor and returns a list of the
record field names. With the record definition
<strong>-record(foo, {x,y,z}).</strong>, the expression
<strong>record_info(fields,foo)</strong> is expanded to the list
<strong>[x,y,z]</strong>. It is therefore possible for you to provide
the attribute names or to use the <strong>record_info/2</strong>
notation.</p> <p>It is recommended to use the <strong>record_info/2</strong> notation,
as it becomes easier to maintain the program and the program
becomes more robust with regards to future record changes.</p> </li><li> <p><strong>{record_name, Atom}</strong> specifies the common name of
all records stored in the table. All records stored in
the table must have this name as their first element.
<strong>record_name</strong> defaults to the name of the table.
For more information, see
<a href="./Mnesia_chap4#recordnames_tablenames">Record Names versus Table Names</a>.</p> </li></ul> </li></ul><p>As an example, consider the following record definition:</p><pre>
      -record(funky, {x, y}).</pre><p>The following call would create a table that is replicated on two
nodes, has an extra index on attribute <strong>y</strong>, and is of type
<strong>bag</strong>.</p><pre>
      mnesia:create_table(funky, [{disc_copies, [N1, N2]}, {index,
      [y]}, {type, bag}, {attributes, record_info(fields, funky)}]).</pre><p>Whereas a call to the following default code values would return
a table with a RAM copy on the local node, no extra indexes, and the
attributes defaulted to the list <strong>[key,val]</strong>.</p><pre>
mnesia:create_table(stuff, [])</pre><p>This section describes the <strong>Mnesia</strong> transaction system and
the transaction properties that make <strong>Mnesia</strong> a fault-tolerant,
distributed Database Management System (DBMS).</p><p>This section also describes the locking functions,
including table locks and sticky locks, as well as alternative
functions that bypass the transaction system in favor of improved
speed and reduced overhead. These functions are called "dirty
operations". The use of nested transactions is also described.
The following topics are included:</p><ul><li>Transaction properties, which include atomicity, consistency, isolation, and durability</li><li>Locking</li><li>Dirty operations</li><li>Record names versus table names</li><li>Activity concept and various access contexts</li><li>Nested transactions</li><li>Pattern matching</li><li>Iteration</li></ul><a name="trans_prop"></a><h3>Transaction Properties</h3><p>Transactions are important when designing fault-tolerant,
distributed systems. A <strong>Mnesia</strong> transaction is a mechanism
by which a series of database operations can be executed as one
functional block. The functional block that is run as a
transaction is called a Functional Object (Fun), and this code can
read, write, and delete <strong>Mnesia</strong> records. The Fun is evaluated
as a transaction that either commits or terminates. If a transaction
succeeds in executing the Fun, it replicates the action on all nodes
involved, or terminates if an error occurs.</p><p>The following example shows a transaction that raises the
salary of certain employee numbers:</p><pre><code class="">

raise(Eno, Raise) -&gt;
    F = fun() -&gt;
                [E] = mnesia:read(employee, Eno, write),
                Salary = E#employee.salary + Raise,
                New = E#employee{salary = Salary},
                mnesia:write(New)
        end,
    mnesia:transaction(F).</code></pre><p>The function <strong>raise/2</strong> contains a Fun
made up of four code lines. This Fun is called by the statement
<strong>mnesia:transaction(F)</strong> and returns a value.</p><p>The <strong>Mnesia</strong> transaction system facilitates the construction of
reliable, distributed systems by providing the following important
properties:</p><ul><li>The transaction handler ensures that a Fun, which is placed inside a transaction, does not interfere with operations embedded in other transactions when it executes a series of operations on tables.   </li><li>The transaction handler ensures that either all operations in the transaction are performed successfully on all nodes atomically, or the transaction fails without permanent effect on any node. </li><li>The <strong>Mnesia</strong> transactions have four important properties, called <em>A</em>tomicity, <em>C</em>onsistency, <em>I</em>solation, and <em>D</em>urability (ACID). These properties are described in the following sections.</li></ul><h3>Atomicity</h3><p>Atomicity means that database changes that are
executed by a transaction take effect on all nodes involved, or
on none of the nodes. That is, the transaction either
succeeds entirely, or it fails entirely.</p><p>Atomicity is important when it is needed to write
atomically more than one record in the same
transaction. The function <strong>raise/2</strong>, shown in the previous
example, writes one record only. The function <strong>insert_emp/3</strong>,
shown in the program listing in
<a href="./Mnesia_chap2#getting_started">Getting Started</a>, writes the record
<strong>employee</strong> as well as employee relations, such as
<strong>at_dep</strong> and <strong>in_proj</strong>, into the database. If this
latter code is run inside a transaction, the transaction
handler ensures that the transaction either succeeds completely,
or not at all.</p><p><strong>Mnesia</strong> is a distributed DBMS where data can be replicated
on several nodes. In many applications, it is important that a
series of write operations are performed atomically inside a
transaction. The atomicity property ensures that a transaction
takes effect on all nodes, or none.</p><h3>Consistency</h3><p>The consistency property ensures that
a transaction always leaves the DBMS in a consistent state. For
example, <strong>Mnesia</strong> ensures that no inconsistencies occur if
Erlang, <strong>Mnesia</strong>, or the computer crashes while a write
operation is in progress.</p><h3>Isolation</h3><p>The isolation property ensures that
transactions that execute on different nodes in a network, and
access and manipulate the same data records, do not interfere
with each other. The isolation property makes it possible to
execute the function <strong>raise/2</strong> concurrently. A classical
problem in concurrency control theory is the "lost update
problem".</p><p>The isolation property is in particular useful if the following
circumstances occur where an employee (with employee number
123) and two processes (P1 and P2) are concurrently trying to
raise the salary for the employee:</p><ul><li><em>Step 1:</em> The initial value of the employees salary is, for example, 5. Process P1 starts to execute, reads the employee record, and adds 2 to the salary.</li><li><em>Step 2:</em> Process P1 is for some reason pre-empted and process P2 has the opportunity to run.</li><li><em>Step 3:</em> Process P2 reads the record, adds 3 to the salary, and finally writes a new employee record with the salary set to 8.</li><li><em>Step 4:</em> Process P1 starts to run again and writes its employee record with salary set to 7, thus effectively overwriting and undoing the work performed by process P2. The update performed by P2 is lost.</li></ul><p>A transaction system makes it possible to execute two or more
processes concurrently that manipulate the same record.
The programmer does not need to check that the
updates are synchronous; this is overseen by the
transaction handler. All programs accessing the database through
the transaction system can be written as if they had sole access
to the data.</p><h3>Durability</h3><p>The durability property ensures that
changes made to the DBMS by a transaction are permanent. Once a
transaction is committed, all changes made to the database are
durable, that is, they are written safely to disc and do not
become corrupted and do not disappear.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>The described durability feature does not entirely apply to
situations where <strong>Mnesia</strong> is configured as a "pure"
primary memory database.</p></div><h3>Locking</h3><p>Different transaction managers employ different strategies to
satisfy the isolation property. <strong>Mnesia</strong> uses the standard
technique of two phase locking. That is, locks are set on records
before they are read or written. <strong>Mnesia</strong> uses the following
lock types:</p><ul><li><em>Read locks</em>. A read lock is set on one replica of a record before it can be read. </li><li><em>Write locks</em>. Whenever a transaction writes to a record, write locks are first set on all replicas of that particular record. </li><li><em>Read table locks</em>. If a transaction traverses an entire table in search for a record that satisfies some particular property, it is most inefficient to set read locks on the records one by one. It is also memory consuming, as the read locks themselves can take up considerable space if the table is large. Therefore, <strong>Mnesia</strong> can set a read lock on an entire table. </li><li><em>Write table locks</em>. If a transaction writes many records to one table, a write lock can be set on the entire table. </li><li><em>Sticky locks</em>. These are write locks that stay in place at a node after the transaction that initiated the lock has terminated.</li></ul><p><strong>Mnesia</strong> employs a strategy whereby functions, such as
<a href="./mnesia#read/1">mnesia:read/1</a>
acquire the necessary locks dynamically as
the transactions execute. <strong>Mnesia</strong> automatically sets and
releases the locks and the programmer does not need to code these
operations.</p><p>Deadlocks can occur when concurrent processes set and release
locks on the same records. <strong>Mnesia</strong> employs a "wait-die"
strategy to resolve
these situations. If <strong>Mnesia</strong> suspects that a deadlock can
occur when a transaction tries to set a lock, the transaction is
forced to release all its locks and sleep for a while. The Fun
in the transaction is evaluated once more.</p><p>It is therefore important that the code inside the Fun given to
<a href="./mnesia#transaction/2">mnesia#transaction/2</a>
is pure. Some strange results can
occur if, for example, messages are sent by the transaction
Fun. The following example illustrates this situation:</p><pre><code class="">

bad_raise(Eno, Raise) -&gt;
    F = fun() -&gt;
                [E] = mnesia:read({employee, Eno}),
                Salary = E#employee.salary + Raise,
                New = E#employee{salary = Salary},
                io:format("Trying to write ... ~n", []),
                mnesia:write(New)
        end,
    mnesia:transaction(F).</code></pre><p>This transaction can write the text <strong>"Trying to write ... "</strong>
1000 times to the terminal. However, <strong>Mnesia</strong> guarantees
that each transaction will eventually run. As a result,
<strong>Mnesia</strong> is not only deadlock free, but also livelock free.</p><p>The <strong>Mnesia</strong> programmer cannot prioritize one particular
transaction to execute before other transactions that are waiting
to execute. As a result, the <strong>Mnesia</strong> DBMS transaction system is
not suitable for hard real-time applications. However, <strong>Mnesia</strong>
contains other features that have real-time properties.</p><p><strong>Mnesia</strong> dynamically sets and releases locks as transactions
execute. It is therefore dangerous to execute code with
transaction side-effects. In particular, a <strong>receive</strong>
statement inside a transaction can lead to a situation where the
transaction hangs and never returns, which in turn can cause locks
not to release. This situation can bring the whole system to a
standstill, as other transactions that execute in other
processes, or on other nodes, are forced to wait for the defective
transaction.</p><p>If a transaction terminates abnormally, <strong>Mnesia</strong>
automatically releases the locks held by the transaction.</p><p>Up to now, examples of a number of functions that can be used
inside a transaction have been shown. The following list shows
the <em>simplest</em> <strong>Mnesia</strong> functions that work with
transactions. Notice that these functions must be embedded in a
transaction. If no enclosing transaction (or other enclosing
<strong>Mnesia</strong> activity) exists, they all fail.</p><ul><li><a href="./mnesia#transaction/2">mnesia:transaction(Fun) -&gt; {aborted, Reason} |{atomic, Value}</a> executes one transaction with the functional object <strong>Fun</strong> as the single parameter. </li><li><a href="./mnesia#read/1">mnesia:read({Tab, Key}) -&gt; transaction abort | RecordList</a> reads all records with <strong>Key</strong> as key from table <strong>Tab</strong>. This function has the same semantics regardless of the location of <strong>Table</strong>. If the table is of type <strong>bag</strong>, <strong>read({Tab, Key})</strong> can return an arbitrarily long list. If the table is of type <strong>set</strong>, the list is either of length one or <strong>[]</strong>. </li><li><a href="./mnesia#wread/1">mnesia:wread({Tab, Key}) -&gt; transaction abort | RecordList</a> behaves the same way as the previously listed function <strong>read/1</strong>, except that it acquires a write lock instead of a read lock. To execute a transaction that reads a record, modifies the record, and then writes the record, it is slightly more efficient to set the write lock immediately. When a <a href="./mnesia#read/1">mnesia:read/1</a> is issued, followed by a <a href="./mnesia#write/1">mnesia:write/1</a> the first read lock must be upgraded to a write lock when the write operation is executed. </li><li><a href="./mnesia#write/1">mnesia:write(Record) -&gt; transaction abort | ok</a> writes a record into the database. Argument <strong>Record</strong> is an instance of a record. The function returns <strong>ok</strong>, or terminates the transaction if an error occurs. </li><li><a href="./mnesia#delete/1">mnesia:delete({Tab, Key}) -&gt; transaction abort | ok</a> deletes all records with the given key. </li><li><a href="./mnesia#delete_object/1">mnesia:delete_object(Record) -&gt; transaction abort | ok</a> deletes records with the OID <strong>Record</strong>. Use this function to delete only some records in a table of type <strong>bag</strong>.</li></ul><h3>Sticky Locks</h3><p>As previously stated, the locking strategy used by <strong>Mnesia</strong>
is to lock one record when reading a record, and lock all replicas
of a record when writing a record. However, some
applications use <strong>Mnesia</strong> mainly for its fault-tolerant
qualities. These applications can be configured with one
node doing all the heavy work, and a standby node that is ready
to take over if the main node fails. Such applications can
benefit from using sticky locks instead of the normal locking
scheme.</p><p>A sticky lock is a lock that stays in place at a node, after
the transaction that first acquired the lock has terminated. To
illustrate this, assume that the following transaction is
executed:</p><pre><code class="">
        F = fun() -&gt;
              mnesia:write(#foo{a = kalle})
            end,
        mnesia:transaction(F).</code></pre><p>The <strong>foo</strong> table is replicated on the two nodes <strong>N1</strong>
and <strong>N2</strong>.</p><p>Normal locking requires the following:</p><ul><li>One network RPC (two messages) to acquire the write lock </li><li>Three network messages to execute the two-phase commit protocol </li></ul><p>If sticky locks are used, the code must first be changed as
follows:</p><pre><code class="">
        F = fun() -&gt;
              mnesia:s_write(#foo{a = kalle})
            end,
        mnesia:transaction(F).</code></pre><p>This code uses the function
<a href="./mnesia#s_write/1">s_write/1</a>
instead of the function
<a href="./mnesia#write/1">write/1</a>
The function <strong>s_write/1</strong> sets a
sticky lock instead of a normal lock. If the table is not
replicated, sticky locks have no special effect. If the table is
replicated, and a sticky lock is set on node <strong>N1</strong>, this
lock then sticks to node <strong>N1</strong>. The next time you try to
set a sticky lock on the same record at node <strong>N1</strong>,
<strong>Mnesia</strong> detects that the lock is already set and do no
network operation to acquire the lock.</p><p>It is more efficient to set a local lock than it is to set
a networked lock. Sticky locks can therefore benefit an
application that uses a replicated table and perform most of the
work on only one of the nodes.</p><p>If a record is stuck at node <strong>N1</strong> and you try to set a
sticky lock for the record on node <strong>N2</strong>, the record must be
unstuck. This operation is expensive and reduces performance.
The unsticking is done automatically if you issue <strong>s_write/1</strong>
requests at <strong>N2</strong>.</p><h3>Table Locks</h3><p><strong>Mnesia</strong> supports read and write locks on whole tables as a
complement to the normal locks on single records. As previously
stated, <strong>Mnesia</strong> sets and releases locks automatically, and
the programmer does not need to code these operations. However,
transactions that read and write many records in a
specific table execute more efficiently if the
transaction is started by setting a table lock on this table. This
blocks other concurrent transactions from the table. The
following two functions are used to set explicit table locks for
read and write operations:</p><ul><li><a href="./mnesia#read_lock_table/1">mnesia:read_lock_table(Tab)</a> sets a read lock on table <strong>Tab</strong>.</li><li><a href="./mnesia#write_lock_table/1">mnesia:write_lock_table(Tab)</a> sets a write lock on table <strong>Tab</strong>.</li></ul><p>Alternative syntax for acquisition of table locks is as
follows:</p><pre><code class="">
        mnesia:lock({table, Tab}, read)
        mnesia:lock({table, Tab}, write)</code></pre><p>The matching operations in <strong>Mnesia</strong> can either lock the
entire table or only a single record (when the key is bound in
the pattern).</p><h3>Global Locks</h3><p>Write locks are normally acquired on all nodes where a
replica of the table resides (and is active). Read locks are
acquired on one node (the local one if a local
replica exists).</p><p>The function
<a href="./mnesia#lock/2">mnesia:lock/2</a>
is intended to support table locks (as mentioned previously)
but also for situations when locks need to be
acquired regardless of how tables have been replicated:</p><pre><code class="">
        mnesia:lock({global, GlobalKey, Nodes}, LockKind)

        LockKind ::= read | write | ...</code></pre><p>The lock is acquired on <strong>LockItem</strong> on all nodes in the
node list.</p><h3>Dirty Operations</h3><p>In many applications, the overhead of processing a transaction
can result in a loss of performance. Dirty operation are short
cuts that bypass much of the processing and increase the speed
of the transaction.</p><p>Dirty operation are often useful, for example, in a
datagram routing application
where <strong>Mnesia</strong> stores the routing table, and it is time
consuming to start a whole transaction every time a packet is
received. <strong>Mnesia</strong> has therefore functions that manipulate
tables without using transactions. This alternative
to processing is known as a dirty operation. However, notice the
trade-off in avoiding the overhead of transaction processing:</p><ul><li>The atomicity and the isolation properties of <strong>Mnesia</strong> are lost. </li><li>The isolation property is compromised, because other Erlang processes, which use transaction to manipulate the data, do not get the benefit of isolation if dirty operations simultaneously are used to read and write records from the same table. </li></ul><p>The major advantage of dirty operations is that they execute
much faster than equivalent operations that are processed as
functional objects within a transaction.</p><p>Dirty operations
are written to disc if they are performed on a table of type
<strong>disc_copies</strong> or type <strong>disc_only_copies</strong>. <strong>Mnesia</strong>
also ensures that all replicas of a table are updated if a
dirty write operation is performed on a table.</p><p>A dirty operation ensures a certain level of consistency.
For example, dirty operations cannot return
garbled records. Hence, each individual read or write operation
is performed in an atomic manner.</p><p>All dirty functions execute a call to <strong>exit({aborted, Reason})</strong>
on failure. Even if the following functions are
executed inside a transaction no locks are acquired. The
following functions are available:</p><ul><li><a href="./mnesia#dirty_read/1">mnesia:dirty_read({Tab, Key})</a> reads one or more records from <strong>Mnesia</strong>. </li><li><a href="./mnesia#dirty_write/1">mnesia:dirty_write(Record)</a> writes the record <strong>Record</strong>. </li><li><a href="./mnesia#dirty_delete/1">mnesia:dirty_delete({Tab, Key})</a> deletes one or more records with key <strong>Key</strong>. </li><li><a href="./mnesia#dirty_delete_object/1">mnesia:dirty_delete_object(Record)</a> is the dirty operation alternative to the function <a href="./mnesia#delete_object/1">delete_object/1</a>. </li><li> <p><a href="./mnesia#dirty_first/1">mnesia:dirty_first(Tab)</a>
returns the "first" key in table <strong>Tab</strong>.</p> <p>Records in <strong>set</strong> or <strong>bag</strong> tables are not sorted.
However, there is a record order that is unknown to the user.
This means that a table can be traversed by this function
with the function
<a href="./mnesia#dirty_next/2">mnesia:dirty_next/2</a>.</p> <p>If there are no records in the table, this function
returns the atom <strong>'$end_of_table'</strong>. It is not
recommended to use this atom as the key for any user
records.</p> </li><li><p><a href="./mnesia#dirty_next/2">mnesia:dirty_next(Tab, Key)</a>
returns the "next" key in table <strong>Tab</strong>. This function makes it
possible to traverse a table and perform some operation on all
records in the table. When the end of the table is reached, the
special key <strong>'$end_of_table'</strong> is returned. Otherwise, the
function returns a key that can be used to read the actual
record.</p> <p>The behavior is undefined if any process performs a write
operation on the table while traversing the table with the
function
<a href="./mnesia#dirty_next/2">dirty_next/2</a>
This is because <strong>write</strong>
operations on a <strong>Mnesia</strong> table can lead to internal
reorganizations of the table itself. This is an implementation
detail, but remember that the dirty functions are low-level
functions.</p> </li><li><a href="./mnesia#dirty_last/1">mnesia:dirty_last(Tab)</a> works exactly like <a href="./mnesia#dirty_first/1">mnesia:dirty_first/1</a> but returns the last object in Erlang term order for the table type <strong>ordered_set</strong>. For all other table types, <strong>mnesia:dirty_first/1</strong> and  <strong>mnesia:dirty_last/1</strong> are synonyms. </li><li><a href="./mnesia#dirty_prev/2">mnesia:dirty_prev(Tab, Key)</a> works exactly like <strong>mnesia:dirty_next/2</strong> but returns the previous object in Erlang term order for the table type <strong>ordered_set</strong>. For all other table types, <strong>mnesia:dirty_next/2</strong> and <strong>mnesia:dirty_prev/2</strong> are synonyms. </li><li> <p><a href="./mnesia#dirty_slot/2">mnesia:dirty_slot(Tab, Slot)</a>
returns the list of records that are associated with <strong>Slot</strong>
in a table. It can be used to traverse a table in a manner
similar to the function <strong>dirty_next/2</strong>. A table has a
number of slots that range from zero to some unknown upper
bound. The function <strong>dirty_slot/2</strong> returns the special
atom <strong>'$end_of_table'</strong> when the end of the table is
reached.</p> <p>The behavior of this function is undefined if the
table is written on while being
traversed. The function
<a href="./mnesia#read_lock_table/1">mnesia:read_lock_table(Tab)</a>
can be used to ensure that no transaction-protected writes
are performed during the iteration.</p> </li><li><p><a href="./mnesia#dirty_update_counter/2">mnesia:dirty_update_counter({Tab,Key}, Val)</a>.
Counters are positive integers with a value greater than or
equal to zero. Updating a counter adds <strong>Val</strong> and the
counter where <strong>Val</strong> is a positive or negative integer.</p> <p><strong>Mnesia</strong> has no special counter records. However, records
of the form <strong>{TabName, Key, Integer}</strong> can be used as
counters, and can be persistent.</p> <p>Transaction-protected updates of counter records are not
possible.</p> <p>There are two significant differences when using this
function instead of reading the record, performing the
arithmetic, and writing the record:</p> <ul><li>It is much more efficient. </li><li>The funcion <a href="./mnesia#dirty_update_counter/2">dirty_update_counter/2</a> is performed as an atomic operation although it is not protected by a transaction. Therfore no table update is lost if two processes simultaneously execute the function <strong>dirty_update_counter/2</strong>. </li></ul> </li><li><a href="./mnesia#dirty_match_object/2">mnesia:dirty_match_object(Pat)</a> is the dirty equivalent of <a href="./mnesia#match_object/1">mnesia:match_object/1</a>. </li><li><a href="./mnesia#dirty_select/2">mnesia:dirty_select(Tab, Pat)</a> is the dirty equivalent of <a href="./mnesia#select/2"> mnesia:select/2</a>. </li><li><a href="./mnesia#dirty_index_match_object/2">mnesia:dirty_index_match_object(Pat, Pos)</a> is the dirty equivalent of <a href="./mnesia#index_match_object/2">mnesia:index_match_object/2</a>. </li><li><a href="./mnesia#dirty_index_read/3">mnesia:dirty_index_read(Tab, SecondaryKey, Pos)</a> is the dirty equivalent of <a href="./mnesia#index_read/3">mnesia:index_read/3</a>. </li><li><a href="./mnesia#dirty_all_keys/1">mnesia:dirty_all_keys(Tab)</a> is the dirty equivalent of <a href="./mnesia#all_keys/1"> mnesia:all_keys/1</a>. </li></ul><a name="recordnames_tablenames"></a><h3>Record Names versus Table Names</h3><p>In <strong>Mnesia</strong>, all records in a table must have the same name.
All the records must be instances of the same
record type. The record name, however, does not necessarily have
to be the same as the table name, although this is the case in
most of the examples in this User's Guide. If a table is created
without property <strong>record_name</strong>, the following code ensures
that all records in the tables have the same name as the table:</p><pre><code class="">
      mnesia:create_table(subscriber, [])</code></pre><p>However, if the table is created with an explicit record name
as argument, as shown in the following example, subscriber records
can be stored in both of the tables regardless of the table
names:</p><pre><code class="">
      TabDef = [{record_name, subscriber}],
      mnesia:create_table(my_subscriber, TabDef),
      mnesia:create_table(your_subscriber, TabDef).</code></pre><p>To access such tables, simplified access functions
(as described earlier) cannot be used. For example,
writing a subscriber record into a table requires the function
<a href="./mnesia#write/3">mnesia:write/3</a>
instead of the simplified functions
<a href="./mnesia#write/1">mnesia:write/1</a>
and
<a href="./mnesia#s_write/1">mnesia:s_write/1</a>:</p><pre><code class="">
      mnesia:write(subscriber, #subscriber{}, write)
      mnesia:write(my_subscriber, #subscriber{}, sticky_write)
      mnesia:write(your_subscriber, #subscriber{}, write)</code></pre><p>The following simple code illustrates the
relationship between the simplified access functions used in
most of the examples and their more flexible counterparts:</p><pre><code class="">
      mnesia:dirty_write(Record) -&gt;
        Tab = element(1, Record),
        mnesia:dirty_write(Tab, Record).
      
      mnesia:dirty_delete({Tab, Key}) -&gt;
        mnesia:dirty_delete(Tab, Key).
      
      mnesia:dirty_delete_object(Record) -&gt;
        Tab = element(1, Record),
        mnesia:dirty_delete_object(Tab, Record) 
      
      mnesia:dirty_update_counter({Tab, Key}, Incr) -&gt;
        mnesia:dirty_update_counter(Tab, Key, Incr).
      
      mnesia:dirty_read({Tab, Key}) -&gt;
        Tab = element(1, Record),
        mnesia:dirty_read(Tab, Key).
      
      mnesia:dirty_match_object(Pattern) -&gt;
        Tab = element(1, Pattern),
        mnesia:dirty_match_object(Tab, Pattern).
      
      mnesia:dirty_index_match_object(Pattern, Attr) 
        Tab = element(1, Pattern),
        mnesia:dirty_index_match_object(Tab, Pattern, Attr).
      
      mnesia:write(Record) -&gt;
        Tab = element(1, Record),
        mnesia:write(Tab, Record, write).
      
      mnesia:s_write(Record) -&gt;
        Tab = element(1, Record),
        mnesia:write(Tab, Record, sticky_write).
      
      mnesia:delete({Tab, Key}) -&gt;
        mnesia:delete(Tab, Key, write).
      
      mnesia:s_delete({Tab, Key}) -&gt;
        mnesia:delete(Tab, Key, sticky_write).
      
      mnesia:delete_object(Record) -&gt;
        Tab = element(1, Record),
        mnesia:delete_object(Tab, Record, write).
      
      mnesia:s_delete_object(Record) -&gt;
        Tab = element(1, Record),
        mnesia:delete_object(Tab, Record, sticky_write).
      
      mnesia:read({Tab, Key}) -&gt;
        mnesia:read(Tab, Key, read).
      
      mnesia:wread({Tab, Key}) -&gt;
        mnesia:read(Tab, Key, write).
      
      mnesia:match_object(Pattern) -&gt;
        Tab = element(1, Pattern),
        mnesia:match_object(Tab, Pattern, read).
      
      mnesia:index_match_object(Pattern, Attr) -&gt;
        Tab = element(1, Pattern),
        mnesia:index_match_object(Tab, Pattern, Attr, read).</code></pre><h3>Activity Concept and Various Access Contexts</h3><p>As previously described, a Functional Object (Fun) performing
table access operations, as listed here, can be passed
on as arguments to the function
<a href="./mnesia#transaction/2">mnesia:transaction/1,2,3</a>:
</p><ul><li> <a href="./mnesia#write/3">mnesia:write/3 (write/1, s_write/1)</a> </li><li> <a href="./mnesia#delete/3">mnesia:delete/3</a> (<a href="./mnesia#delete/1">mnesia:delete/1</a>, <a href="./mnesia#s_delete/1">mnesia:s_delete/1</a>) </li><li> <a href="./mnesia#delete_object/3">mnesia:delete_object/3</a> (<a href="./mnesia#delete_object/1">mnesia:delete_object/1</a>, <a href="./mnesia#s_delete_object/1">mnesia:s_delete_object/1</a>) </li><li> <a href="./mnesia#read/3">mnesia:read/3</a> (<a href="./mnesia#read/1">mnesia:read/1</a>, <a href="./mnesia#wread/1">mnesia:wread/1</a>) </li><li> <a href="./mnesia#match_object/3">mnesia:match_object/2</a> (<a href="./mnesia#match_object/1">mnesia:match_object/1</a>) </li><li> <a href="./mnesia#select/2">mnesia:select/3</a> (<a href="./mnesia#select/2">mnesia:select/2</a>) </li><li> <a href="./mnesia#foldl/3">mnesia:foldl/3</a> (<strong>mnesia:foldl/4</strong>, <a href="./mnesia#foldr/3">mnesia:foldr/3</a>, <strong>mnesia:foldr/4</strong>) </li><li> <a href="./mnesia#all_keys/1">mnesia:all_keys/1</a> </li><li> <a href="./mnesia#index_match_object/4">mnesia:index_match_object/4</a> (<a href="./mnesia#index_match_object/2">mnesia:index_match_object/2</a>) </li><li> <a href="./mnesia#index_read/3">mnesia:index_read/3</a> </li><li> <a href="./mnesia#lock/2">mnesia:lock/2</a> (<a href="./mnesia#read_lock_table/1">mnesia:read_lock_table/1</a>, <a href="./mnesia#write_lock_table/1">mnesia:write_lock_table/1</a>) </li><li> <a href="./mnesia#table_info/2">mnesia:table_info/2</a> </li></ul><p>These functions are performed in a
transaction context involving mechanisms, such as locking, logging,
replication, checkpoints, subscriptions, and commit protocols.
However, the same function can also be
evaluated in other activity contexts.</p><p>The following activity access contexts are currently supported:</p><ul><li><strong>transaction</strong></li><li><strong>sync_transaction</strong></li><li><strong>async_dirty</strong></li><li><strong>sync_dirty</strong></li><li><strong>ets</strong></li></ul><p>By passing the same "fun" as argument to the function
<a href="./mnesia#sync_transaction/3">mnesia:sync_transaction(Fun [, Args])</a>
it is performed
in synced transaction context. Synced transactions wait until all
active replicas has committed the transaction (to disc) before
returning from the <strong>mnesia:sync_transaction</strong> call. Using
<strong>sync_transaction</strong> is useful in the following cases:</p><ul><li>When an application executes on several nodes and wants to be sure that the update is performed on the remote nodes before a remote process is spawned or a message is sent to a remote process.</li><li>When a combining transaction writes with "dirty_reads", that is, the functions <strong>dirty_match_object</strong>, <strong>dirty_read</strong>, <strong>dirty_index_read</strong>, <strong>dirty_select</strong>, and so on.</li><li>When an application performs frequent or voluminous updates that can overload <strong>Mnesia</strong> on other nodes.</li></ul><p>By passing the same "fun" as argument to the function
<a href="./mnesia#async_dirty/2">mnesia:async_dirty(Fun [, Args])</a>,
it is performed in dirty context. The function calls are mapped to
the corresponding dirty functions. This still involves logging,
replication, and subscriptions but no locking,
local transaction storage, or commit protocols are involved.
Checkpoint retainers are updated but updated
"dirty". Thus, they are updated asynchronously. The
functions wait for the operation to be performed on one
node but not the others. If the table resides locally, no waiting
occurs.</p><p>By passing the same "fun" as an argument to the function
<a href="./mnesia#sync_dirty/2">mnesia:sync_dirty(Fun [, Args])</a>,
it is performed in almost the same context as the function
<a href="./mnesia#async_dirty/2">mnesia:async_dirty/1,2</a>.
The difference is that the operations are performed
synchronously. The caller waits for the updates to be
performed on all active replicas. Using <strong>mnesia:sync_dirty/1,2</strong>
is useful in the following cases:</p><ul><li>When an application executes on several nodes and wants to be sure that the update is performed on the remote nodes before a remote process is spawned or a message is sent to a remote process.</li><li>When an application performs frequent or voluminous updates that can overload <strong>Mnesia</strong> on the nodes.</li></ul><p>To check if your code is executed within a transaction, use
the function
<a href="./mnesia#is_transaction/0">mnesia:is_transaction/0</a>.
It returns <strong>true</strong> when called
inside a transaction context, otherwise <strong>false</strong>.</p><p><strong>Mnesia</strong> tables with storage type <strong>RAM_copies</strong> and
<strong>disc_copies</strong> are implemented internally as
<strong>ets</strong> tables. Applications can access the these tables
directly. This is only
recommended if all options have been weighed and the possible
outcomes are understood. By passing the earlier mentioned "fun"
to the function
<a href="./mnesia#ets/2">mnesia:ets(Fun [, Args])</a>,
it is performed but in a raw
context. The operations are performed directly on the
local <strong>ets</strong> tables, assuming that the local storage type is
<strong>RAM_copies</strong> and that the table is not replicated on other
nodes.</p><p>Subscriptions are not triggered and no checkpoints are updated,
but this operation is blindingly fast. Disc resident
tables are not to be updated with the <strong>ets</strong> function, as the
disc is not updated.</p><p>The Fun can also be passed as an argument to the function
<a href="./mnesia#activity-4">mnesia:activity/2,3,4</a>,
which enables use of customized
activity access callback modules. It can either be obtained
directly by stating the module name as argument, or implicitly
by use of configuration parameter <strong>access_module</strong>. A
customized callback module can be used for several purposes,
such as providing triggers, integrity constraints, runtime
statistics, or virtual tables.</p><p>The callback module does not have
to access real <strong>Mnesia</strong> tables, it is free to do whatever
it wants as long as the callback interface is fulfilled.</p><p><a href="Mnesia_App_B">Appendix B, Activity Access Callback Interface</a> provides the
source code, <strong>mnesia_frag.erl</strong>, for one alternative
implementation. The context-sensitive function
<a href="./mnesia#table_info/2">mnesia:table_info/2</a>
can be used to provide virtual
information about a table. One use of this is to perform
<strong>QLC</strong> queries within an activity context with a
customized callback module. By providing table information about
table indexes and other <strong>QLC</strong> requirements, <strong>QLC</strong> can
be used as a generic query language to access virtual tables.</p><p>QLC queries can be performed in all these activity
contexts (<strong>transaction</strong>, <strong>sync_transaction</strong>,
<strong>async_dirty</strong>, <strong>sync_dirty</strong>, and <strong>ets</strong>). The
<strong>ets</strong> activity only works if the table has no indexes.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>The function <strong>mnesia:dirty_*</strong> always executes with
<strong>async_dirty</strong> semantics regardless of which activity
access contexts that are started. It can even start contexts
without any enclosing activity access context.</p></div><h3>Nested Transactions</h3><p>Transactions can be nested in an arbitrary fashion. A child
transaction must run in the same process as its parent. When a
child transaction terminates, the caller of the child transaction
gets return value <strong>{aborted, Reason}</strong> and any work performed
by the child is erased. If a child transaction commits, the
records written by the child are propagated to the parent.</p><p>No locks are released when child transactions terminate. Locks
created by a sequence of nested transactions are kept until
the topmost transaction terminates. Furthermore, any update
performed by a nested transaction is only propagated
in such a manner so that the parent of the nested transaction
sees the updates. No final commitment is done until
the top-level transaction terminates.
So, although a nested transaction returns <strong>{atomic, Val}</strong>,
if the enclosing parent transaction terminates, the entire
nested operation terminates.</p><p>The ability to have nested transaction with identical semantics
as top-level transaction makes it easier to write
library functions that manipulate <strong>Mnesia</strong> tables.</p><p>Consider a function that adds a subscriber to a telephony
system:</p><pre>
      add_subscriber(S) -&gt;
          mnesia:transaction(fun() -&gt;
              case mnesia:read( ..........</pre><p>This function needs to be called as a transaction.
Assume that you wish to write a function that
both calls the function <strong>add_subscriber/1</strong> and
is in itself protected by the context of a transaction.
By calling <strong>add_subscriber/1</strong> from within
another transaction, a nested transaction is created.</p><p>Also, different activity access contexts can be mixed while
nesting. However, the dirty ones (<strong>async_dirty</strong>,
<strong>sync_dirty</strong>, and <strong>ets</strong>) inherit the transaction
semantics if they are called inside a transaction and thus
grab locks and use two or three phase commit.</p><p><em>Example:</em></p><pre>
      add_subscriber(S) -&gt;
          mnesia:transaction(fun() -&gt;
             %% Transaction context 
             mnesia:read({some_tab, some_data}),
             mnesia:sync_dirty(fun() -&gt;
                 %% Still in a transaction context.
                 case mnesia:read( ..) ..end), end).
      add_subscriber2(S) -&gt;
          mnesia:sync_dirty(fun() -&gt;
             %% In dirty context 
             mnesia:read({some_tab, some_data}),
             mnesia:transaction(fun() -&gt;
                 %% In a transaction context.
                 case mnesia:read( ..) ..end), end).</pre><h3>Pattern Matching</h3><a name="matching"></a><p>When the function
<a href="./mnesia#read/3">mnesia:read/3</a>
cannot be used, <strong>Mnesia</strong>
provides the programmer with several functions for matching
records against a pattern. The most useful ones
are the following:</p><pre><code class="">
      mnesia:select(Tab, MatchSpecification, LockKind) -&gt;
          transaction abort | [ObjectList]
      mnesia:select(Tab, MatchSpecification, NObjects, Lock) -&gt;  
          transaction abort | {[Object],Continuation} | '$end_of_table'
      mnesia:select(Cont) -&gt;
          transaction abort | {[Object],Continuation} | '$end_of_table'
      mnesia:match_object(Tab, Pattern, LockKind) -&gt;
          transaction abort | RecordList</code></pre><p>These functions match a <strong>Pattern</strong> against all records in
table <strong>Tab</strong>. In a
<a href="./mnesia#select/2">mnesia:select</a>
call, <strong>Pattern</strong> is
a part of <strong>MatchSpecification</strong> described in the following. It
is not necessarily performed as an exhaustive search of the entire
table. By using indexes and bound values in the key of the
pattern, the actual work done by the function can be condensed
into a few hash lookups. Using <strong>ordered_set</strong> tables can reduce
the search space if the keys are partially bound.</p><p>The pattern provided to the functions must be a valid record,
and the first element of the provided tuple must be the
<strong>record_name</strong> of the table. The special element <strong>'_'</strong>
matches any data structure in Erlang (also known as an Erlang
term). The special elements <strong>'$&lt;number&gt;'</strong>
behave as Erlang variables, that is, they match anything,
bind the first occurrence, and match the
coming occurrences of that variable against the bound value.</p><p>Use function
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, wild_pattern)</a>
to obtain a basic pattern, which matches all records in a table,
or use the default value in record creation.
Do not make the pattern hard-coded, as this makes the code more
vulnerable to future changes of the record definition.</p><p><em>Example:</em></p><pre><code class="">
      Wildpattern = mnesia:table_info(employee, wild_pattern), 
      %% Or use
      Wildpattern = #employee{_ = '_'},</code></pre><p>For the employee table, the wild pattern looks as follows:</p><pre><code class="">
      {employee, '_', '_', '_', '_', '_',' _'}.</code></pre><p>To constrain the match, it is needed to replace some
of the <strong>'_'</strong> elements. The code for matching out
all female employees looks as follows:</p><pre><code class="">
      Pat = #employee{sex = female, _ = '_'},
      F = fun() -&gt; mnesia:match_object(Pat) end,
      Females = mnesia:transaction(F).</code></pre><p>The match function can also be used to check the equality of
different attributes. For example, to find all employees with
an employee number equal to their room number:</p><pre><code class="">
      Pat = #employee{emp_no = '$1', room_no = '$1', _ = '_'},
      F = fun() -&gt; mnesia:match_object(Pat) end,
      Odd = mnesia:transaction(F).</code></pre><p>The function
<a href="./mnesia#match_object/3">mnesia:match_object/3</a>
lacks some important features that
<a href="./mnesia#select/2">mnesia:select/3</a>
have. For example,
<strong>mnesia:match_object/3</strong> can only return the matching records,
and it cannot express constraints other than equality. To find
the names of the male employees on the second floor:</p><pre><code class="">

      MatchHead = #employee{name='$1', sex=male, room_no={'$2', '_'}, _='_'},
      Guard = [{'&gt;=', '$2', 220},{'&lt;', '$2', 230}],
      Result = '$1',
      mnesia:select(employee,[{MatchHead, Guard, [Result]}])</code></pre><p>The function <strong>select</strong> can be used to add more constraints
and create output that cannot be done with
<strong>mnesia:match_object/3</strong>.</p><p>The second argument to <strong>select</strong> is a <strong>MatchSpecification</strong>.
A <strong>MatchSpecification</strong> is a list of <strong>MatchFunction</strong>s, where
each <strong>MatchFunction</strong> consists of a tuple containing
<strong>{MatchHead, MatchCondition, MatchBody}</strong>:</p><ul><li><strong>MatchHead</strong> is the same pattern as used in <strong>mnesia:match_object/3</strong> described earlier.</li><li><strong>MatchCondition</strong> is a list of extra constraints applied to each record.</li><li><strong>MatchBody</strong> constructs the return values.</li></ul><p>For details about the match specifications, see
"Match Specifications in Erlang" in
<a href="./index">ERTS</a> User's Guide.
For more information, see the
<a href="./ets">ets</a> and
<a href="./dets">dets</a>
manual pages in <strong>STDLIB</strong>.</p><p>The functions
<a href="./mnesia#select/4">select/4</a> and
<a href="./mnesia#select/2">select/1</a>
are used to
get a limited number of results, where <strong>Continuation</strong>
gets the next chunk of results. <strong>Mnesia</strong> uses
<strong>NObjects</strong> as a recommendation only. Thus, more or less
results than specified with <strong>NObjects</strong> can be returned in
the result list, even the empty list can be returned even
if there are more results to collect.</p><div class="alert alert-warning"><h4 class="alert-heading">Warning</h4><p>There is a severe performance penalty in using
<strong>mnesia:select/[1|2|3|4]</strong> after any modifying operation
is done on that table in the same transaction. That is, avoid
using
<a href="./mnesia#write/1">mnesia:write/1</a> or
<a href="./mnesia#delete/1">mnesia:delete/1</a>
before <strong>mnesia:select</strong> in the same transaction.</p></div><p>If the key attribute is bound in a pattern, the match operation
is efficient. However, if the key attribute in a pattern is
given as <strong>'_'</strong> or <strong>'$1'</strong>, the whole <strong>employee</strong>
table must be searched for records that match. Hence if the table is
large, this can become a time-consuming operation, but it can be
remedied with indexes (see
<a href="./Mnesia_chap5#indexing">Indexing</a>)
if the function
<a href="./mnesia#match_object/1">mnesia:match_object</a>
is used.</p><p>QLC queries can also be used to search <strong>Mnesia</strong> tables. By
using the function
<a href="./mnesia#table/1">mnesia:table/[1|2]</a>
as the generator inside a QLC
query, you let the query operate on a <strong>Mnesia</strong> table.
<strong>Mnesia</strong>-specific options to <strong>mnesia:table/2</strong> are
<strong>{lock, Lock}</strong>, <strong>{n_objects,Integer}</strong>, and
<strong>{traverse, SelMethod}</strong>:</p><ul><li><strong>lock</strong> specifies whether <strong>Mnesia</strong> is to acquire a read or write lock on the table.</li><li><strong>n_objects</strong> specifies how many results are to be returned in each chunk to QLC.</li><li><strong>traverse</strong> specifies which function <strong>Mnesia</strong> is to use to traverse the table. Default <strong>select</strong> is used, but by using <strong>{traverse, {select, MatchSpecification}}</strong> as an option to <a href="./mnesia#table/1">mnesia:table/2</a> the user can specify its own view of the table.</li></ul><p>If no options are specified, a read lock is acquired, 100
results are returned in each chunk, and <strong>select</strong> is used
to traverse the table, that is:</p><pre><code class="">
      mnesia:table(Tab) -&gt;
          mnesia:table(Tab, [{n_objects,100},{lock, read}, {traverse, select}]).</code></pre><p>The function
<a href="./mnesia#all_keys/1">mnesia:all_keys(Tab)</a>
returns all keys in a table.</p><h3>Iteration</h3><a name="iteration"></a><p><strong>Mnesia</strong> provides the following functions that iterate over all
the records in a table:</p><pre><code class="">
      mnesia:foldl(Fun, Acc0, Tab) -&gt; NewAcc | transaction abort
      mnesia:foldr(Fun, Acc0, Tab) -&gt; NewAcc | transaction abort
      mnesia:foldl(Fun, Acc0, Tab, LockType) -&gt; NewAcc | transaction abort
      mnesia:foldr(Fun, Acc0, Tab, LockType) -&gt; NewAcc | transaction abort</code></pre><p>These functions iterate over the <strong>Mnesia</strong> table <strong>Tab</strong>
and apply the function <strong>Fun</strong> to each record. <strong>Fun</strong>
takes two arguments, the first is a record from the
table, and the second is the accumulator.
<strong>Fun</strong> returns a new accumulator.</p><p>The first time <strong>Fun</strong> is applied, <strong>Acc0</strong> is
the second argument. The next time <strong>Fun</strong> is called,
the return value from the previous call is used as the
second argument. The term the last call to <strong>Fun</strong> returns
is the return value of the function
<a href="./mnesia#foldl/3">mnesia:foldl/3</a> or
<a href="./mnesia#foldr/3">mnesia:foldr/3</a>.</p><p>The difference between these functions is the
order the table is accessed for <strong>ordered_set</strong> tables.
For other table types the functions are equivalent.</p><p><strong>LockType</strong> specifies what type of lock that is to be
acquired for the iteration, default is <strong>read</strong>. If
records are written or deleted during the iteration, a write
lock is to be acquired.</p><p>These functions can be used to find records in a table
when it is impossible to write constraints for the function
<a href="./mnesia#match_object/3">mnesia:match_object/3</a>,
or when you want to perform some action on certain records.</p><p>For example, finding all the employees who have a salary
less than 10 can look as follows:</p><pre><code class="">
      find_low_salaries() -&gt;
        Constraint = 
             fun(Emp, Acc) when Emp#employee.salary &lt; 10 -&gt;
                    [Emp | Acc];
                (_, Acc) -&gt;
                    Acc
             end,
        Find = fun() -&gt; mnesia:foldl(Constraint, [], employee) end,
        mnesia:transaction(Find).
    </code></pre><p>To raise the salary to 10 for everyone with a salary less than 10
and return the sum of all raises:</p><pre><code class="">
      increase_low_salaries() -&gt;
         Increase = 
             fun(Emp, Acc) when Emp#employee.salary &lt; 10 -&gt;
                    OldS = Emp#employee.salary,
                    ok = mnesia:write(Emp#employee{salary = 10}),
                    Acc + 10 - OldS;
                (_, Acc) -&gt;
                    Acc
             end,
        IncLow = fun() -&gt; mnesia:foldl(Increase, 0, employee, write) end,
        mnesia:transaction(IncLow).
    </code></pre><p>Many nice things can be done with the iterator functions but take
some caution about performance and memory use for large tables.</p><p>Call these iteration functions on nodes that contain a replica of
the table. Each call to the function <strong>Fun</strong> access the table
and if the table resides on another node it generates much
unnecessary network traffic.</p><p><strong>Mnesia</strong> also provides some functions that make it possible
for the user to iterate over the table. The order of the iteration
is unspecified if the table is not of type <strong>ordered_set</strong>:</p><pre><code class="">
      mnesia:first(Tab) -&gt;  Key | transaction abort
      mnesia:last(Tab)  -&gt;  Key | transaction abort
      mnesia:next(Tab,Key)  -&gt;  Key | transaction abort
      mnesia:prev(Tab,Key)  -&gt;  Key | transaction abort
      mnesia:snmp_get_next_index(Tab,Index) -&gt; {ok, NextIndex} | endOfTable</code></pre><p>The order of <strong>first</strong>/<strong>last</strong> and <strong>next</strong>/<strong>prev</strong>
is only valid for
<strong>ordered_set</strong> tables, they are synonyms for other tables.
When the end of the table is reached, the special key
<strong>'$end_of_table'</strong> is returned.</p><p>If records are written and deleted during the traversal, use
the function
<a href="./mnesia#foldl">mnesia:foldl/3</a> or
<a href="./mnesia#foldr">mnesia:foldr/3</a>
with a <strong>write</strong> lock. Or the function
<a href="./mnesia#write_lock_table/1">mnesia:write_lock_table/1</a>
when using <strong>first</strong> and <strong>next</strong>.</p><p>Writing or deleting in transaction context creates a local copy
of each modified record. Thus, modifying each record in a large
table uses much memory. <strong>Mnesia</strong> compensates for every
written or deleted record during the iteration in a transaction
context, which can reduce the performance. If possible, avoid writing
or deleting records in the same transaction before iterating over the
table.</p><p>In dirty context, that is, <strong>sync_dirty</strong> or <strong>async_dirty</strong>,
the modified records are not stored in a local copy; instead,
each record is updated separately. This generates much
network traffic if the table has a replica on another node and
has all the other drawbacks that dirty operations
have. Especially for commands
<a href="./mnesia#first/1">mnesia:first/1</a> and
<a href="./mnesia#next/2">mnesia:next/2</a>,
the same drawbacks as described previously for
<a href="./mnesia#dirty_first/1">mnesia:dirty_first/1</a>
and
<a href="./mnesia#dirty_next/2">mnesia:dirty_next/2</a>
applies, that
is, no writing to the table is to be done during iteration.</p><p>The previous sections describe how to get started
with <strong>Mnesia</strong> and how to build a <strong>Mnesia</strong> database. This
section describes the more advanced features available
when building a distributed, fault-tolerant <strong>Mnesia</strong> database.
The following topics are included:</p><ul><li>Indexing</li><li>Distribution and fault tolerance</li><li>Table fragmentation</li><li>Local content tables</li><li>Disc-less nodes</li><li>More about schema management</li><li><strong>Mnesia</strong> event handling</li><li>Debugging <strong>Mnesia</strong> applications</li><li>Concurrent processes in <strong>Mnesia</strong></li><li>Prototyping</li><li>Object-based programming with <strong>Mnesia</strong></li></ul><a name="indexing"></a><h3>Indexing</h3><p>Data retrieval and matching can be performed efficiently
if the key for the record is known. Conversely, if the key is
unknown, all records in a table must be searched. The larger the
table, the more time consuming it becomes. To remedy this
problem, <strong>Mnesia</strong> indexing capabilities are used to improve
data retrieval and matching of records.</p><p>The following two functions manipulate indexes on existing
tables:</p><ul><li><a href="./mnesia#add_table_index/2">mnesia:add_table_index(Tab, AttributeName) -&gt; {aborted, R} |{atomic, ok}</a></li><li><a href="./mnesia#del_table_index/2">mnesia:del_table_index(Tab, AttributeName) -&gt; {aborted, R} |{atomic, ok}</a></li></ul><p>These functions create or delete a table index on a field
defined by <strong>AttributeName</strong>. To illustrate this, add an
index to the table definition <strong>(employee, {emp_no, name, salary, sex, phone, room_no})</strong>, which is the example table
from the <strong>Company</strong> database. The function that
adds an index on element <strong>salary</strong> can be expressed
as <strong>mnesia:add_table_index(employee, salary)</strong>.</p><p>The indexing capabilities of <strong>Mnesia</strong> are used with the
following three functions, which retrieve and match records
based on index entries in the database:</p><ul><li> <a href="./mnesia#index_read/3">mnesia:index_read(Tab, SecondaryKey, AttributeName) -&gt; transaction abort | RecordList</a> avoids an exhaustive search of the entire table, by looking up <strong>SecondaryKey</strong> in the index to find the primary keys. </li><li> <a href="./mnesia#index_match_object/2">mnesia:index_match_object(Pattern, AttributeName) -&gt; transaction abort | RecordList</a> avoids an exhaustive search of the entire table, by looking up the secondary key in the index to find the primary keys. The secondary key is found in field <strong>AttributeName</strong> of <strong>Pattern</strong>. The secondary key must be bound. </li><li> <a href="./mnesia#match_object/1">mnesia:match_object(Pattern) -&gt; transaction abort | RecordList</a> uses indexes to avoid exhaustive search of the entire table. Unlike the previous functions, this function can use any index as long as the secondary key is bound.</li></ul><p>These functions are further described and exemplified in
<a href="./Mnesia_chap4#matching">Pattern Matching</a>.
</p><h3>Distribution and Fault Tolerance</h3><p><strong>Mnesia</strong> is a distributed, fault-tolerant DBMS. Tables
can be replicated on different Erlang nodes in various
ways. The <strong>Mnesia</strong> programmer does not need to state
where the different tables reside, only the names of the
different tables need to be specified in the program code. This
is known as "location transparency" and is an important
concept. In particular:</p><ul><li><p>A program works regardless of the data
location. It makes no difference whether the data
resides on the local node or on a remote node.</p> <p>Notice that the program runs slower if the data
is located on a remote node.</p> </li><li>The database can be reconfigured, and tables can be moved between nodes. These operations do not affect the user programs.  </li></ul><p>It has previously been shown that each table has a number of
system attributes, such as <strong>index</strong> and <strong>type</strong>.</p><p>Table attributes are specified when the table is created. For
example, the following function creates a table with two
RAM replicas:</p><pre>
      mnesia:create_table(foo,
                          [{ram_copies, [N1, N2]},
                           {attributes, record_info(fields, foo)}]).</pre><p>Tables can also have the following properties,
where each attribute has a list of Erlang nodes as its value:</p><ul><li> <p><strong>ram_copies</strong>. The value of the node list is a list
of Erlang nodes, and a RAM replica of the table resides on
each node in the list.</p> <p>Notice that no disc operations are performed when
a program executes write operations to these replicas.
However, if permanent RAM replicas are required, the
following alternatives are available:</p> <ul><li>The function <a href="./mnesia#dump_tables/1">mnesia:dump_tables/1</a> can be used to dump RAM table replicas to disc. </li><li>The table replicas can be backed up, either from RAM, or from disc if dumped there with this function. </li></ul> </li><li><strong>disc_copies</strong>. The value of the attribute is a list of Erlang nodes, and a replica of the table resides both in RAM and on disc on each node in the list. Write operations addressed to the table address both the RAM and the disc copy of the table.  </li><li><strong>disc_only_copies</strong>. The value of the attribute is a list of Erlang nodes, and a replica of the table resides only as a disc copy on each node in the list. The major disadvantage of this type of table replica is the access speed. The major advantage is that the table does not occupy space in memory. </li></ul><p>In addition, table properties can be set and changed.
For details, see
<a href="./Mnesia_chap3#def_schema">Define a Schema</a>.
</p><p>There are basically two reasons for using more than one table
replica: fault tolerance and speed. Notice
that table replication provides a solution to both of these
system requirements.</p><p>If there are two active table replicas, all information is
still available if one replica fails. This can be an
important property in many applications. Furthermore, if a table
replica exists at two specific nodes, applications that execute
at either of these nodes can read data from the table without
accessing the network. Network operations are considerably
slower and consume more resources than local operations.</p><p>It can be advantageous to create table replicas for a
distributed application that reads data often, but writes data
seldom, to achieve fast read operations on the local
node. The major disadvantage with replication is the increased
time to write data. If a table has two replicas, every write
operation must access both table replicas. Since one of these
write operations must be a network operation, it is considerably
more expensive to perform a write operation to a replicated
table than to a non-replicated table.</p><h3>Table Fragmentation</h3><h3>Concept</h3><p>A concept of table fragmentation has been introduced
to cope with large tables. The idea is to split a
table into several manageable fragments. Each fragment is
implemented as a first class <strong>Mnesia</strong> table and can be
replicated, have indexes, and so on, as any other table. But
the tables cannot have <strong>local_content</strong> or have the
<strong>snmp</strong> connection activated.</p><p>To be able to access a record in a fragmented
table, <strong>Mnesia</strong> must determine to which fragment the
actual record belongs. This is done by module
<strong>mnesia_frag</strong>, which implements the <strong>mnesia_access</strong>
callback behavior. It is recommended to read the
documentation about the function
<a href="./mnesia#activity/4">mnesia:activity/4</a>
to see how <strong>mnesia_frag</strong>
can be used as a <strong>mnesia_access</strong> callback module.</p><p>At each record access, <strong>mnesia_frag</strong> first computes
a hash value from the record key. Second, the name of the
table fragment is determined from the hash value.
Finally the actual table access is performed by the same
functions as for non-fragmented tables. When the key is
not known beforehand, all fragments are searched for
matching records.</p><p>Notice that in <strong>ordered_set</strong> tables, the records
are ordered per fragment, and the order is undefined in
results returned by <strong>select</strong> and <strong>match_object</strong>,
as well as <strong>first</strong>, <strong>next</strong>, <strong>prev</strong> and
<strong>last</strong>.</p><p>The following code illustrates how a <strong>Mnesia</strong> table is
converted to be a fragmented table and how more fragments
are added later:</p><pre><code class="">
Eshell V4.7.3.3  (abort with ^G)
(a@sam)1&gt; mnesia:start().
ok
(a@sam)2&gt; mnesia:system_info(running_db_nodes).
[b@sam,c@sam,a@sam]
(a@sam)3&gt; Tab = dictionary.
dictionary
(a@sam)4&gt; mnesia:create_table(Tab, [{ram_copies, [a@sam, b@sam]}]).
{atomic,ok}
(a@sam)5&gt; Write = fun(Keys) -&gt; [mnesia:write({Tab,K,-K}) || K &lt;- Keys], ok end.
#Fun&lt;erl_eval&gt;
(a@sam)6&gt; mnesia:activity(sync_dirty, Write, [lists:seq(1, 256)], mnesia_frag).
ok
(a@sam)7&gt; mnesia:change_table_frag(Tab, {activate, []}).
{atomic,ok}
(a@sam)8&gt; mnesia:table_info(Tab, frag_properties).
[{base_table,dictionary},
 {foreign_key,undefined},
 {n_doubles,0},
 {n_fragments,1},
 {next_n_to_split,1},
 {node_pool,[a@sam,b@sam,c@sam]}]
(a@sam)9&gt; Info = fun(Item) -&gt; mnesia:table_info(Tab, Item) end.
#Fun&lt;erl_eval&gt;
(a@sam)10&gt; Dist = mnesia:activity(sync_dirty, Info, [frag_dist], mnesia_frag).
[{c@sam,0},{a@sam,1},{b@sam,1}]
(a@sam)11&gt; mnesia:change_table_frag(Tab, {add_frag, Dist}).
{atomic,ok}
(a@sam)12&gt; Dist2 = mnesia:activity(sync_dirty, Info, [frag_dist], mnesia_frag).
[{b@sam,1},{c@sam,1},{a@sam,2}]
(a@sam)13&gt; mnesia:change_table_frag(Tab, {add_frag, Dist2}).
{atomic,ok}
(a@sam)14&gt; Dist3 = mnesia:activity(sync_dirty, Info, [frag_dist], mnesia_frag).
[{a@sam,2},{b@sam,2},{c@sam,2}]
(a@sam)15&gt; mnesia:change_table_frag(Tab, {add_frag, Dist3}).
{atomic,ok}
(a@sam)16&gt; Read = fun(Key) -&gt; mnesia:read({Tab, Key}) end.
#Fun&lt;erl_eval&gt;
(a@sam)17&gt; mnesia:activity(transaction, Read, [12], mnesia_frag).
[{dictionary,12,-12}]
(a@sam)18&gt; mnesia:activity(sync_dirty, Info, [frag_size], mnesia_frag).
[{dictionary,64},
 {dictionary_frag2,64},
 {dictionary_frag3,64},
 {dictionary_frag4,64}]
(a@sam)19&gt; 
      </code></pre><h3>Fragmentation Properties</h3><p>The table property <strong>frag_properties</strong> can be read with
the function
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, frag_properties)</a>.
The fragmentation properties are a list of tagged tuples with
arity 2. By default the list is empty, but when it is
non-empty it triggers <strong>Mnesia</strong> to regard the table as
fragmented. The fragmentation properties are as follows:</p><dl><dt><strong>{n_fragments, Int}</strong></dt><dd> <p><strong>n_fragments</strong> regulates how many fragments
that the table currently has. This property can explicitly
be set at table creation and later be changed with
<strong>{add_frag, NodesOrDist}</strong> or
<strong>del_frag</strong>. <strong>n_fragments</strong> defaults to <strong>1</strong>.</p> </dd><dt><strong>{node_pool, List}</strong></dt><dd> <p>The node pool contains a list of nodes and can
explicitly be set at table creation and later be changed
with <strong>{add_node, Node}</strong> or <strong>{del_node, Node}</strong>.
At table creation <strong>Mnesia</strong> tries to distribute
the replicas of each fragment evenly over all the nodes in
the node pool. Hopefully all nodes end up with the
same number of replicas. <strong>node_pool</strong> defaults to the
return value from the function
<a href="./mnesia#system_info/1">mnesia:system_info(db_nodes)</a>.</p> </dd><dt><strong>{n_ram_copies, Int}</strong></dt><dd> <p>Regulates how many <strong>ram_copies</strong> replicas
that each fragment is to have. This property can
explicitly be set at table creation. Defaults is
<strong>0</strong>, but if <strong>n_disc_copies</strong> and
<strong>n_disc_only_copies</strong> also are <strong>0</strong>,
<strong>n_ram_copies</strong> defaults to <strong>1</strong>.</p> </dd><dt><strong>{n_disc_copies, Int}</strong></dt><dd> <p>Regulates how many <strong>disc_copies</strong> replicas that
each fragment is to have. This property can explicitly
be set at table creation. Default is <strong>0</strong>.</p> </dd><dt><strong>{n_disc_only_copies, Int}</strong></dt><dd> <p>Regulates how many <strong>disc_only_copies</strong> replicas
that each fragment is to have. This property can
explicitly be set at table creation. Defaults is
<strong>0</strong>.</p> </dd><dt><strong>{foreign_key, ForeignKey}</strong></dt><dd> <p><strong>ForeignKey</strong> can either be the atom
<strong>undefined</strong> or the tuple <strong>{ForeignTab, Attr}</strong>,
where <strong>Attr</strong> denotes an attribute that is to be
interpreted as a key in another fragmented table named
<strong>ForeignTab</strong>. <strong>Mnesia</strong> ensures that the number of
fragments in this table and in the foreign table are
always the same.</p> <p>When fragments are added or deleted, <strong>Mnesia</strong>
automatically propagates the operation to all
fragmented tables that have a foreign key referring to this
table. Instead of using the record key to determine which
fragment to access, the value of field  <strong>Attr</strong> is
used. This feature makes it possible to colocate records
automatically in different tables to the same node.
<strong>foreign_key</strong> defaults to
<strong>undefined</strong>. However, if the foreign key is set to
something else, it causes the default values of the
other fragmentation properties to be the same values as
the actual fragmentation properties of the foreign table.</p> </dd><dt><strong>{hash_module, Atom}</strong></dt><dd> <p>Enables definition of an alternative hashing scheme.
The module must implement the
<a href="mnesia_frag_hash">mnesia_frag_hash</a>
callback behavior. This property can explicitly be set at
table creation. Default is <strong>mnesia_frag_hash</strong>.</p> </dd><dt><strong>{hash_state, Term}</strong></dt><dd> <p>Enables a table-specific parameterization of a
generic hash module. This property can explicitly be set
at table creation. Default is <strong>undefined</strong>.</p> <pre><code class="">
Eshell V4.7.3.3  (abort with ^G)
(a@sam)1&gt; mnesia:start().
ok
(a@sam)2&gt; PrimProps = [{n_fragments, 7}, {node_pool, [node()]}].
[{n_fragments,7},{node_pool,[a@sam]}]
(a@sam)3&gt; mnesia:create_table(prim_dict, 
                              [{frag_properties, PrimProps},
                               {attributes,[prim_key,prim_val]}]).
{atomic,ok}
(a@sam)4&gt; SecProps = [{foreign_key, {prim_dict, sec_val}}].
[{foreign_key,{prim_dict,sec_val}}]
(a@sam)5&gt; mnesia:create_table(sec_dict, 
                              [{frag_properties, SecProps},
(a@sam)5&gt;                      {attributes, [sec_key, sec_val]}]).
{atomic,ok}
(a@sam)6&gt; Write = fun(Rec) -&gt; mnesia:write(Rec) end.
#Fun&lt;erl_eval&gt;
(a@sam)7&gt; PrimKey = 11.
11
(a@sam)8&gt; SecKey = 42.
42
(a@sam)9&gt; mnesia:activity(sync_dirty, Write,
                          [{prim_dict, PrimKey, -11}], mnesia_frag).
ok
(a@sam)10&gt; mnesia:activity(sync_dirty, Write,
                           [{sec_dict, SecKey, PrimKey}], mnesia_frag).
ok
(a@sam)11&gt; mnesia:change_table_frag(prim_dict, {add_frag, [node()]}).
{atomic,ok}
(a@sam)12&gt; SecRead = fun(PrimKey, SecKey) -&gt;
               mnesia:read({sec_dict, PrimKey}, SecKey, read) end.
#Fun&lt;erl_eval&gt;
(a@sam)13&gt; mnesia:activity(transaction, SecRead,
                           [PrimKey, SecKey], mnesia_frag).
[{sec_dict,42,11}]
(a@sam)14&gt; Info = fun(Tab, Item) -&gt; mnesia:table_info(Tab, Item) end.
#Fun&lt;erl_eval&gt;
(a@sam)15&gt; mnesia:activity(sync_dirty, Info,
                           [prim_dict, frag_size], mnesia_frag).
[{prim_dict,0},
 {prim_dict_frag2,0},
 {prim_dict_frag3,0},
 {prim_dict_frag4,1},
 {prim_dict_frag5,0},
 {prim_dict_frag6,0},
 {prim_dict_frag7,0},
 {prim_dict_frag8,0}]
(a@sam)16&gt; mnesia:activity(sync_dirty, Info,
                           [sec_dict, frag_size], mnesia_frag).
[{sec_dict,0},
 {sec_dict_frag2,0},
 {sec_dict_frag3,0},
 {sec_dict_frag4,1},
 {sec_dict_frag5,0},
 {sec_dict_frag6,0},
 {sec_dict_frag7,0},
 {sec_dict_frag8,0}]
(a@sam)17&gt;
          </code></pre> </dd></dl><h3>Management of Fragmented Tables</h3><p>The function <strong>mnesia:change_table_frag(Tab, Change)</strong>
is intended to be used for reconfiguration of fragmented
tables. Argument <strong>Change</strong> is to have one of the
following values:</p><dl><dt><strong>{activate, FragProps}</strong></dt><dd> <p>Activates the fragmentation properties of an
existing table. <strong>FragProps</strong> is either to contain
<strong>{node_pool, Nodes}</strong> or be empty.</p> </dd><dt><strong>deactivate</strong></dt><dd> <p>Deactivates the fragmentation properties of a
table. The number of fragments must be <strong>1</strong>. No other
table can refer to this table in its foreign key.</p> </dd><dt><strong>{add_frag, NodesOrDist}</strong></dt><dd> <p>Adds a fragment to a fragmented table. All
records in one of the old fragments are rehashed and
about half of them are moved to the new (last)
fragment. All other fragmented tables, which refer to this
table in their foreign key, automatically get a new
fragment. Also, their records are dynamically
rehashed in the same manner as for the main table.</p> <p>Argument <strong>NodesOrDist</strong> can either be a list of
nodes or the result from the function
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, frag_dist)</a>.
Argument <strong>NodesOrDist</strong> is
assumed to be a sorted list with the best nodes to
host new replicas first in the list. The new fragment
gets the same number of replicas as the first
fragment (see <strong>n_ram_copies</strong>, <strong>n_disc_copies</strong>,
and <strong>n_disc_only_copies</strong>). The <strong>NodesOrDist</strong>
list must at least contain one element for each
replica that needs to be allocated.</p> </dd><dt><strong>del_frag</strong></dt><dd> <p>Deletes a fragment from a fragmented table. All
records in the last fragment are  moved to one of the other
fragments. All other fragmented tables, which refer to
this table in their foreign key, automatically lose
their last fragment. Also, their records are
dynamically rehashed in the same manner as for the main
table.</p> </dd><dt><strong>{add_node, Node}</strong></dt><dd> <p>Adds a node to <strong>node_pool</strong>. The new
node pool affects the list returned from the function
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, frag_dist)</a>.
</p> </dd><dt><strong>{del_node, Node}</strong></dt><dd> <p>Deletes a node from <strong>node_pool</strong>. The new
node pool affects the list returned from the function
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, frag_dist)</a>.
</p> </dd></dl><h3>Extensions of Existing Functions</h3><p>The function
<a href="./mnesia#create_table/2">mnesia:create_table/2</a>
creates a brand new fragmented table, by setting table
property <strong>frag_properties</strong> to some proper values.</p><p>The function
<a href="./mnesia#delete_table/1">mnesia:delete_table/1</a>
deletes a fragmented table including all its
fragments. There must however not exist any other fragmented
tables that refer to this table in their foreign key.</p><p>The function
<a href="./mnesia#table_info/2">mnesia:table_info/2</a>
now understands item <strong>frag_properties</strong>.</p><p>If the function <strong>mnesia:table_info/2</strong> is started in
the activity context of module <strong>mnesia_frag</strong>,
information of several new items can be obtained:</p><dl><dt><strong>base_table</strong></dt><dd>The name of the fragmented table</dd><dt><strong>n_fragments</strong></dt><dd>The actual number of fragments</dd><dt><strong>node_pool</strong></dt><dd>The pool of nodes</dd><dt><strong>n_ram_copies</strong></dt><dd></dd><dt><strong>n_disc_copies</strong></dt><dd></dd><dt><strong>n_disc_only_copies</strong></dt><dd> <p>The number of replicas with storage type <strong>ram_copies</strong>,
<strong>disc_copies</strong>, and <strong>disc_only_copies</strong>,
respectively. The actual values are dynamically derived
from the first fragment. The first fragment serves as a
protype. When the actual values need to be computed
(for example, when adding new fragments) they are
determined by counting the number of each replica for
each storage type. This means that when the functions
<a href="./mnesia#add_table_copy/3">mnesia:add_table_copy/3</a>,
<a href="./mnesia#del_table_copy/2">mnesia:del_table_copy/2</a>,
and
<a href="./mnesia#change_table_copy_type/3">mnesia:change_table_copy_type/2</a> are applied on the
first fragment, it affects the settings on
<strong>n_ram_copies</strong>, <strong>n_disc_copies</strong>, and
<strong>n_disc_only_copies</strong>.</p> </dd><dt><strong>foreign_key</strong></dt><dd> <p>The foreign key</p> </dd><dt><strong>foreigners</strong></dt><dd> <p>All other tables that refer to this table in
their foreign key</p> </dd><dt><strong>frag_names</strong></dt><dd> <p>The names of all fragments</p> </dd><dt><strong>frag_dist</strong></dt><dd> <p>A sorted list of <strong>{Node, Count}</strong> tuples
that are sorted in increasing <strong>Count</strong> order.
<strong>Count</strong> is the total number of replicas that this
fragmented table hosts on each <strong>Node</strong>. The list
always contains at least all nodes in
<strong>node_pool</strong>. Nodes that do not belong to
<strong>node_pool</strong> are put last in the list even if
their <strong>Count</strong> is lower.</p> </dd><dt><strong>frag_size</strong></dt><dd> <p>A list of <strong>{Name, Size}</strong> tuples, where
<strong>Name</strong> is a fragment <strong>Name</strong>, and <strong>Size</strong> is
how many records it contains</p> </dd><dt><strong>frag_memory</strong></dt><dd> <p>A list of <strong>{Name, Memory}</strong> tuples, where
<strong>Name</strong> is a fragment <strong>Name</strong>, and <strong>Memory</strong> is
how much memory it occupies</p> </dd><dt><strong>size</strong></dt><dd> <p>Total size of all fragments</p> </dd><dt><strong>memory</strong></dt><dd> <p>Total memory of all fragments</p> </dd></dl><h3>Load Balancing</h3><p>There are several algorithms for distributing records
in a fragmented table evenly over a
pool of nodes. No one is best, it depends on the
application needs. The following examples of
situations need some attention:</p><ul><li><strong>permanent change of nodes</strong>. When a new permanent <strong>db_node</strong> is introduced or dropped, it can be time to change the pool of nodes and redistribute the replicas evenly over the new pool of nodes. It can also be time to add or delete a fragment before the replicas are redistributed. </li><li><strong>size/memory threshold</strong>. When the total size or total memory of a fragmented table (or a single fragment) exceeds some application-specific threshold, it can be time to add a new fragment dynamically to obtain a better distribution of records. </li><li><strong>temporary node down</strong>. When a node temporarily goes down, it can be time to compensate some fragments with new replicas to keep the desired level of redundancy. When the node comes up again, it can be time to remove the superfluous replica. </li><li><strong>overload threshold</strong>. When the load on some node exceeds some application-specific threshold, it can be time to either add or move some fragment replicas to nodes with lower load. Take extra care if the table has a foreign key relation to some other table. To avoid severe performance penalties, the same redistribution must be performed for all the related tables. </li></ul><p>Use the function
<strong>mnesia:change_table_frag/2</strong> to add new fragments
and apply the usual schema manipulation functions (such as
<a href="./mnesia#add_table_copy/3">mnesia:add_table_copy/3</a>,
<a href="./mnesia#del_table_copy/2">mnesia:del_table_copy/2</a>,
and
<a href="./mnesia#change_table_copy_type/3">mnesia:change_table_copy_type/2</a>)
on each fragment to perform the actual redistribution.</p><h3>Local Content Tables</h3><p>Replicated tables have the same content on all nodes where
they are replicated. However, it is sometimes advantageous to
have tables, but different content on different nodes.</p><p>If attribute <strong>{local_content, true}</strong> is specified when
you create the table, the table resides on the nodes where you
specify the table to exist, but the write operations on the
table are only performed on the local copy.</p><p>Furthermore, when the table is initialized at startup, the
table is only initialized locally, and the table
content is not copied from another node.</p><h3>Disc-Less Nodes</h3><p><strong>Mnesia</strong> can be run on nodes that do not have a disc.
Replicas of <strong>disc_copies</strong> or <strong>disc_only_copies</strong> are
not possible on such nodes. This is especially troublesome for
the <strong>schema</strong> table, as <strong>Mnesia</strong> needs the schema
to initialize itself.</p><p>The schema table can, as other tables, reside on one or
more nodes. The storage type of the schema table can either
be <strong>disc_copies</strong> or <strong>ram_copies</strong>
(but not <strong>disc_only_copies</strong>). At
startup, <strong>Mnesia</strong> uses its schema to determine with which
nodes it is to try to establish contact. If any
other node is started already, the starting node
merges its table definitions with the table definitions
brought from the other nodes. This also applies to the
definition of the schema table itself. Application
parameter <strong>extra_db_nodes</strong> contains a list of nodes that
<strong>Mnesia</strong> also is to establish contact with besides those
found in the schema. Default is <strong>[]</strong> (empty list).</p><p>Hence, when a disc-less node needs to find the schema
definitions from a remote node on the network, this
information must be supplied through application parameter
<strong>-mnesia extra_db_nodes NodeList</strong>. Without this
configuration parameter set, <strong>Mnesia</strong> starts as a single
node system. Also, the function
<a href="./mnesia#change_config/2">mnesia:change_config/2</a>
can be used to assign a value to <strong>extra_db_nodes</strong> and force
a connection after <strong>Mnesia</strong> has been started, that is,
<strong>mnesia:change_config(extra_db_nodes, NodeList)</strong>.</p><p>Application parameter <strong>schema_location</strong> controls where
<strong>Mnesia</strong> searches for its schema. The parameter can be one
of the following atoms:</p><dl><dt><strong>disc</strong></dt><dd> <p>Mandatory disc. The schema is assumed to be located
in the <strong>Mnesia</strong> directory. If the schema cannot be found,
<strong>Mnesia</strong> refuses to start.</p> </dd><dt><strong>ram</strong></dt><dd> <p>Mandatory RAM. The schema resides in RAM
only. At startup, a tiny new schema is generated. This
default schema contains only the definition of the schema
table and resides on the local node only. Since no other
nodes are found in the default schema, configuration
parameter <strong>extra_db_nodes</strong> must be used to let the
node share its table definitions with other nodes. (Parameter
<strong>extra_db_nodes</strong> can also be used on disc-full nodes.)</p> </dd><dt><strong>opt_disc</strong></dt><dd> <p>Optional disc. The schema can reside on either disc or
RAM. If the schema is found on disc, <strong>Mnesia</strong> starts as
a disc-full node (the storage type of the schema table is
disc_copies). If no schema is found on disc, <strong>Mnesia</strong>
starts as a disc-less node (the storage type of the schema
table is <strong>ram_copies</strong>). The default for the
application parameter is <strong>opt_disc</strong>.</p> </dd></dl><p>When <strong>schema_location</strong> is set to <strong>opt_disc</strong>, the
function
<a href="./mnesia#change_table_copy_type/3">mnesia:change_table_copy_type/3</a>
can be used to change the storage type of the schema.
This is illustrated as follows:</p><pre>
        1&gt; mnesia:start().
        ok
        2&gt; mnesia:change_table_copy_type(schema, node(), disc_copies).
        {atomic, ok}</pre><p>Assuming that the call to
<a href="./mnesia#start/0">mnesia:start/0</a> does not
find any schema to read on the disc, <strong>Mnesia</strong> starts
as a disc-less node, and then change it to a node that
use the disc to store the schema locally.</p><h3>More about Schema Management</h3><p>Nodes can be added to and removed from a <strong>Mnesia</strong> system.
This can be done by adding a copy of the schema to those nodes.</p><p>The functions
<a href="./mnesia#add_table_copy/3">mnesia:add_table_copy/3</a>
and
<a href="./mnesia#del_table_copy/2">mnesia:del_table_copy/2</a>
can be used to add and delete
replicas of the schema table. Adding a node to the list of
nodes where the schema is replicated affects the following:</p><ul><li>It allows other tables to be replicated to this node. </li><li>It causes <strong>Mnesia</strong> to try to contact the node at startup of disc-full nodes. </li></ul><p>The function call <strong>mnesia:del_table_copy(schema, mynode@host)</strong> deletes node <strong>mynode@host</strong> from the
<strong>Mnesia</strong> system. The call fails if <strong>Mnesia</strong> is running
on <strong>mynode@host</strong>. The other <strong>Mnesia</strong> nodes never try to
connect to that node again. Notice that if there is a disc resident
schema on node <strong>mynode@host</strong>, the entire <strong>Mnesia</strong>
directory is to be deleted. This is done with the function
<a href="./mnesia#delete_schema/1">mnesia:delete_schema/1</a>.
If <strong>Mnesia</strong> is started again
on node <strong>mynode@host</strong> and the directory has not been
cleared, the behavior of <strong>Mnesia</strong> is undefined.</p><p>If the storage type of the schema is <strong>ram_copies</strong>,
that is, a disc-less node, <strong>Mnesia</strong>
does not use the disc on that particular node. The disc
use is enabled by changing the storage type of table
<strong>schema</strong> to <strong>disc_copies</strong>.</p><p>New schemas are created explicitly with the function
<a href="./mnesia#create_schema/1">mnesia:create_schema/1</a>
or implicitly by starting
<strong>Mnesia</strong> without a disc resident schema. Whenever
a table (including the schema table) is created, it is
assigned its own unique cookie. The schema table is not created
with the function
<a href="./mnesia#create_table/2">mnesia:create_table/2</a>
as normal tables.</p><p>At startup, <strong>Mnesia</strong> connects different nodes to each other,
then they exchange table definitions with each other, and the table
definitions are merged. During the merge procedure, <strong>Mnesia</strong>
performs a sanity test to ensure that the table definitions are
compatible with each other. If a table exists on several nodes,
the cookie must be the same, otherwise <strong>Mnesia</strong> shut down one
of the nodes. This unfortunate situation occurs if a table
has been created on two nodes independently of each other while
they were disconnected. To solve this, one of the tables
must be deleted (as the cookies differ, it is regarded to be two
different tables even if they have the same name).</p><p>Merging different versions of the schema table does not
always require the cookies to be the same. If the storage
type of the schema table is <strong>disc_copies</strong>, the cookie is
immutable, and all other <strong>db_nodes</strong> must have the same
cookie. When the schema is stored as type <strong>ram_copies</strong>,
its cookie can be replaced with a cookie from another node
(<strong>ram_copies</strong> or <strong>disc_copies</strong>). The cookie replacement
(during merge of the schema table definition) is performed each
time a RAM node connects to another node.</p><p>Further, the following applies:</p><ul><li><a href="./mnesia#system_info/1">mnesia:system_info(schema_location)</a> and <a href="./mnesia#system_info/1">mnesia:system_info(extra_db_nodes)</a> can be used to determine the actual values of <strong>schema_location</strong> and <strong>extra_db_nodes</strong>, respectively. </li><li><a href="./mnesia#system_info/1">mnesia:system_info(use_dir)</a> can be used to determine whether <strong>Mnesia</strong> is actually using the <strong>Mnesia</strong> directory. </li><li><strong>use_dir</strong> can be determined even before <strong>Mnesia</strong> is started. </li></ul><p>The function <a href="./mnesia#info/0">mnesia:info/0</a>
can now be used to print
some system information even before <strong>Mnesia</strong> is started.
When <strong>Mnesia</strong> is started, the function prints more
information.</p><p>Transactions that update the definition of a table
requires that <strong>Mnesia</strong> is started on all nodes where the
storage type of the schema is <strong>disc_copies</strong>. All replicas of
the table on these nodes must also be loaded. There are a
few exceptions to these availability rules:</p><ul><li>Tables can be created and new replicas can be added without starting all the disc-full nodes. </li><li>New replicas can be added before all other replicas of the table have been loaded, provided that at least one other replica is active. </li></ul><a name="event_handling"></a><h3>Mnesia Event Handling</h3><p>System events and table events are the two event categories
that <strong>Mnesia</strong> generates in various situations.</p><p>A user process can subscribe on the events generated by
<strong>Mnesia</strong>. The following two functions are provided:</p><dl><dt><a href="./mnesia#subscribe/1">mnesia:subscribe(Event-Category)</a> </dt><dd>Ensures that a copy of all events of type <strong>Event-Category</strong> are sent to the calling process</dd><dt><a href="./mnesia#unsubscribe/1">mnesia:unsubscribe(Event-Category)</a> </dt><dd>Removes the subscription on events of type <strong>Event-Category</strong> </dd></dl><p><strong>Event-Category</strong> can be either of the following:</p><ul><li>The atom <strong>system</strong> </li><li>The atom <strong>activity</strong> </li><li>The tuple <strong>{table, Tab, simple}</strong> </li><li>The tuple <strong>{table, Tab, detailed}</strong> </li></ul><p>The old event category <strong>{table, Tab}</strong> is the same
event category as <strong>{table, Tab, simple}</strong>.</p><p>The subscribe functions activate a subscription
of events. The events are delivered as messages to the process
evaluating the function
<a href="./mnesia#subscribe/1">mnesia:subscribe/1</a>
The syntax is as follows:</p><ul><li><strong>{mnesia_system_event, Event}</strong> for system events </li><li><strong>{mnesia_activity_event, Event}</strong> for activity events </li><li><strong>{mnesia_table_event, Event}</strong> for table events </li></ul><p>The event types are described in the next sections.</p><p>All system events are subscribed by the <strong>Mnesia</strong>
<strong>gen_event</strong> handler. The default <strong>gen_event</strong> handler
is <strong>mnesia_event</strong>, but it can be changed by using
application parameter <strong>event_module</strong>. The value of this
parameter must be the name of a module implementing a complete
handler, as specified by the
<a href="./gen_event">gen_event</a> module
in <strong>STDLIB</strong>.</p><p><a href="./mnesia#system_info/1">mnesia:system_info(subscribers)</a>
and
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, subscribers)</a>
can be used to determine which processes are subscribed to
various events.</p><h3>System Events</h3><p>The system events are as follows:</p><dl><dt><strong>{mnesia_up, Node}</strong></dt><dd>Mnesia is started on a node. <strong>Node</strong> is the node name. By default this event is ignored. </dd><dt><strong>{mnesia_down, Node}</strong></dt><dd>Mnesia is stopped on a node. <strong>Node</strong> is the node name. By default this event is ignored. </dd><dt><strong>{mnesia_checkpoint_activated, Checkpoint}</strong></dt><dd>A checkpoint with the name <strong>Checkpoint</strong> is activated and the current node is involved in the checkpoint. Checkpoints can be activated explicitly with the function <a href="./mnesia#activate_checkpoint/1">mnesia:activate_checkpoint/1</a> or implicitly at backup, when adding table replicas, at internal transfer of data between nodes, and so on. By default this event is ignored. </dd><dt><strong>{mnesia_checkpoint_deactivated, Checkpoint}</strong></dt><dd>A checkpoint with the name <strong>Checkpoint</strong> is deactivated and the current node is involved in the checkpoint. Checkpoints can be deactivated explicitly with the function <a href="./mnesia#deactivate_checkpoint/1">mnesia:deactivate/1</a> or implicitly when the last replica of a table (involved in the checkpoint) becomes unavailable, for example, at node-down. By default this event is ignored. </dd><dt><strong>{mnesia_overload, Details}</strong></dt><dd><p><strong>Mnesia</strong> on the current node is
overloaded and the subscriber is to take action.</p> <p>A typical overload situation occurs when the
applications perform more updates on disc resident
tables than <strong>Mnesia</strong> can handle. Ignoring
this kind of overload can lead to a situation where
the disc space is exhausted (regardless of the size of
the tables stored on disc).</p> <p>Each update is appended to the transaction log and
occasionally (depending on how it
is configured) dumped to the tables files. The
table file storage is more compact than the transaction
log storage, especially if the same record is updated
repeatedly. If the thresholds for dumping the
transaction log are reached before the previous
dump is finished, an overload event is triggered.</p> <p>Another typical overload situation is when the
transaction manager cannot commit transactions at the
same pace as the applications perform updates of
disc resident tables. When this occurs, the message
queue of the transaction manager continues to grow
until the memory is exhausted or the load
decreases.</p> <p>The same problem can occur for dirty updates. The overload
is detected locally on the current node, but its cause can
be on another node. Application processes can cause high
load if any table resides on another node (replicated
or not). By default this event
is reported to <strong>error_logger.</strong></p> </dd><dt><strong>{inconsistent_database, Context, Node}</strong></dt><dd><strong>Mnesia</strong> regards the database as potential inconsistent and gives its applications a chance to recover from the inconsistency. For example, by installing a consistent backup as fallback and then restart the system. An alternative is to pick a <strong>MasterNode</strong> from <a href="./mnesia#system_info/1">mnesia:system_info(db_nodes)</a> and invoke <a href="./mnesia#set_master_nodes/1">mnesia:set_master_node([MasterNode])</a>. By default an error is reported to <strong>error_logger</strong>. </dd><dt><strong>{mnesia_fatal, Format, Args, BinaryCore}</strong></dt><dd> <p><strong>Mnesia</strong> detected a fatal error and
terminates soon. The fault reason is explained in
<strong>Format</strong> and <strong>Args</strong>, which can be given as input
to <strong>io:format/2</strong> or sent to <strong>error_logger</strong>. By
default it is sent to <strong>error_logger</strong>.</p> <p><strong>BinaryCore</strong> is a binary containing a summary of the
<strong>Mnesia</strong> internal state at the time when the fatal
error was detected. By default the binary is written to a
unique filename on the current directory. On RAM nodes, the
core is ignored.</p> </dd><dt><strong>{mnesia_info, Format, Args}</strong></dt><dd><strong>Mnesia</strong> detected something that can be of interest when debugging the system. This is explained in <strong>Format</strong> and <strong>Args</strong>, which can appear as input to <strong>io:format/2</strong> or sent to <strong>error_logger</strong>. By default this event is printed with <strong>io:format/2</strong>. </dd><dt><strong>{mnesia_error, Format, Args}</strong></dt><dd><strong>Mnesia</strong> has detected an error. The fault reason is explained in <strong>Format</strong> and <strong>Args</strong>, which can be given as input to <strong>io:format/2</strong> or sent to <strong>error_logger</strong>. By default this event is reported to <strong>error_logger</strong>. </dd><dt><strong>{mnesia_user, Event}</strong></dt><dd>An application started the function <a href="./mnesia#report_event/1">mnesia:report_event(Event)</a>. <strong>Event</strong> can be any Erlang data structure. When tracing a system of <strong>Mnesia</strong> applications, it is useful to be able to interleave own events of <strong>Mnesia</strong> with application-related events that give information about the application context. Whenever the application starts with a new and demanding <strong>Mnesia</strong> activity, or enters a new and interesting phase in its execution, it can be a good idea to use <strong>mnesia:report_event/1</strong>. </dd></dl><h3>Activity Events</h3><p>Currently, there is only one type of activity event:</p><dl><dt><strong>{complete, ActivityID}</strong></dt><dd> <p>This event occurs when a transaction that caused a modification
to the database is completed. It is useful for determining when
a set of table events (see the next section), caused by a given
activity, have been sent. Once this event is received, it is
guaranteed that no further table events with the same
<strong>ActivityID</strong> will be received. Notice that this event can
still be received even if no table events with a corresponding
<strong>ActivityID</strong> were received, depending on
the tables to which the receiving process is subscribed.</p> <p>Dirty operations always contain only one update and thus no
activity event is sent.</p> </dd></dl><h3>Table Events</h3><p>Table events are events related to table updates. There are
two types of table events, simple and detailed.</p><p>The <em>simple table events</em> are tuples like
<strong>{Oper, Record, ActivityId}</strong>, where:</p><ul><li><strong>Oper</strong> is the operation performed. </li><li><strong>Record</strong> is the record involved in the operation. </li><li><strong>ActivityId</strong> is the identity of the transaction performing the operation. </li></ul><p>Notice that the record name is the table name even when
<strong>record_name</strong> has another setting.</p><p>The table-related events that can occur are as follows:</p><dl><dt><strong>{write, NewRecord, ActivityId}</strong></dt><dd>A new record has been written. <strong>NewRecord</strong> contains the new record value. </dd><dt><strong>{delete_object, OldRecord, ActivityId}</strong></dt><dd>A record has possibly been deleted with <a href="./mnesia#delete_object/1">mnesia:delete_object/1</a>. <strong>OldRecord</strong> contains the value of the old record, as stated as argument by the application. Notice that other records with the same key can remain in the table if it is of type <strong>bag</strong>. </dd><dt><strong>{delete, {Tab, Key}, ActivityId}</strong></dt><dd>One or more records have possibly been deleted. All records with the key <strong>Key</strong> in the table <strong>Tab</strong> have been deleted. </dd></dl><p>The <em>detailed table events</em> are tuples like
<strong>{Oper, Table, Data, [OldRecs], ActivityId}</strong>, where:</p><ul><li><strong>Oper</strong> is the operation performed. </li><li><strong>Table</strong> is the table involved in the operation. </li><li><strong>Data</strong> is the record/OID written/deleted. </li><li><strong>OldRecs</strong> is the contents before the operation. </li><li><strong>ActivityId</strong> is the identity of the transaction performing the operation. </li></ul><p>The table-related events that can occur are as follows:</p><dl><dt><strong>{write, Table, NewRecord, [OldRecords], ActivityId}</strong></dt><dd>A new record has been written. <strong>NewRecord</strong> contains the new record value and <strong>OldRecords</strong> contains the records before the operation is performed. Notice that the new content depends on the table type. </dd><dt><strong>{delete, Table, What, [OldRecords], ActivityId}</strong></dt><dd>Records have possibly been deleted. <strong>What</strong> is either <strong>{Table, Key}</strong> or a record <strong>{RecordName, Key, ...}</strong> that was deleted. Notice that the new content depends on the table type. </dd></dl><h3>Debugging Mnesia Applications</h3><p>Debugging a <strong>Mnesia</strong> application can be difficult
for various reasons, primarily related
to difficulties in understanding how the transaction
and table load mechanisms work. Another source of
confusion can be the semantics of nested transactions.</p><p>The debug level of <strong>Mnesia</strong> is set by calling the function
<a href="./mnesia#set_debug_level/1">mnesia:set_debug_level(Level)</a>,
where <strong>Level</strong>is one of the following:</p><dl><dt><strong>none</strong></dt><dd>No trace outputs. This is the default. </dd><dt><strong>verbose</strong></dt><dd>Activates tracing of important debug events. These events generate <strong>{mnesia_info, Format, Args}</strong> system events. Processes can subscribe to these events with the function <a href="./mnesia#subscribe/1">mnesia:subscribe/1</a>. The events are always sent to the <strong>Mnesia</strong> event handler. </dd><dt><strong>debug</strong></dt><dd>Activates all events at the verbose level plus traces of all debug events. These debug events generate <strong>{mnesia_info, Format, Args}</strong> system events. Processes can subscribe to these events with <strong>mnesia:subscribe/1</strong>. The events are always sent to the <strong>Mnesia</strong> event handler. On this debug level, the <strong> Mnesia</strong> event handler starts subscribing to updates in the schema table. </dd><dt><strong>trace</strong></dt><dd>Activates all events at the debug level. On this level, the <strong>Mnesia</strong> event handler starts subscribing to updates on all <strong>Mnesia</strong> tables. This level is intended only for debugging small toy systems, as many large events can be generated. </dd><dt><strong>false</strong></dt><dd>An alias for none. </dd><dt><strong>true</strong></dt><dd>An alias for debug. </dd></dl><p>The debug level of <strong>Mnesia</strong> itself is also an application
parameter, making it possible to start an Erlang system
to turn on <strong>Mnesia</strong> debug in the initial
startup phase by using the following code:</p><pre>
      % erl -mnesia debug verbose</pre><h3>Concurrent Processes in Mnesia</h3><p>Programming concurrent Erlang systems is the subject of
a separate book. However, it is worthwhile to draw attention to
the following features, which permit concurrent processes to
exist in a <strong>Mnesia</strong> system:</p><ul><li><p>A group of functions or processes can be called within a
transaction. A transaction can include statements that read,
write, or delete data from the DBMS. Many such
transactions can run concurrently, and the programmer does not
need to explicitly synchronize the processes that manipulate
the data.</p> <p>All programs accessing the database through the
transaction system can be written as if they had sole access to
the data. This is a desirable property, as all
synchronization is taken care of by the transaction handler. If
a program reads or writes data, the system ensures that no other
program tries to manipulate the same data at the same time.</p> </li><li>Tables can be moved or deleted, and the layout of a table can be reconfigured in various ways. An important aspect of the implementation of these functions is that user programs can continue to use a table while it is being reconfigured. For example, it is possible to move a table and perform write operations to the table at the same time. This is important for many applications that require continuously available services. For more information, see <a href="./Mnesia_chap4#trans_prop">Transactions and Other Access Contexts</a>. </li></ul><h3>Prototyping</h3><p>If and when you would like to start and manipulate
<strong>Mnesia</strong>, it is often easier to write the definitions and
data into an ordinary text file.
Initially, no tables and no data exist, or which
tables are required. At the initial stages of prototyping, it
is prudent to write all data into one file, process that
file, and have the data in the file inserted into the database.
<strong>Mnesia</strong> can be initialized with data read from a text file.
The following two functions can be used to work with text
files.</p><ul><li> <a href="./mnesia#load_textfile/1">mnesia:load_textfile(Filename)</a> loads a series of local table definitions and data found in the file into <strong>Mnesia</strong>. This function also starts <strong>Mnesia</strong> and possibly creates a new schema. The function operates on the local node only. </li><li> <a href="./mnesia#dump_to_textfile/1">mnesia:dump_to_textfile(Filename)</a> dumps all local tables of a <strong>Mnesia</strong> system into a text file, which can be edited (with a normal text editor) and later reloaded. </li></ul><p>These functions are much slower than the ordinary store and
load functions of <strong>Mnesia</strong>. However, this is mainly intended
for minor experiments and initial prototyping. The major
advantage of these functions is that they are easy to use.</p><p>The format of the text file is as follows:</p><pre>
      {tables, [{Typename, [Options]},
      {Typename2 ......}]}.
      
      {Typename, Attribute1, Attribute2 ....}.
      {Typename, Attribute1, Attribute2 ....}.</pre><p><strong>Options</strong> is a list of <strong>{Key,Value}</strong> tuples conforming
to the options that you can give to
<a href="./mnesia#create_table/2">mnesia:create_table/2</a>.
</p><p>For example, to start playing with a small database for healthy
foods, enter the following data into file <strong>FRUITS</strong>:</p><pre><code class="">

{tables,
 [{fruit, [{attributes, [name, color, taste]}]},
  {vegetable, [{attributes, [name, color, taste, price]}]}]}.


{fruit, orange, orange, sweet}.
{fruit, apple, green, sweet}.
{vegetable, carrot, orange, carrotish, 2.55}.
{vegetable, potato, yellow, none, 0.45}.</code></pre><p>The following session with the Erlang shell shows how
to load the <strong>FRUITS</strong> database:</p><pre>
      % erl
      Erlang (BEAM) emulator version 4.9
 
      Eshell V4.9  (abort with ^G)
      1&gt; mnesia:load_textfile("FRUITS").
      New table fruit
      New table vegetable
      {atomic,ok}
      2&gt; mnesia:info().
      ---&gt; Processes holding locks &lt;--- 
      ---&gt; Processes waiting for locks &lt;--- 
      ---&gt; Pending (remote) transactions &lt;--- 
      ---&gt; Active (local) transactions &lt;---
      ---&gt; Uncertain transactions &lt;--- 
      ---&gt; Active tables &lt;--- 
      vegetable      : with 2 records occuping 299 words of mem 
      fruit          : with 2 records occuping 291 words of mem 
      schema         : with 3 records occuping 401 words of mem 
      ===&gt; System info in version "1.1", debug level = none &lt;===
      opt_disc. Directory "/var/tmp/Mnesia.nonode@nohost" is used.
      use fallback at restart = false
      running db nodes = [nonode@nohost]
      stopped db nodes = [] 
      remote           = []
      ram_copies       = [fruit,vegetable]
      disc_copies      = [schema]
      disc_only_copies = []
      [{nonode@nohost,disc_copies}] = [schema]
      [{nonode@nohost,ram_copies}] = [fruit,vegetable]
      3 transactions committed, 0 aborted, 0 restarted, 2 logged to disc
      0 held locks, 0 in queue; 0 local transactions, 0 remote
      0 transactions waits for other nodes: []
      ok
      3&gt; 
    </pre><p>It can be seen that the DBMS was initiated from a
regular text file.</p><h3>Object-Based Programming with Mnesia</h3><p>The <strong>Company</strong> database, introduced in
<a href="./Mnesia_chap2#getting_started">Getting Started</a>,
has three tables that store records (<strong>employee</strong>,
<strong>dept</strong>, <strong>project</strong>), and three tables that store
relationships (<strong>manager</strong>, <strong>at_dep</strong>, <strong>in_proj</strong>).
This is a normalized data model, which has some advantages over
a non-normalized data model.</p><p>It is more efficient to do a
generalized search in a normalized database. Some operations are
also easier to perform on a normalized data model. For example,
one project can easily be removed, as the following example
illustrates:</p><pre><code class="">

remove_proj(ProjName) -&gt;
    F = fun() -&gt;
                Ip = qlc:e(qlc:q([X || X &lt;- mnesia:table(in_proj),
				       X#in_proj.proj_name == ProjName]
				)),
                mnesia:delete({project, ProjName}),
                del_in_projs(Ip)
        end,
    mnesia:transaction(F).

del_in_projs([Ip|Tail]) -&gt;
    mnesia:delete_object(Ip),
    del_in_projs(Tail);
del_in_projs([]) -&gt;
    done.</code></pre><p>In reality, data models are seldom fully normalized. A
realistic alternative to a normalized database model would be
a data model that is not even in first normal form. <strong>Mnesia</strong>
is suitable for applications such as telecommunications,
because it is easy to organize data in a flexible manner. A
<strong>Mnesia</strong> database is always organized as a set of tables.
Each table is filled with rows, objects, and records.
What sets <strong>Mnesia</strong> apart is that individual fields in
a record can contain any type of
compound data structures. An individual field in a record can
contain lists, tuples, functions, and even record code.</p><p>Many telecommunications applications have unique requirements
on lookup times for certain types of records. If the <strong>Company</strong>
database had been a part of a telecommunications system, it
could be to minimize the lookup time of an employee
<em>together</em> with a list of the projects the employee is
working on. If this is the case, a drastically different data model
without direct relationships can be chosen. You would then have
only the records themselves, and different records could contain
either direct references to other records, or contain other
records that are not part of the <strong>Mnesia</strong> schema.</p><p>The following record definitions can be created:</p><pre><code class="">

-record(employee, {emp_no,
		   name,
		   salary,
		   sex,
		   phone,
		   room_no,
		   dept,
		   projects,
		   manager}).
		   

-record(dept, {id, 
               name}).

-record(project, {name,
                  number,
                  location}).
</code></pre><p>A record that describes an employee can look as follows:</p><pre>
        Me = #employee{emp_no= 104732,
        name = klacke,
        salary = 7,
        sex = male,
        phone = 99586,
        room_no = {221, 015},
        dept = 'B/SFR',
        projects = [erlang, mnesia, otp],
        manager = 114872},</pre><p>This model has only three different tables, and the employee
records contain references to other records. The record has the
following references:</p><ul><li><strong>'B/SFR'</strong> refers to a <strong>dept</strong> record. </li><li><strong>[erlang, mnesia, otp]</strong> is a list of three direct references to three different <strong>projects</strong> records. </li><li><strong>114872</strong> refers to another employee record. </li></ul><p>The <strong>Mnesia</strong> record identifiers (<strong>{Tab, Key}</strong>) can
also be used as references. In this case, attribute <strong>dept</strong>
would be set to value <strong>{dept, 'B/SFR'}</strong> instead of
<strong>'B/SFR'</strong>.</p><p>With this data model, some operations execute considerably
faster than they do with the normalized data model in the
<strong>Company</strong> database. However, some other operations
become much more complicated. In particular, it becomes more
difficult to ensure that records do not contain dangling
pointers to other non-existent, or deleted, records.</p><p>The following code exemplifies a search with a non-normalized
data model. To find all employees at department <strong>Dep</strong> with
a salary higher than <strong>Salary</strong>, use the following code:</p><pre><code class="">

get_emps(Salary, Dep) -&gt;
    Q = qlc:q( 
          [E || E &lt;- mnesia:table(employee),
                E#employee.salary &gt; Salary,
                E#employee.dept == Dep]
	 ),
    F = fun() -&gt; qlc:e(Q) end,
    transaction(F).</code></pre><p>This code is easier to write and to understand, and it
also executes much faster.</p><p>It is easy to show examples of code that executes faster if
a non-normalized data model is used, instead of a normalized
model. The main reason is that fewer tables are required.
Therefore, data from different tables can more easily be
combined in join operations. In the previous example, the
function <strong>get_emps/2</strong> is transformed from a join operation
into a simple query, which consists of a selection and a
projection on one single table.</p><p>The following topics are included:</p><ul><li>Database configuration data</li><li>Core dumps</li><li>Dumping tables</li><li>Checkpoints</li><li>Startup files, log file, and data files</li><li>Loading tables at startup</li><li>Recovery from communication failure</li><li>Recovery of transactions</li><li>Backup, restore, fallback, and disaster recovery</li></ul><h3>Database Configuration Data</h3><p>The following two functions can be used to retrieve system
information. For details, see the Reference Manual.</p><ul><li><a href="./mnesia#table_info/2">mnesia:table_info(Tab, Key) -&gt; Info | exit({aborted,Reason})</a> returns information about one table, for example, the current size of the table and on which nodes it resides. </li><li><a href="./mnesia#system_info/1">mnesia:system_info(Key) -&gt; Info | exit({aborted, Reason})</a> returns information about the <strong>Mnesia</strong> system, for example, transaction statistics, <strong>db_nodes</strong>, and configuration parameters. </li></ul><h3>Core Dumps</h3><p>If <strong>Mnesia</strong> malfunctions, system information is dumped to
file <strong>MnesiaCore.Node.When</strong>. The type of system
information contained in this file can also be generated with
the function <strong>mnesia_lib:coredump()</strong>. If a <strong>Mnesia</strong>
system behaves strangely, it is recommended that a <strong>Mnesia</strong>
core dump file is included in the bug report.</p><h3>Dumping Tables</h3><p>Tables of type <strong>ram_copies</strong> are by definition stored in
memory only. However, these tables can be dumped to
disc, either at regular intervals or before the system is
shut down. The function
<a href="./mnesia#dump_tables/1">mnesia:dump_tables(TabList)</a>
dumps all replicas of a set of RAM tables to disc. The tables can be
accessed while being dumped to disc. To dump the tables to disc,
all replicas must have the storage type <strong>ram_copies</strong>.</p><p>The table content is placed in a <strong>.DCD</strong> file on the
disc. When the <strong>Mnesia</strong> system is started, the RAM table
is initially loaded with data from its <strong>.DCD</strong> file.</p><a name="checkpoints"></a><h3>Checkpoints</h3><p>A checkpoint is a transaction consistent state that spans over
one or more tables. When a checkpoint is activated, the system
remembers the current content of the set of tables. The
checkpoint retains a transaction consistent state of the tables,
allowing the tables to be read and updated while the checkpoint
is active. A checkpoint is typically used to
back up tables to external media, but they are also used
internally in <strong>Mnesia</strong> for other purposes. Each checkpoint
is independent and a table can be involved in several checkpoints
simultaneously.</p><p>Each table retains its old contents in a checkpoint retainer.
For performance critical applications, it can be important
to realize the processing overhead associated with checkpoints.
In a worst case scenario, the checkpoint retainer consumes
more memory than the table itself. Also, each update becomes
slightly slower on those nodes where checkpoint
retainers are attached to the tables.</p><p>For each table, it is possible to choose if there is to be one
checkpoint retainer attached to all replicas of the table, or if
it is enough to have only one checkpoint retainer attached to a
single replica. With a single checkpoint retainer per table, the
checkpoint consumes less memory, but it is vulnerable
to node crashes. With several redundant checkpoint retainers, the
checkpoint survives as long as there is at least one active
checkpoint retainer attached to each table.</p><p>Checkpoints can be explicitly deactivated with the function
<a href="./mnesia#deactivate_checkpoint/1">mnesia:deactivate_checkpoint(Name)</a>,
where <strong>Name</strong> is
the name of an active checkpoint. This function returns
<strong>ok</strong> if successful or <strong>{error, Reason}</strong> if there is
an error. All tables in a checkpoint must be attached to at
least one checkpoint retainer. The checkpoint is automatically
deactivated by <strong>Mnesia</strong>, when any table lacks a checkpoint
retainer. This can occur when a node goes down or when a
replica is deleted. Use arguments <strong>min</strong> and
<strong>max</strong> (described in the following list) to control the
degree of checkpoint retainer redundancy.</p><a name="mnesia:chkpt(Args)"></a><p>Checkpoints are activated with the function
<a href="./mnesia#activate_checkpoint/1">mnesia:activate_checkpoint(Args)</a>,
where <strong>Args</strong> is a list of the following tuples:</p><ul><li><strong>{name,Name}</strong>, where <strong>Name</strong> specifies a temporary name of the checkpoint. The name can be reused when the checkpoint has been deactivated. If no name is specified, a name is generated automatically. </li><li><strong>{max,MaxTabs}</strong>, where <strong>MaxTabs</strong> is a list of tables that are to be included in the checkpoint. Default is <strong>[]</strong> (empty list). For these tables, the redundancy is maximized. The old content of the table is retained in the checkpoint retainer when the main table is updated by the applications. The checkpoint is more fault tolerant if the tables have several replicas. When new replicas are added by the schema manipulation function <a href="./mnesia#add_table_copy/3">mnesia:add_table_copy/3</a> it also attaches a local checkpoint retainer. </li><li><strong>{min,MinTabs}</strong>, where <strong>MinTabs</strong> is a list of tables that are to be included in the checkpoint. Default is <strong>[]</strong>. For these tables, the redundancy is minimized, and there is to be single checkpoint retainer per table, preferably at the local node. </li><li><strong>{allow_remote,Bool}</strong>, where <strong>false</strong> means that all checkpoint retainers must be local. If a table does not reside locally, the checkpoint cannot be activated. <strong>true</strong> allows checkpoint retainers to be allocated on any node. Default is <strong>true</strong>. </li><li><strong>{ram_overrides_dump,Bool}</strong>. This argument only applies to tables of type <strong>ram_copies</strong>. <strong>Bool</strong> specifies if the table state in RAM is to override the table state on disc. <strong>true</strong> means that the latest committed records in RAM are included in the checkpoint retainer. These are the records that the application accesses. <strong>false</strong> means that the records on the disc <strong>.DAT</strong> file are included in the checkpoint retainer. These records are loaded on startup. Default is <strong>false</strong>.</li></ul><p>The function
<a href="./mnesia#activate_checkpoint/1">mnesia:activate_checkpoint(Args)</a>
returns one of the following values:</p><ul><li><strong>{ok, Name, Nodes}</strong></li><li><strong>{error, Reason}</strong></li></ul><p><strong>Name</strong> is the checkpoint name. <strong>Nodes</strong> are
the nodes where the checkpoint is known.</p><p>A list of active checkpoints can be obtained with the following
functions:</p><ul><li><a href="./mnesia#system_info/1">mnesia:system_info(checkpoints)</a> returns all active checkpoints on the current node.</li><li><a href="./mnesia#table_info/2">mnesia:table_info(Tab, checkpoints)</a> returns active checkpoints on a specific table.</li></ul><h3>Startup Files, Log File, and Data Files</h3><p>This section describes the internal files that are created
and maintained by the <strong>Mnesia</strong> system. In particular,
the workings of the <strong>Mnesia</strong> log are described.</p><h3>Startup Files</h3><p><a href="./Mnesia_chap3#start_mnesia">Start Mnesia</a>
states the following prerequisites
for starting <strong>Mnesia</strong>:</p><ul><li>An Erlang session must be started and a <strong>Mnesia</strong> directory must be specified for the database. </li><li>A database schema must be initiated, using the function <a href="./mnesia#create_schema/1">mnesia:create_schema/1</a>. </li></ul><p>The following example shows how these tasks are performed:</p><p><em>Step 1:</em> Start an Erlang session and specify a
<strong>Mnesia</strong> directory for the database:</p><pre>
% <span class="input">erl -sname klacke -mnesia dir '"/ldisc/scratch/klacke"'</span></pre><pre>
Erlang (BEAM) emulator version 4.9
 
Eshell V4.9  (abort with ^G)
(klacke@gin)1&gt; <span class="input">mnesia:create_schema([node()]).</span>
ok
(klacke@gin)2&gt; 
<span class="input">^Z</span>
Suspended</pre><p><em>Step 2:</em> You can inspect the <strong>Mnesia</strong> directory
to see what files have been created:</p><pre>
% <span class="input">ls -l /ldisc/scratch/klacke</span>
-rw-rw-r--   1 klacke   staff       247 Aug 12 15:06 FALLBACK.BUP</pre><p>The response shows that the file <strong>FALLBACK.BUP</strong> has
been created. This is called a backup file, and it contains
an initial schema. If more than one node in the function
<a href="./mnesia#create_schema/1">mnesia:create_schema/1</a>
had been specified, identical
backup files would have been created on all nodes.</p><p><em>Step 3:</em> Start <strong>Mnesia</strong>:</p><pre>
(klacke@gin)3&gt;<span class="input">mnesia:start( ).</span>
ok</pre><p><em>Step 4:</em> You can see the following listing in
the <strong>Mnesia</strong> directory:</p><pre>
-rw-rw-r--   1 klacke   staff         86 May 26 19:03 LATEST.LOG
-rw-rw-r--   1 klacke   staff      34507 May 26 19:03 schema.DAT</pre><p>The schema in the backup file <strong>FALLBACK.BUP</strong> has been
used to generate the file <strong>schema.DAT</strong>. Since there are
no other disc resident tables than the schema, no other data
files were created. The file <strong>FALLBACK.BUP</strong> was removed
after the successful "restoration". You also see some files
that are for internal use by <strong>Mnesia</strong>.</p><p><em>Step 5:</em> Create a table:</p><pre>
(klacke@gin)4&gt; <span class="input">mnesia:create_table(foo,[{disc_copies, [node()]}]).</span>
{atomic,ok}</pre><p><em>Step 6:</em> You can see the following listing in
the <strong>Mnesia</strong> directory:</p><pre>
% <span class="input">ls -l /ldisc/scratch/klacke</span>
-rw-rw-r-- 1 klacke staff    86 May 26 19:07 LATEST.LOG
-rw-rw-r-- 1 klacke staff    94 May 26 19:07 foo.DCD
-rw-rw-r-- 1 klacke staff  6679 May 26 19:07 schema.DAT</pre><p>The file <strong>foo.DCD</strong> has been created. This file will
eventually store all data that is written into the
<strong>foo</strong> table.</p><h3>Log File</h3><p>When starting <strong>Mnesia</strong>, a <strong>.LOG</strong> file called
<strong>LATEST.LOG</strong> is created
and placed in the database directory. This file is used by
<strong>Mnesia</strong> to log disc-based transactions. This includes all
transactions that write at least one record in a table that is
of storage type <strong>disc_copies</strong> or <strong>disc_only_copies</strong>.
The file also includes all operations that
manipulate the schema itself, such as creating new tables.
The log format can vary with different implementations of
<strong>Mnesia</strong>. The <strong>Mnesia</strong> log is currently implemented
in the standard library module
<a href="./disk_log">disk_log</a> in
<strong>Kernel</strong>.</p><p>The log file grows continuously and must be dumped at
regular intervals. "Dumping the log file" means that <strong>Mnesia</strong>
performs all the operations listed in the log and place the
records in the corresponding <strong>.DAT</strong>, <strong>.DCD</strong>, and
<strong>.DCL</strong> data files. For example, if the operation "write
record <strong>{foo, 4, elvis,  6}</strong>" is listed in the log,
<strong>Mnesia</strong> inserts the operation into the file
<strong>foo.DCL</strong>. Later, when <strong>Mnesia</strong> thinks that the
<strong>.DCL</strong> file is too large, the data is moved to the
<strong>.DCD</strong> file. The dumping operation can be time consuming
if the log is large. Notice that the <strong>Mnesia</strong> system
continues to operate during log dumps.</p><p>By default <strong>Mnesia</strong> either dumps the log whenever
100 records have
been written in the log or when three minutes have passed.
This is controlled by the two application parameters
<strong>-mnesia dump_log_write_threshold WriteOperations</strong> and
<strong>-mnesia dump_log_time_threshold MilliSecs</strong>.</p><p>Before the log is dumped, the file <strong>LATEST.LOG</strong> is
renamed to <strong>PREVIOUS.LOG</strong>, and a new <strong>LATEST.LOG</strong> file
is created. Once the log has been successfully dumped, the file
<strong>PREVIOUS.LOG</strong> is deleted.</p><p>The log is also dumped at startup and whenever a schema
operation is performed.</p><h3>Data Files</h3><p>The directory listing also contains one <strong>.DAT</strong> file,
which contains the schema itself, contained in the
<strong>schema.DAT</strong> file. The <strong>DAT</strong> files are indexed
files, and it is efficient to insert and search for records
in these files with a specific key. The <strong>.DAT</strong> files
are used for the schema and for <strong>disc_only_copies</strong>
tables. The <strong>Mnesia</strong> data files are currently implemented
in the standard library module
<a href="./dets">dets</a> in
<strong>STDLIB</strong>.</p><p>All operations that can be performed on <strong>dets</strong> files
can also be performed on the <strong>Mnesia</strong> data files. For
example, <strong>dets</strong> contains the function
<strong>dets:traverse/2</strong>, which can be used to view the
contents of a <strong>Mnesia</strong> <strong>DAT</strong> file. However, this
can only be done when <strong>Mnesia</strong> is not running. So, to
view the schema file, do as follows;</p><pre>
{ok, N} = dets:open_file(schema, [{file, "./schema.DAT"},{repair,false}, 
{keypos, 2}]),
F = fun(X) -&gt; io:format("~p~n", [X]), continue end,
dets:traverse(N, F),
dets:close(N).</pre><div class="alert alert-warning"><h4 class="alert-heading">Warning</h4><p>The <strong>DAT</strong> files must always be opened with option
<strong>{repair, false}</strong>. This ensures that these files are not
automatically repaired. Without this option, the database can
become inconsistent, because <strong>Mnesia</strong> can believe that
the files were properly closed. For information about
configuration parameter <strong>auto_repair</strong>, see the
Reference Manual.</p></div><div class="alert alert-warning"><h4 class="alert-heading">Warning</h4><p>It is recommended that the data files are not tampered
with while <strong>Mnesia</strong> is running. While not prohibited,
the behavior of <strong>Mnesia</strong> is unpredictable.</p></div><p>The <strong>disc_copies</strong> tables are stored on disk with
<strong>.DCL</strong> and <strong>.DCD</strong> files, which are standard
<strong>disk_log</strong> files.</p><h3>Loading Tables at Startup</h3><p>At startup, <strong>Mnesia</strong> loads tables to make them accessible
for its applications. Sometimes <strong>Mnesia</strong> decides to load
all tables that reside locally, and sometimes the tables are
not accessible until <strong>Mnesia</strong> brings a copy of the table
from another node.</p><p>To understand the behavior of <strong>Mnesia</strong> at startup, it is
essential to understand how <strong>Mnesia</strong> reacts when it loses
contact with <strong>Mnesia</strong> on another node. At this stage,
<strong>Mnesia</strong> cannot distinguish between a communication
failure and a "normal" node-down. When this occurs,
<strong>Mnesia</strong> assumes that the other node is no longer running,
whereas, in reality, the communication between the nodes has
failed.</p><p>To overcome this situation, try to restart the ongoing
transactions that are accessing tables on the failing node,
and write a <strong>mnesia_down</strong> entry to a log file.</p><p>At startup, notice that all tables residing on nodes
without a <strong>mnesia_down</strong> entry can have fresher replicas.
Their replicas can have been updated after the termination of
<strong>Mnesia</strong> on the current node. To catch up with the latest
updates, transfer a copy of the table from one of these other
"fresh" nodes. If you are unlucky, other nodes can be down
and you must wait for the table to be loaded on one of these
nodes before receiving a fresh copy of the table.</p><p>Before an application makes its first access to a table,
<a href="./mnesia#wait_for_tables/2">mnesia:wait_for_tables(TabList, Timeout)</a>
is to be executed
to ensure that the table is accessible from the local node. If
the function times out, the application can choose to force a
load of the local replica with
<a href="./mnesia#force_load_table/1">mnesia:force_load_table(Tab)</a>
and deliberately lose all
updates that can have been performed on the other nodes while
the local node was down. If <strong>Mnesia</strong>
has loaded the table on another node already, or intends
to do so, copy the table from that node to
avoid unnecessary inconsistency.</p><div class="alert alert-warning"><h4 class="alert-heading">Warning</h4><p>Only one table is loaded by
<a href="./mnesia#force_load_table/1">mnesia:force_load_table(Tab)</a>.
Since committed
transactions can have caused updates in several tables, the
tables can become inconsistent because of the forced load.</p></div><p>The allowed <strong>AccessMode</strong> of a table can be defined to be
<strong>read_only</strong> or <strong>read_write</strong>. It can be toggled with
the function
<a href="./mnesia#change_table_access_mode/2"> mnesia:change_table_access_mode(Tab, AccessMode)</a>
in runtime. <strong>read_only</strong> tables and
<strong>local_content</strong> tables are always loaded locally, as
there is no need for copying the table from other nodes. Other
tables are primarily loaded remotely from active replicas on
other nodes if the table has been loaded there already, or if
the running <strong>Mnesia</strong> has decided to load the table there
already.</p><p>At startup, <strong>Mnesia</strong> assumes that its local replica is the
most recent version and loads the table from disc if either of
the following situations is detected:</p><ul><li><strong>mnesia_down</strong> is returned from all other nodes that hold a disc resident replica of the table.</li><li>All replicas are <strong>ram_copies</strong>.</li></ul><p>This is normally a wise decision, but it can be disastrous
if the nodes have been disconnected because of a communication
failure, as the <strong>Mnesia</strong> normal table load
mechanism does not cope with communication failures.</p><p>When <strong>Mnesia</strong> loads many tables, the default load order
is used. However, the load order
can be affected, by explicitly changing property
<strong>load_order</strong> for the tables, with the function
<a href="./mnesia#change_table_load_order/2"> mnesia:change_table_load_order(Tab, LoadOrder)</a>.
<strong>LoadOrder</strong> is by default <strong>0</strong> for all tables, but
it can be set to any integer. The table with the highest
<strong>load_order</strong> is loaded first. Changing the load order is
especially useful for applications that need to ensure early
availability of fundamental tables. Large peripheral tables
are to have a low load order value, perhaps less than <strong>0</strong></p><h3>Recovery from Communication Failure</h3><p>There are several occasions when <strong>Mnesia</strong> can detect
that the network has been partitioned because of a
communication failure, for example:</p><ul><li><strong>Mnesia</strong> is operational already and the Erlang nodes gain contact again. Then <strong>Mnesia</strong> tries to contact <strong>Mnesia</strong> on the other node to see if it also thinks that the network has been partitioned for a while. If <strong>Mnesia</strong> on both nodes has logged <strong>mnesia_down</strong> entries from each other, <strong>Mnesia</strong> generates a system event, called <strong>{inconsistent_database, running_partitioned_network, Node}</strong>, which is sent to the <strong>Mnesia</strong> event handler and other possible subscribers. The default event handler reports an error to the error logger. </li><li>If <strong>Mnesia</strong> detects at startup that both the local node and another node received <strong>mnesia_down</strong> from each other, <strong>Mnesia</strong> generates an <strong>{inconsistent_database, starting_partitioned_network, Node}</strong> system event and acts as described in the previous item. </li></ul><p>If the application detects that there has been a communication
failure that can have caused an inconsistent database, it can
use the function
<a href="./mnesia#set_master_nodes/2">mnesia:set_master_nodes(Tab, Nodes)</a>
to pinpoint from which nodes each table can be loaded.</p><p>At startup, the <strong>Mnesia</strong> normal table load algorithm is
bypassed and the table is loaded from one of the master
nodes defined for the table, regardless of potential
<strong>mnesia_down</strong> entries in the log. <strong>Nodes</strong> can only
contain nodes where the table has a replica. If <strong>Nodes</strong>
is empty, the master node recovery mechanism for the particular
table is reset and the normal load mechanism is used at the
next restart.</p><p>The function
<a href="./mnesia#set_master_nodes/1">mnesia:set_master_nodes(Nodes)</a>
sets master
nodes for all tables. For each table it determines its replica
nodes and starts
<a href="./mnesia#set_master_nodes/2">mnesia:set_master_nodes(Tab, TabNodes)</a>
with those replica nodes that are included in the <strong>Nodes</strong>
list (that is, <strong>TabNodes</strong> is the intersection of
<strong>Nodes</strong> and the replica nodes of the table). If the
intersection is empty, the master node recovery mechanism for
the particular table is reset and the normal load mechanism
is used at the next restart.</p><p>The functions
<a href="./mnesia#system_info/1">mnesia:system_info(master_node_tables)</a>
and
<a href="./mnesia#table_info/2">mnesia:table_info(Tab, master_nodes)</a>
can be used to
obtain information about the potential master nodes.</p><p>Determining what data to keep after a communication failure
is outside the scope of <strong>Mnesia</strong>. One approach is to
determine which "island" contains most of the nodes. Using
option <strong>{majority,true}</strong> for critical tables can be a way
to ensure that nodes that are not part of a "majority island"
cannot update those tables. Notice that this constitutes a
reduction in service on the minority nodes. This would be a
tradeoff in favor of higher consistency guarantees.</p><p>The function
<a href="./mnesia#force_load_table/1">mnesia:force_load_table(Tab)</a>
can be used to force load the table regardless of which table
load mechanism that is activated.</p><h3>Recovery of Transactions</h3><p>A <strong>Mnesia</strong> table can reside on one or more nodes. When a
table is updated, <strong>Mnesia</strong> ensures that the updates are
replicated to all nodes where the table resides. If a replica is
inaccessible (for example, because of a temporary node-down),
<strong>Mnesia</strong> performs the replication later.</p><p>On the node where the application is started, there is a
transaction coordinator process. If the transaction is
distributed, there is also a transaction participant process on
all the other nodes where commit-work needs to be performed.</p><p>Internally <strong>Mnesia</strong> uses several commit protocols. The
selected protocol depends on which table that has been updated
in the transaction. If all the involved tables are symmetrically
replicated (that is, they all have the same <strong>ram_nodes</strong>,
<strong>disc_nodes</strong>, and <strong>disc_only_nodes</strong> currently
accessible from the coordinator node), a lightweight transaction
commit protocol is used.</p><p>The number of messages that the
transaction coordinator and its participants need to exchange
is few, as the <strong>Mnesia</strong> table load mechanism takes care of
the transaction recovery if the commit protocol gets
interrupted. Since all involved tables are replicated
symmetrically, the transaction is automatically recovered by
loading the involved tables from the same node at startup of a
failing node. It does not matter if the transaction was
committed or terminated as long as the ACID properties can be
ensured. The lightweight commit protocol is non-blocking,
that is, the surviving participants and their coordinator
finish the transaction, even if any node crashes in the
middle of the commit protocol.</p><p>If a node goes down in the middle of a dirty operation, the
table load mechanism ensures that the update is
performed on all replicas, or none. Both asynchronous dirty
updates and synchronous dirty updates use the same recovery
principle as lightweight transactions.</p><p>If a transaction involves updates of asymmetrically replicated
tables or updates of the schema table, a heavyweight commit
protocol is used. This protocol can
finish the transaction regardless of how the tables are
replicated. The typical use of a heavyweight transaction is
when a replica is to be moved from one node to another. Then
ensure that the replica either is entirely moved or left as
it was. Do never end up in a situation with replicas on both
nodes, or on no node at all. Even if a node crashes in the middle
of the commit protocol, the transaction must be guaranteed to be
atomic. The heavyweight commit protocol involves more messages
between the transaction coordinator and its participants than
a lightweight protocol, and it performs recovery work at
startup to finish the terminating or commit work.</p><p>The heavyweight commit protocol is also non-blocking,
which allows the surviving participants and their coordinator to
finish the transaction regardless (even if a node crashes in the
middle of the commit protocol). When a node fails at startup,
<strong>Mnesia</strong> determines the outcome of the transaction and
recovers it. Lightweight protocols, heavyweight protocols, and
dirty updates, are dependent on other nodes to be operational
to make the correct heavyweight transaction recovery decision.</p><p>If <strong>Mnesia</strong> has not started on some of the nodes that
are involved in the transaction <em>and</em> neither the
local node nor any of the already running nodes know the
outcome of the transaction, <strong>Mnesia</strong> waits for one,
by default. In the worst case scenario, all other involved
nodes must start before <strong>Mnesia</strong> can make the correct
decision about the transaction and finish its startup.</p><p>Thus, <strong>Mnesia</strong> (on one node) can hang if a double fault
occurs, that is, when two nodes crash simultaneously
and one attempts to start when the other refuses to
start, for example, because of a hardware error.</p><p>The maximum time that <strong>Mnesia</strong> waits for other nodes to
respond with a transaction recovery decision can be specified.
The configuration parameter <strong>max_wait_for_decision</strong>
defaults to <strong>infinity</strong>, which can cause the indefinite
hanging as mentioned earlier. However, if the parameter is
set to a definite time period (for example, three minutes),
<strong>Mnesia</strong> then enforces a transaction recovery decision,
if needed, to allow <strong>Mnesia</strong> to continue with its startup
procedure.</p><p>The downside of an enforced transaction recovery decision is
that the decision can be incorrect, because of insufficient
information about the recovery decisions from the other nodes.
This can result in an inconsistent database where <strong>Mnesia</strong>
has committed the transaction on some nodes but terminated it
on others.</p><p>In fortunate cases, the inconsistency is only visible in
tables belonging to a specific application. However, if a
schema transaction is inconsistently recovered because of
the enforced transaction recovery decision, the
effects of the inconsistency can be fatal.
However, if the higher priority is availability rather than
consistency, it can be worth the risk.</p><p>If <strong>Mnesia</strong> detects an inconsistent transaction decision,
an <strong>{inconsistent_database, bad_decision, Node}</strong> system event
is generated to give the application a chance to install a
fallback or other appropriate measures to resolve the
inconsistency. The default behavior of the <strong>Mnesia</strong>
event handler is the same as if the database became
inconsistent as a result of partitioned network (as
described earlier).</p><h3>Backup, Restore, Fallback, and Disaster Recovery</h3><p>The following functions are used to back up data, to install
a backup as fallback, and for disaster recovery:</p><ul><li> <a href="./mnesia#backup_checkpoint/2">mnesia:backup_checkpoint(Name, Opaque, [Mod])</a> performs a backup of the tables included in the checkpoint. </li><li> <a href="./mnesia#backup/1">mnesia:backup(Opaque, [Mod])</a> activates a new checkpoint that covers all <strong>Mnesia</strong> tables and performs a backup. It is performed with maximum degree of redundancy (see also the function <a href="#checkpoints">mnesia:activate_checkpoint(Args)</a>, <strong>{max, MaxTabs} and {min, MinTabs})</strong>. </li><li> <a href="./mnesia#traverse_backup/4">mnesia:traverse_backup(Source, [SourceMod,] Target, [TargetMod,] Fun, Acc)</a> can be used to read an existing backup, create a backup from an existing one, or to copy a backup from one type media to another. </li><li> <a href="./mnesia#uninstall_fallback/0">mnesia:uninstall_fallback()</a> removes previously installed fallback files. </li><li> <a href="./mnesia#restore/2">mnesia:restore(Opaque, Args)</a> restores a set of tables from a previous backup. </li><li> <a href="./mnesia#install_fallback/1">mnesia:install_fallback(Opaque, [Mod])</a> can be configured to restart <strong>Mnesia</strong> and the reload data tables, and possibly the schema tables, from an existing backup. This function is typically used for disaster recovery purposes, when data or schema tables are corrupted. </li></ul><p>These functions are explained in the following sections.
See also <a href="#checkpoints">Checkpoints</a>,
which describes the two functions used
to activate and deactivate checkpoints.</p><h3>Backup</h3><p>Backup operation are performed with the following functions:</p><ul><li> <a href="./mnesia#backup_checkpoint/2">mnesia:backup_checkpoint(Name, Opaque, [Mod])</a> </li><li> <a href="./mnesia#backup/1">mnesia:backup(Opaque, [Mod])</a> </li><li> <a href="./mnesia#traverse_backup/4">mnesia:traverse_backup(Source, [SourceMod,] Target, [TargetMod,] Fun, Acc)</a> </li></ul><p>By default, the actual access to the backup media is
performed through module <strong>mnesia_backup</strong> for both read
and write. Currently <strong>mnesia_backup</strong> is implemented with
the standard library module <strong>disc_log</strong>. However, you
can write your own module with the same interface as
<strong>mnesia_backup</strong> and configure <strong>Mnesia</strong> so that
the alternative module performs the actual accesses to
the backup media. The user can
therefore put the backup on a media that <strong>Mnesia</strong>
does not know about, possibly on hosts where Erlang is not
running. Use configuration parameter
<strong>-mnesia backup_module &lt;module&gt;</strong>
for this purpose.</p><p>The source for a backup is an activated checkpoint.
The backup function
<a href="./mnesia#backup_checkpoint/2">mnesia:backup_checkpoint(Name, Opaque,[Mod])</a>
is most commonly used and returns <strong>ok</strong> or
<strong>{error,Reason}</strong>. It has the following arguments:</p><ul><li><strong>Name</strong> is the name of an activated checkpoint. For details on how to include table names in checkpoints, see the function <strong>mnesia:activate_checkpoint(ArgList)</strong> in <a href="#checkpoints">Checkpoints</a>. </li><li><strong>Opaque</strong>. <strong>Mnesia</strong> does not interpret this argument, but it is forwarded to the backup module. The <strong>Mnesia</strong> default backup module <strong>mnesia_backup</strong> interprets this argument as a local filename. </li><li><strong>Mod</strong> is the name of an alternative backup module. </li></ul><p>The function
<a href="./mnesia#backup/1">mnesia:backup(Opaque [,Mod])</a>
activates a
new checkpoint that covers all <strong>Mnesia</strong> tables with
maximum degree of redundancy and performs a backup. Maximum
redundancy means that each table replica has a checkpoint
retainer. Tables with property <strong>local_contents</strong> are
backed up as they look on the current node.</p><p>You can iterate over a backup, either to transform it
into a new backup, or only read it. The function
<a href="./mnesia#traverse_backup/4">mnesia:traverse_backup(Source, [SourceMod,] Target, [TargetMod,] Fun, Acc)</a>,
which normally returns <strong>{ok, LastAcc}</strong>,
is used for both of these purposes.</p><p>Before the traversal starts, the source backup media is
opened with <strong>SourceMod:open_read(Source)</strong>, and the target
backup media is opened with
<strong>TargetMod:open_write(Target)</strong>. The arguments are as
follows:</p><ul><li><strong>SourceMod</strong> and <strong>TargetMod</strong> are module names. </li><li><strong>Source</strong> and <strong>Target</strong> are opaque data used exclusively by the modules <strong>SourceMod</strong> and <strong>TargetMod</strong> for initializing the backup medias. </li><li><strong>Acc</strong> is an initial accumulator value. </li><li><strong>Fun(BackupItems, Acc)</strong> is applied to each item in the backup. The Fun must return a tuple <strong>{ValGoodBackupItems, NewAcc}</strong>, where <strong>ValidBackupItems</strong> is a list of valid backup items. <strong>NewAcc</strong> is a new accumulator value. The <strong>ValidBackupItems</strong> are written to the target backup with the function <strong>TargetMod:write/2</strong>. </li><li><strong>LastAcc</strong> is the last accumulator value, that is, the last <strong>NewAcc</strong> value that was returned by <strong>Fun</strong>. </li></ul><p>Also, a read-only traversal of the source backup can be
performed without updating a target backup. If
<strong>TargetMod==read_only</strong>, no target backup is accessed.</p><p>By setting <strong>SourceMod</strong> and <strong>TargetMod</strong> to different
modules, a backup can be copied from one backup
media to another.</p><p>Valid <strong>BackupItems</strong> are the following tuples:</p><ul><li><strong>{schema, Tab}</strong> specifies a table to be deleted. </li><li><strong>{schema, Tab, CreateList}</strong> specifies a table to be created. For more information about <strong>CreateList</strong>, see <a href="./mnesia#create_table/2">mnesia:create_table/2</a>. </li><li><strong>{Tab, Key}</strong> specifies the full identity of a record to be deleted. </li><li><strong>{Record}</strong> specifies a record to be inserted. It can be a tuple with <strong>Tab</strong> as first field. Notice that the record name is set to the table name regardless of what <strong>record_name</strong> is set to. </li></ul><p>The backup data is divided into two sections. The first
section contains information related to the schema. All
schema-related items are tuples where the first field equals
the atom schema. The second section is the record section.
Schema records cannot be mixed with other records and all
schema records must be located first in the backup.</p><p>The schema itself is a table and is possibly included in
the backup. Each node where the schema table resides is
regarded as a <strong>db_node</strong>.</p><p>The following example shows how
<a href="./mnesia#traverse_backup/4">mnesia:traverse_backup</a>
can be used to rename a <strong>db_node</strong> in a backup file:</p><pre><code class="">

change_node_name(Mod, From, To, Source, Target) -&gt;
    Switch =
        fun(Node) when Node == From -&gt; To;
           (Node) when Node == To -&gt; throw({error, already_exists});
           (Node) -&gt; Node
        end,
    Convert =
        fun({schema, db_nodes, Nodes}, Acc) -&gt;
                {[{schema, db_nodes, lists:map(Switch,Nodes)}], Acc};
           ({schema, version, Version}, Acc) -&gt;
                {[{schema, version, Version}], Acc};
           ({schema, cookie, Cookie}, Acc) -&gt;
                {[{schema, cookie, Cookie}], Acc};
           ({schema, Tab, CreateList}, Acc) -&gt;
                Keys = [ram_copies, disc_copies, disc_only_copies],
                OptSwitch =
                    fun({Key, Val}) -&gt;
                            case lists:member(Key, Keys) of
                                true -&gt; {Key, lists:map(Switch, Val)};
                                false-&gt; {Key, Val}
                            end
                    end,
                {[{schema, Tab, lists:map(OptSwitch, CreateList)}], Acc};
           (Other, Acc) -&gt;
                {[Other], Acc}
        end,
    mnesia:traverse_backup(Source, Mod, Target, Mod, Convert, switched).

view(Source, Mod) -&gt;
    View = fun(Item, Acc) -&gt;
                   io:format("~p.~n",[Item]),
                   {[Item], Acc + 1}
           end,
    mnesia:traverse_backup(Source, Mod, dummy, read_only, View, 0).</code></pre><h3>Restore</h3><p>Tables can be restored online from a backup without
restarting <strong>Mnesia</strong>. A restore is performed with the
function
<a href="./mnesia#restore/2">mnesia:restore(Opaque, Args)</a>,
where <strong>Args</strong> can contain the following tuples:</p><ul><li><strong>{module,Mod}</strong>. The backup module <strong>Mod</strong> is used to access the backup media. If omitted, the default backup module is used. </li><li><strong>{skip_tables, TableList}</strong>, where <strong>TableList</strong> is a list of tables, which is not to be read from the backup. </li><li><strong>{clear_tables, TableList}</strong>, where <strong>TableList</strong> is a list of tables, which is to be cleared before the records from the backup are inserted. That is, all records in the tables are deleted before the tables are restored. Schema information about the tables is not cleared or read from the backup. </li><li><strong>{keep_tables, TableList}</strong>, where <strong>TableList</strong> is a list of tables, which is not to be cleared before the records from the backup are inserted. That is, the records in the backup are added to the records in the table. Schema information about the tables is not cleared or read from the backup. </li><li><strong>{recreate_tables, TableList}</strong>, where <strong>TableList</strong> is a list of tables, which is to be recreated before the records from the backup are inserted. The tables are first deleted and then created with the schema information from the backup. All the nodes in the backup need to be operational. </li><li><strong>{default_op, Operation}</strong>, where <strong>Operation</strong> is one of the operations <strong>skip_tables</strong>, <strong>clear_tables</strong>, <strong>keep_tables</strong>, or <strong>recreate_tables</strong>. The default operation specifies which operation is to be used on tables from the backup that are not specified in any of the previous lists. If omitted, the operation <strong>clear_tables</strong> is used. </li></ul><p>The argument <strong>Opaque</strong> is forwarded to the backup module.
It returns <strong>{atomic, TabList}</strong> if successful, or the
tuple <strong>{aborted, Reason}</strong> if there is an error.
<strong>TabList</strong> is a list of the restored tables. Tables that
are restored are write-locked during the restore
operation. However, regardless of any lock conflict caused by
this, applications can continue to do their work during the
restore operation.</p><p>The restoration is performed as a single transaction. If the
database is large, it cannot always be restored
online. The old database must then be restored by
installing a fallback, followed by a restart.</p><h3>Fallback</h3><p>The function
<a href="./mnesia#install_fallback/2">mnesia:install_fallback(Opaque, [Mod])</a>
installs a backup as fallback. It uses the backup module
<strong>Mod</strong>, or the default backup module, to access the backup
media. The function returns <strong>ok</strong> if successful, or
<strong>{error, Reason}</strong> if there is an error.</p><p>Installing a fallback is a distributed operation, which is
<em>only</em> performed on all <strong>db_nodes</strong>. The fallback
restores the database the next time the system is started.
If a <strong>Mnesia</strong> node with a fallback installed detects that
<strong>Mnesia</strong> on another node has died, it
unconditionally terminates itself.</p><p>A fallback is typically used when a system upgrade is
performed. A system typically involves the installation of new
software versions, and <strong>Mnesia</strong> tables are often transformed
into new layouts. If the system crashes during an upgrade, it is
highly probable that reinstallation of the old applications is
required, and restoration of the database to its previous state.
This can be done if a backup is performed and
installed as a fallback before the system upgrade begins.</p><p>If the system upgrade fails, <strong>Mnesia</strong> must be restarted
on all <strong>db_nodes</strong> to restore the old database. The
fallback is automatically deinstalled after a successful
startup. The function
<a href="./mnesia#uninstall_fallback/0">mnesia:uninstall_fallback()</a>
can also be used to deinstall the fallback after a
successful system upgrade. Again, this is a distributed
operation that is either performed on all <strong>db_nodes</strong> or
none. Both the installation and deinstallation of fallbacks
require Erlang to be operational on all <strong>db_nodes</strong>, but
it does not matter if <strong>Mnesia</strong> is running or not.</p><h3>Disaster Recovery</h3><p>The system can become inconsistent as a result of a power
failure. The UNIX feature <strong>fsck</strong> can possibly repair the
file system, but there is no guarantee that the file content
is consistent.</p><p>If <strong>Mnesia</strong> detects that a file has not been properly
closed, possibly as a result of a power failure, it tries to
repair the bad file in a similar manner. Data can be lost, but
<strong>Mnesia</strong> can be restarted even if the data is inconsistent.
Configuration parameter
<strong>-mnesia auto_repair &lt;bool&gt;</strong> can be used
to control the behavior of <strong>Mnesia</strong> at startup. If
<strong>&lt;bool&gt;</strong> has the value <strong>true</strong>,
<strong>Mnesia</strong> tries to repair the file. If
<strong>&lt;bool&gt;</strong> has the value <strong>false</strong>,
<strong>Mnesia</strong> does not restart if it detects a suspect file.
This configuration parameter affects the repair behavior of log
files, <strong>DAT</strong> files, and the default backup media.</p><p>Configuration parameter
<strong>-mnesia dump_log_update_in_place &lt;bool&gt;</strong>
controls the safety level of the function
<a href="./mnesia#dump_log/0">mnesia:dump_log()</a>
By default, <strong>Mnesia</strong> dumps the
transaction log directly into the <strong>DAT</strong> files. If a power
failure occurs during the dump, this can cause the randomly
accessed <strong>DAT</strong> files to become corrupt. If the parameter
is set to <strong>false</strong>, <strong>Mnesia</strong> copies the <strong>DAT</strong>
files and target the dump
to the new temporary files. If the dump is successful, the
temporary files are renamed to their normal <strong>DAT</strong>
suffixes. The possibility for unrecoverable inconsistencies in
the data files becomes much smaller with this strategy.
However, the actual dumping of the transaction log becomes
considerably slower. The system designer must decide whether
speed or safety is the higher priority.</p><p>Replicas of type <strong>disc_only_copies</strong> are only
affected by this parameter during the initial dump of the log
file at startup. When designing applications with
<em>very</em> high requirements, it can be appropriate not to
use <strong>disc_only_copies</strong> tables at all. The reason for this
is the random access nature of normal operating system files. If
a node goes down for a reason such as a power
failure, these files can be corrupted because they are not
properly closed. The <strong>DAT</strong> files for <strong>disc_only_copies</strong>
are updated on a per transaction basis.</p><p>If a disaster occurs and the <strong>Mnesia</strong> database is
corrupted, it can be reconstructed from a backup. Regard
this as a last resort, as the backup contains old data. The
data is hopefully consistent, but data is definitely lost
when an old backup is used to restore the database.</p><h3>Combine Mnesia and SNMP</h3><p>Many telecommunications applications must be controlled and
reconfigured remotely. It is sometimes an advantage to perform
this remote control with an open protocol such as the Simple
Network Management Protocol (SNMP). The alternatives to this would
be the following:</p><ul><li>Not being able to control the application remotely </li><li>Using a proprietary control protocol </li><li>Using a bridge that maps control messages in a proprietary protocol to a standardized management protocol and conversely </li></ul><p>All these approaches have different advantages and
disadvantages. Mnesia applications can easily be opened to
the SNMP protocol. A direct 1-to-1 mapping can be established
between Mnesia tables and SNMP tables. This means
that a Mnesia table can be configured to be <em>both</em>
a Mnesia table and an SNMP table. A number of functions to
control this behavior are described in the Reference Manual.</p><h3>mnesia_backup Callback Behavior</h3><pre><code class="">


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% This module contains one implementation of callback functions
%% used by Mnesia at backup and restore. The user may however
%% write an own module the same interface as mnesia_backup and
%% configure Mnesia so the alternate module performs the actual
%% accesses to the backup media. This means that the user may put
%% the backup on medias that Mnesia does not know about, possibly
%% on hosts where Erlang is not running.
%%
%% The OpaqueData argument is never interpreted by other parts of
%% Mnesia. It is the property of this module. Alternate implementations
%% of this module may have different interpretations of OpaqueData.
%% The OpaqueData argument given to open_write/1 and open_read/1
%% are forwarded directly from the user.
%%
%% All functions must return {ok, NewOpaqueData} or {error, Reason}.
%%
%% The NewOpaqueData arguments returned by backup callback functions will
%% be given as input when the next backup callback function is invoked.
%% If any return value does not match {ok, _} the backup will be aborted.
%%
%% The NewOpaqueData arguments returned by restore callback functions will
%% be given as input when the next restore callback function is invoked
%% If any return value does not match {ok, _} the restore will be aborted.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

-module(mnesia_backup).

-include_lib("kernel/include/file.hrl").

-export([
	 %% Write access
         open_write/1,
	 write/2,
	 commit_write/1,
	 abort_write/1,

	 %% Read access
         open_read/1,
	 read/1,
	 close_read/1
        ]).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Backup callback interface
-record(backup, {tmp_file, file, file_desc}).

%% Opens backup media for write
%%
%% Returns {ok, OpaqueData} or {error, Reason}
open_write(OpaqueData) -&gt;
    File = OpaqueData,
    Tmp = lists:concat([File,".BUPTMP"]),
    file:delete(Tmp),
    file:delete(File),
    case disk_log:open([{name, make_ref()},
			{file, Tmp},
			{repair, false},
			{linkto, self()}]) of
	{ok, Fd} -&gt;
	    {ok, #backup{tmp_file = Tmp, file = File, file_desc = Fd}};
	{error, Reason} -&gt;
	    {error, Reason}
    end.

%% Writes BackupItems to the backup media
%%
%% Returns {ok, OpaqueData} or {error, Reason}
write(OpaqueData, BackupItems) -&gt;
    B = OpaqueData,
    case disk_log:log_terms(B#backup.file_desc, BackupItems) of
        ok -&gt;
            {ok, B};
        {error, Reason} -&gt;
            abort_write(B),
            {error, Reason}
    end.

%% Closes the backup media after a successful backup
%%
%% Returns {ok, ReturnValueToUser} or {error, Reason}
commit_write(OpaqueData) -&gt;
    B = OpaqueData,
    case disk_log:sync(B#backup.file_desc) of
        ok -&gt;
            case disk_log:close(B#backup.file_desc) of
                ok -&gt;
		    case file:rename(B#backup.tmp_file, B#backup.file) of
		       ok -&gt;
			    {ok, B#backup.file};
		       {error, Reason} -&gt;
			    {error, Reason}
		    end;
                {error, Reason} -&gt;
		    {error, Reason}
            end;
        {error, Reason} -&gt;
            {error, Reason}
    end.

%% Closes the backup media after an interrupted backup
%%
%% Returns {ok, ReturnValueToUser} or {error, Reason}
abort_write(BackupRef) -&gt;
    Res = disk_log:close(BackupRef#backup.file_desc),
    file:delete(BackupRef#backup.tmp_file),
    case Res of
        ok -&gt;
            {ok, BackupRef#backup.file};
        {error, Reason} -&gt;
            {error, Reason}
    end.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Restore callback interface

-record(restore, {file, file_desc, cont}).

%% Opens backup media for read
%%
%% Returns {ok, OpaqueData} or {error, Reason}
open_read(OpaqueData) -&gt;
    File = OpaqueData,
    case file:read_file_info(File) of
	{error, Reason} -&gt;
	    {error, Reason};
	_FileInfo -&gt; %% file exists
	    case disk_log:open([{file, File},
				{name, make_ref()},
				{repair, false},
				{mode, read_only},
				{linkto, self()}]) of
		{ok, Fd} -&gt;
		    {ok, #restore{file = File, file_desc = Fd, cont = start}};
		{repaired, Fd, _, {badbytes, 0}} -&gt;
		    {ok, #restore{file = File, file_desc = Fd, cont = start}};
		{repaired, Fd, _, _} -&gt;
		    {ok, #restore{file = File, file_desc = Fd, cont = start}};
		{error, Reason} -&gt;
		    {error, Reason}
	    end
    end.

%% Reads BackupItems from the backup media
%%
%% Returns {ok, OpaqueData, BackupItems} or {error, Reason}
%%
%% BackupItems == [] is interpreted as eof
read(OpaqueData) -&gt;
    R = OpaqueData,
    Fd = R#restore.file_desc,
    case disk_log:chunk(Fd, R#restore.cont) of
        {error, Reason} -&gt;
            {error, {"Possibly truncated", Reason}};
        eof -&gt;
            {ok, R, []};
        {Cont, []} -&gt;
            read(R#restore{cont = Cont});
        {Cont, BackupItems, _BadBytes} -&gt;
            {ok, R#restore{cont = Cont}, BackupItems};
        {Cont, BackupItems} -&gt;
            {ok, R#restore{cont = Cont}, BackupItems}
    end.

%% Closes the backup media after restore
%%
%% Returns {ok, ReturnValueToUser} or {error, Reason}
close_read(OpaqueData) -&gt;
    R = OpaqueData,
    case disk_log:close(R#restore.file_desc) of
        ok -&gt; {ok, R#restore.file};
        {error, Reason} -&gt; {error, Reason}
    end.</code></pre><h3>mnesia_access Callback Behavior</h3><pre><code class="">


-module(mnesia_frag).

%% Callback functions when accessed within an activity
-export([
	 lock/4,
	 write/5, delete/5, delete_object/5,
	 read/5, match_object/5, all_keys/4,
	 select/5,select/6,select_cont/3,
	 index_match_object/6, index_read/6,
	 foldl/6, foldr/6, table_info/4,
	 first/3, next/4, prev/4, last/3,
	 clear_table/4
       ]).
</code></pre><pre><code class="">


%% Callback functions which provides transparent
%% access of fragmented tables from any activity
%% access context.

lock(ActivityId, Opaque, {table , Tab}, LockKind) -&gt;
    case frag_names(Tab) of
	[Tab] -&gt;
	    mnesia:lock(ActivityId, Opaque, {table, Tab}, LockKind);
	Frags -&gt;
	    DeepNs = [mnesia:lock(ActivityId, Opaque, {table, F}, LockKind) ||
			 F &lt;- Frags],
	    mnesia_lib:uniq(lists:append(DeepNs))
    end;

lock(ActivityId, Opaque, LockItem, LockKind) -&gt;
    mnesia:lock(ActivityId, Opaque, LockItem, LockKind).

write(ActivityId, Opaque, Tab, Rec, LockKind) -&gt;
    Frag = record_to_frag_name(Tab, Rec),
    mnesia:write(ActivityId, Opaque, Frag, Rec, LockKind).

delete(ActivityId, Opaque, Tab, Key, LockKind) -&gt;
    Frag = key_to_frag_name(Tab, Key),
    mnesia:delete(ActivityId, Opaque, Frag, Key, LockKind).

delete_object(ActivityId, Opaque, Tab, Rec, LockKind) -&gt;
    Frag = record_to_frag_name(Tab, Rec),
    mnesia:delete_object(ActivityId, Opaque, Frag, Rec, LockKind).

read(ActivityId, Opaque, Tab, Key, LockKind) -&gt;
    Frag = key_to_frag_name(Tab, Key),
    mnesia:read(ActivityId, Opaque, Frag, Key, LockKind).

match_object(ActivityId, Opaque, Tab, HeadPat, LockKind) -&gt;
    MatchSpec = [{HeadPat, [], ['$_']}],
    select(ActivityId, Opaque, Tab, MatchSpec, LockKind).

select(ActivityId, Opaque, Tab, MatchSpec, LockKind) -&gt;
    do_select(ActivityId, Opaque, Tab, MatchSpec, LockKind).


select(ActivityId, Opaque, Tab, MatchSpec, Limit, LockKind) -&gt;
    init_select(ActivityId, Opaque, Tab, MatchSpec, Limit, LockKind).


all_keys(ActivityId, Opaque, Tab, LockKind) -&gt;
    Match = [mnesia:all_keys(ActivityId, Opaque, Frag, LockKind)
	     || Frag &lt;- frag_names(Tab)],
    lists:append(Match).

clear_table(ActivityId, Opaque, Tab, Obj) -&gt;
    [mnesia:clear_table(ActivityId, Opaque, Frag, Obj)  || Frag &lt;- frag_names(Tab)],
    ok.

index_match_object(ActivityId, Opaque, Tab, Pat, Attr, LockKind) -&gt;
    Match =
	[mnesia:index_match_object(ActivityId, Opaque, Frag, Pat, Attr, LockKind)
	 || Frag &lt;- frag_names(Tab)],
    lists:append(Match).

index_read(ActivityId, Opaque, Tab, Key, Attr, LockKind) -&gt;
    Match =
	[mnesia:index_read(ActivityId, Opaque, Frag, Key, Attr, LockKind)
	     || Frag &lt;- frag_names(Tab)],
    lists:append(Match).

foldl(ActivityId, Opaque, Fun, Acc, Tab, LockKind) -&gt;
    Fun2 = fun(Frag, A) -&gt;
		   mnesia:foldl(ActivityId, Opaque, Fun, A, Frag, LockKind)
	   end,
    lists:foldl(Fun2, Acc, frag_names(Tab)).

foldr(ActivityId, Opaque, Fun, Acc, Tab, LockKind) -&gt;
    Fun2 = fun(Frag, A) -&gt;
		   mnesia:foldr(ActivityId, Opaque, Fun, A, Frag, LockKind)
	   end,
    lists:foldr(Fun2, Acc, frag_names(Tab)).

table_info(ActivityId, Opaque, {Tab, Key}, Item) -&gt;
    Frag = key_to_frag_name(Tab, Key),
    table_info2(ActivityId, Opaque, Tab, Frag, Item);
table_info(ActivityId, Opaque, Tab, Item) -&gt;
    table_info2(ActivityId, Opaque, Tab, Tab, Item).

table_info2(ActivityId, Opaque, Tab, Frag, Item) -&gt;
    case Item of
	size -&gt;
	    SumFun = fun({_, Size}, Acc) -&gt; Acc + Size end,
	    lists:foldl(SumFun, 0, frag_size(ActivityId, Opaque, Tab));
	memory -&gt;
	    SumFun = fun({_, Size}, Acc) -&gt; Acc + Size end,
	    lists:foldl(SumFun, 0, frag_memory(ActivityId, Opaque, Tab));
	base_table -&gt;
	    lookup_prop(Tab, base_table);
	node_pool -&gt;
	    lookup_prop(Tab, node_pool);
	n_fragments -&gt;
	    FH = lookup_frag_hash(Tab),
	    FH#frag_state.n_fragments;
	foreign_key -&gt;
	    FH = lookup_frag_hash(Tab),
	    FH#frag_state.foreign_key;
	foreigners -&gt;
	    lookup_foreigners(Tab);
	n_ram_copies -&gt;
	    length(val({Tab, ram_copies}));
	n_disc_copies -&gt;
	    length(val({Tab, disc_copies}));
	n_disc_only_copies -&gt;
	    length(val({Tab, disc_only_copies}));
	n_external_copies -&gt;
	    length(val({Tab, external_copies}));

	frag_names -&gt;
	    frag_names(Tab);
	frag_dist -&gt;
	    frag_dist(Tab);
	frag_size -&gt;
	    frag_size(ActivityId, Opaque, Tab);
	frag_memory -&gt;
	    frag_memory(ActivityId, Opaque, Tab);
	_ -&gt;
	    mnesia:table_info(ActivityId, Opaque, Frag, Item)
    end.

first(ActivityId, Opaque, Tab) -&gt;
    case ?catch_val({Tab, frag_hash}) of
	{'EXIT', _} -&gt;
	    mnesia:first(ActivityId, Opaque, Tab);
	FH -&gt;
	    FirstFrag = Tab,
	    case mnesia:first(ActivityId, Opaque, FirstFrag) of
		'$end_of_table' -&gt;
		    search_first(ActivityId, Opaque, Tab, 1, FH);
		Next -&gt;
		    Next
	    end
    end.

search_first(ActivityId, Opaque, Tab, N, FH) when N &lt; FH#frag_state.n_fragments -&gt;
    NextN = N + 1,
    NextFrag = n_to_frag_name(Tab, NextN),
    case mnesia:first(ActivityId, Opaque, NextFrag) of
	'$end_of_table' -&gt;
	    search_first(ActivityId, Opaque, Tab, NextN, FH);
	Next -&gt;
	    Next
    end;
search_first(_ActivityId, _Opaque, _Tab, _N, _FH) -&gt;
    '$end_of_table'.

last(ActivityId, Opaque, Tab) -&gt;
    case ?catch_val({Tab, frag_hash}) of
	{'EXIT', _} -&gt;
	    mnesia:last(ActivityId, Opaque, Tab);
	FH -&gt;
	    LastN = FH#frag_state.n_fragments,
	    search_last(ActivityId, Opaque, Tab, LastN, FH)
    end.

search_last(ActivityId, Opaque, Tab, N, FH) when N &gt;= 1 -&gt;
    Frag = n_to_frag_name(Tab, N),
    case mnesia:last(ActivityId, Opaque, Frag) of
	'$end_of_table' -&gt;
	    PrevN = N - 1,
	    search_last(ActivityId, Opaque, Tab, PrevN, FH);
	Prev -&gt;
	    Prev
    end;
search_last(_ActivityId, _Opaque, _Tab, _N, _FH) -&gt;
    '$end_of_table'.

prev(ActivityId, Opaque, Tab, Key) -&gt;
    case ?catch_val({Tab, frag_hash}) of
	{'EXIT', _} -&gt;
	    mnesia:prev(ActivityId, Opaque, Tab, Key);
	FH -&gt;
	    N = key_to_n(FH, Key),
	    Frag = n_to_frag_name(Tab, N),
	    case mnesia:prev(ActivityId, Opaque, Frag, Key) of
		'$end_of_table' -&gt;
		    search_prev(ActivityId, Opaque, Tab, N);
		Prev -&gt;
		    Prev
	    end
    end.

search_prev(ActivityId, Opaque, Tab, N) when N &gt; 1 -&gt;
    PrevN = N - 1,
    PrevFrag = n_to_frag_name(Tab, PrevN),
    case mnesia:last(ActivityId, Opaque, PrevFrag) of
	'$end_of_table' -&gt;
	    search_prev(ActivityId, Opaque, Tab, PrevN);
	Prev -&gt;
	    Prev
    end;
search_prev(_ActivityId, _Opaque, _Tab, _N) -&gt;
    '$end_of_table'.

next(ActivityId, Opaque, Tab, Key) -&gt;
    case ?catch_val({Tab, frag_hash}) of
	{'EXIT', _} -&gt;
	    mnesia:next(ActivityId, Opaque, Tab, Key);
	FH -&gt;
	    N = key_to_n(FH, Key),
	    Frag = n_to_frag_name(Tab, N),
	    case mnesia:next(ActivityId, Opaque, Frag, Key) of
		'$end_of_table' -&gt;
		    search_next(ActivityId, Opaque, Tab, N, FH);
		Prev -&gt;
		    Prev
	    end
    end.

search_next(ActivityId, Opaque, Tab, N, FH) when N &lt; FH#frag_state.n_fragments -&gt;
    NextN = N + 1,
    NextFrag = n_to_frag_name(Tab, NextN),
    case mnesia:first(ActivityId, Opaque, NextFrag) of
	'$end_of_table' -&gt;
	    search_next(ActivityId, Opaque, Tab, NextN, FH);
	Next -&gt;
	    Next
    end;
search_next(_ActivityId, _Opaque, _Tab, _N, _FH) -&gt;
    '$end_of_table'.
</code></pre><h3>mnesia_frag_hash Callback Behavior</h3><pre><code class="">

-module(mnesia_frag_hash).

%% Fragmented Table Hashing callback functions
-export([
	 init_state/2,
	 add_frag/1,
	 del_frag/1,
	 key_to_frag_number/2,
	 match_spec_to_frag_numbers/2
	]).
</code></pre><pre><code class="">

-record(hash_state,
	{n_fragments,
	 next_n_to_split,
	 n_doubles,
	 function}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

init_state(_Tab, State) when State == undefined -&gt;
    #hash_state{n_fragments     = 1,
		next_n_to_split = 1,
		n_doubles       = 0,
		function        = phash2}.

convert_old_state({hash_state, N, P, L}) -&gt;
    #hash_state{n_fragments     = N,
		next_n_to_split = P,
		n_doubles       = L,
		function        = phash}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

add_frag(#hash_state{next_n_to_split = SplitN, n_doubles = L, n_fragments = N} = State) -&gt;
    P = SplitN + 1,
    NewN = N + 1,
    State2 = case power2(L) + 1 of
		 P2 when P2 == P -&gt;
		     State#hash_state{n_fragments      = NewN,
				      n_doubles        = L + 1,
				      next_n_to_split = 1};
		 _ -&gt;
		     State#hash_state{n_fragments     = NewN,
				      next_n_to_split = P}
	     end,
    {State2, [SplitN], [NewN]};
add_frag(OldState) -&gt;
    State = convert_old_state(OldState),
    add_frag(State).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

del_frag(#hash_state{next_n_to_split = SplitN, n_doubles = L, n_fragments = N} = State) -&gt;
    P = SplitN - 1,
    if
	P &lt; 1 -&gt;
	    L2 = L - 1,
	    MergeN = power2(L2),
	    State2 = State#hash_state{n_fragments     = N - 1,
				      next_n_to_split = MergeN,
				      n_doubles       = L2},
	    {State2, [N], [MergeN]};
	true -&gt;
	    MergeN = P,
	    State2 = State#hash_state{n_fragments     = N - 1,
				      next_n_to_split = MergeN},
	    {State2, [N], [MergeN]}
	end;
del_frag(OldState) -&gt;
    State = convert_old_state(OldState),
    del_frag(State).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

key_to_frag_number(#hash_state{function = phash, n_fragments = N, n_doubles = L}, Key) -&gt;
    A = erlang:phash(Key, power2(L + 1)),
    if
	A &gt; N -&gt;
	    A - power2(L);
	true -&gt;
	    A
    end;
key_to_frag_number(#hash_state{function = phash2, n_fragments = N, n_doubles = L}, Key) -&gt;
    A = erlang:phash2(Key, power2(L + 1)) + 1,
    if
	A &gt; N -&gt;
	    A - power2(L);
	true -&gt;
	    A
    end;
key_to_frag_number(OldState, Key) -&gt;
    State = convert_old_state(OldState),
    key_to_frag_number(State, Key).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

match_spec_to_frag_numbers(#hash_state{n_fragments = N} = State, MatchSpec) -&gt;
    case MatchSpec of
	[{HeadPat, _, _}] when is_tuple(HeadPat), tuple_size(HeadPat) &gt; 2 -&gt;
	    KeyPat = element(2, HeadPat),
	    case has_var(KeyPat) of
		false -&gt;
		    [key_to_frag_number(State, KeyPat)];
		true -&gt;
		    lists:seq(1, N)
	    end;
	_ -&gt; 
	    lists:seq(1, N)
    end;
match_spec_to_frag_numbers(OldState, MatchSpec) -&gt;
    State = convert_old_state(OldState),
    match_spec_to_frag_numbers(State, MatchSpec).

power2(Y) -&gt;
    1 bsl Y. % trunc(math:pow(2, Y)).
</code></pre></body></html>