<!doctype html>
<html><head><meta charset="utf-8"><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.0/css/bootstrap.min.css"></head><body style="margin: 4em 10%"><h1>STDLIB User's Guide</h1><h3>Scope</h3><p>The Standard Erlang Libraries application, <em>STDLIB</em>, is mandatory
in the sense that the minimal system based on Erlang/OTP consists of
<em>STDLIB</em> and <em>Kernel</em>.</p><p><em>STDLIB</em> contains the following functional areas:</p><ul><li>Erlang shell</li><li>Command interface</li><li>Query interface</li><li>Interface to standard Erlang I/O servers</li><li>Interface to the Erlang built-in term storage BIFs</li><li>Regular expression matching functions for strings and binaries</li><li>Finite state machine</li><li>Event handling</li><li>Functions for the server of a client-server relation</li><li>Function to control applications in a distributed manner</li><li>Start and control of slave nodes</li><li>Operations on finite sets and relations represented as sets</li><li>Library for handling binary data</li><li>Disk-based term storage</li><li>List processing</li><li>Maps processing</li></ul><h3>Prerequisites</h3><p>It is assumed that the reader is familiar with the Erlang programming
language.</p><p>The I/O protocol in Erlang enables bi-directional communication between
clients and servers.</p><ul><li> <p>The I/O server is a process that handles the requests and performs
the requested task on, for example, an I/O device.</p> </li><li> <p>The client is any Erlang process wishing to read or write data from/to
the I/O device.</p> </li></ul><p>The common I/O protocol has been present in OTP since the beginning, but
has been undocumented and has also evolved over the years. In an
addendum to Robert Virding's rationale, the original I/O protocol is
described. This section describes the current I/O protocol.</p><p>The original I/O protocol was simple and flexible. Demands for memory
efficiency and execution time efficiency have triggered extensions
to the protocol over the years, making the protocol larger and somewhat
less easy to implement than the original. It can certainly be argued that
the current protocol is too complex, but this section describes how it
looks today, not how it should have looked.</p><p>The basic ideas from the original protocol still hold. The I/O server
and client communicate with one single, rather simplistic protocol and no
server state is ever present in the client. Any I/O server can be used
together with any client code, and the client code does not need to be
aware of the I/O device that the I/O server communicates with.</p><h3>Protocol Basics</h3><p>As described in Robert's paper, I/O servers and clients communicate
using <strong>io_request</strong>/<strong>io_reply</strong> tuples as follows:</p><pre>
{io_request, From, ReplyAs, Request}
{io_reply, ReplyAs, Reply}</pre><p>The client sends an <strong>io_request</strong> tuple to the I/O server and the
server eventually sends a corresponding <strong>io_reply</strong> tuple.</p><ul><li> <p><strong>From</strong> is the <strong>pid()</strong> of the client, the process which
the I/O server sends the I/O reply to.</p> </li><li> <p><strong>ReplyAs</strong> can be any datum and is returned in the
corresponding <strong>io_reply</strong>. The
<a href="./io">stdlib/io</a> module monitors the
the I/O server and uses the monitor reference as the <strong>ReplyAs</strong>
datum. A more complicated client can have many outstanding I/O
requests to the same I/O server and can use different references (or
something else) to differentiate among the incoming I/O replies.
Element <strong>ReplyAs</strong> is to be considered opaque by the I/O
server.</p> <p>Notice that the <strong>pid()</strong> of the I/O server is not explicitly
present in tuple <strong>io_reply</strong>. The reply can be sent from any
process, not necessarily the actual I/O server.</p> </li><li> <p><strong>Request</strong> and <strong>Reply</strong> are described below.</p> </li></ul><p>When an I/O server receives an <strong>io_request</strong> tuple, it acts upon the
<strong>Request</strong> part and eventually sends an <strong>io_reply</strong> tuple with
the corresponding <strong>Reply</strong> part.</p><h3>Output Requests</h3><p>To output characters on an I/O device, the following <strong>Request</strong>s
exist:</p><pre>
{put_chars, Encoding, Characters}
{put_chars, Encoding, Module, Function, Args}</pre><ul><li> <p><strong>Encoding</strong> is <strong>unicode</strong> or <strong>latin1</strong>, meaning that the
characters are (in case of binaries) encoded as UTF-8 or ISO Latin-1
(pure bytes). A well-behaved I/O server is also to return an error
indication if list elements contain integers &gt; 255
when <strong>Encoding</strong> is set to <strong>latin1</strong>.</p> <p>Notice that this does not in any way tell how characters are to be
put on the I/O device or handled by the I/O server. Different I/O
servers can handle the characters however they want, this only tells
the I/O server which format the data is expected to have. In the
<strong>Module</strong>/<strong>Function</strong>/<strong>Args</strong> case, <strong>Encoding</strong> tells
which format the designated function produces.</p> <p>Notice also that byte-oriented data is simplest sent using the ISO
Latin-1 encoding.</p> </li><li> <p><strong>Characters</strong> are the data to be put on the I/O device. If
<strong>Encoding</strong> is <strong>latin1</strong>, this is an <strong>iolist()</strong>. If
<strong>Encoding</strong> is <strong>unicode</strong>, this is an Erlang standard mixed
Unicode list (one integer in a list per character, characters in
binaries represented as UTF-8).</p> </li><li> <p><strong>Module</strong>, <strong>Function</strong>, and <strong>Args</strong> denote a function
that is called to produce the data (like
<a href="../stdlib/io_lib#format/2">stdlib/io_lib#format/2</a>).
</p> <p><strong>Args</strong> is a list of arguments to the function. The function is
to produce data in the specified <strong>Encoding</strong>. The I/O server is
to call the function as <strong>apply(Mod, Func, Args)</strong> and put the
returned data on the I/O device as if it was sent in a
<strong>{put_chars, Encoding, Characters}</strong> request. If the function
returns anything else than a binary or list, or throws an exception,
an error is to be sent back to the client.</p> </li></ul><p>The I/O server replies to the client with an <strong>io_reply</strong> tuple, where
element <strong>Reply</strong> is one of:</p><pre>
ok
{error, Error}</pre><ul><li><strong>Error</strong> describes the error to the client, which can do whatever it wants with it. The <a href="./io">stdlib/io</a> module typically returns it "as is".</li></ul><p>For backward compatibility, the following <strong>Request</strong>s are also to be
handled by an I/O server (they are not to be present after
Erlang/OTP R15B):</p><pre>
{put_chars, Characters}
{put_chars, Module, Function, Args}</pre><p>These are to behave as <strong>{put_chars, latin1, Characters}</strong> and
<strong>{put_chars, latin1, Module, Function, Args}</strong>, respectively.</p><h3>Input Requests</h3><p>To read characters from an I/O device, the following <strong>Request</strong>s
exist:</p><pre>
{get_until, Encoding, Prompt, Module, Function, ExtraArgs}</pre><ul><li> <p><strong>Encoding</strong> denotes how data is to be sent back to the client
and what data is sent to the function denoted by
<strong>Module</strong>/<strong>Function</strong>/<strong>ExtraArgs</strong>. If the function
supplied returns data as a list, the data is converted to this
encoding. If the function supplied returns data in some other format,
no conversion can be done, and it is up to the client-supplied
function to return data in a proper way.</p> <p>If <strong>Encoding</strong> is <strong>latin1</strong>, lists of integers <strong>0..255</strong>
or binaries containing plain bytes are sent back to the client when
possible. If <strong>Encoding</strong> is <strong>unicode</strong>, lists with integers
in the whole Unicode range or binaries encoded in UTF-8 are sent to
the client. The user-supplied function always sees lists of
integers, never binaries, but the list can contain numbers &gt; 255
if <strong>Encoding</strong> is <strong>unicode</strong>.</p> </li><li> <p><strong>Prompt</strong> is a list of characters (not mixed, no binaries) or an
atom to be output as a prompt for input on the I/O device.
<strong>Prompt</strong> is often ignored by the I/O server; if set to <strong>''</strong>,
it is always to be ignored (and results in nothing being written to
the I/O device).</p> </li><li> <p><strong>Module</strong>, <strong>Function</strong>, and <strong>ExtraArgs</strong> denote a
function and arguments to determine when enough data is written. The
function is to take two more arguments, the last state, and a list of
characters. The function is to return one of:</p> <pre>
{done, Result, RestChars}
{more, Continuation}</pre> <p><strong>Result</strong> can be any Erlang term, but if it is a <strong>list()</strong>,
the I/O server can convert it to a <strong>binary()</strong> of appropriate
format before returning it to the client, if the I/O server is set in
binary mode (see below).</p> <p>The function is called with the data the I/O server finds on its I/O
device, returning one of:</p> <ul><li> <p><strong>{done, Result, RestChars}</strong> when enough data is read. In
this case <strong>Result</strong> is sent to the client and <strong>RestChars</strong>
is kept in the I/O server as a buffer for later input.</p> </li><li> <p><strong>{more, Continuation}</strong>, which indicates that more
characters are needed to complete the request.</p> </li></ul> <p><strong>Continuation</strong> is sent as the state in later calls to the
function when more characters are available. When no more characters
are available, the function must return <strong>{done, eof, Rest}</strong>. The
initial state is the empty list. The data when an end of file is
reached on the IO device is the atom <strong>eof</strong>.</p> <p>An emulation of the <strong>get_line</strong> request can be (inefficiently)
implemented using the following functions:</p> <pre><code class="">
-module(demo).
-export([until_newline/3, get_line/1]).

until_newline(_ThisFar,eof,_MyStopCharacter) -&gt;
    {done,eof,[]};
until_newline(ThisFar,CharList,MyStopCharacter) -&gt;
    case
        lists:splitwith(fun(X) -&gt; X =/= MyStopCharacter end,  CharList)
    of
	{L,[]} -&gt;
            {more,ThisFar++L};
	{L2,[MyStopCharacter|Rest]} -&gt;
	    {done,ThisFar++L2++[MyStopCharacter],Rest}
    end.

get_line(IoServer) -&gt;
    IoServer ! {io_request,
                self(),
                IoServer,
                {get_until, unicode, '', ?MODULE, until_newline, [$\n]}},
    receive
        {io_reply, IoServer, Data} -&gt;
	    Data
    end.</code></pre> <p>Notice that the last element in the <strong>Request</strong> tuple
(<strong>[$\n]</strong>) is appended to the argument list when the function is
called. The function is to be called like
<strong>apply(Module, Function, [ State, Data | ExtraArgs ])</strong> by the
I/O server.</p> </li></ul><p>A fixed number of characters is requested using the following
<strong>Request</strong>:</p><pre>
{get_chars, Encoding, Prompt, N}</pre><ul><li> <p><strong>Encoding</strong> and <strong>Prompt</strong> as for <strong>get_until</strong>.</p> </li><li> <p><strong>N</strong> is the number of characters to be read from the I/O
device.</p> </li></ul><p>A single line (as in former example) is requested with the
following <strong>Request</strong>:</p><pre>
{get_line, Encoding, Prompt}</pre><ul><li><strong>Encoding</strong> and <strong>Prompt</strong> as for <strong>get_until</strong>.</li></ul><p>Clearly, <strong>get_chars</strong> and <strong>get_line</strong> could be implemented with
the <strong>get_until</strong> request (and indeed they were originally), but
demands for efficiency have made these additions necessary.</p><p>The I/O server replies to the client with an <strong>io_reply</strong> tuple, where
element <strong>Reply</strong> is one of:</p><pre>
Data
eof
{error, Error}</pre><ul><li> <p><strong>Data</strong> is the characters read, in list or binary form
(depending on the I/O server mode, see the next section).</p> </li><li> <p><strong>eof</strong> is returned when input end is reached and no more data is
available to the client process.</p> </li><li> <p><strong>Error</strong> describes the error to the client, which can do
whatever it wants with it. The
<a href="./io">stdlib/io</a> module typically
returns it as is.</p> </li></ul><p>For backward compatibility, the following <strong>Request</strong>s are also to be
handled by an I/O server (they are not to be present after
Erlang/OTP R15B):</p><pre>
{get_until, Prompt, Module, Function, ExtraArgs}
{get_chars, Prompt, N}
{get_line, Prompt}</pre><p>These are to behave as
<strong>{get_until, latin1, Prompt, Module, Function, ExtraArgs}</strong>,
<strong>{get_chars, latin1, Prompt, N}</strong>, and
<strong>{get_line, latin1, Prompt}</strong>, respectively.</p><h3>I/O Server Modes</h3><p>Demands for efficiency when reading data from an I/O server has not only
lead to the addition of the <strong>get_line</strong> and <strong>get_chars</strong> requests,
but has also added the concept of I/O server options. No options are
mandatory to implement, but all I/O servers in the Erlang standard
libraries honor the <strong>binary</strong> option, which allows element
<strong>Data</strong> of the <strong>io_reply</strong> tuple to be a binary instead of a list
<em>when possible</em>. If the data is sent as a binary, Unicode data is
sent in the standard Erlang Unicode format, that is, UTF-8 (notice that
the function of the <strong>get_until</strong> request still gets list data
regardless of the I/O server mode).</p><p>Notice that the <strong>get_until</strong> request allows for a function with the
data specified as always being a list. Also, the return value data from
such a function can be of any type (as is indeed the case when an
<a href="../stdlib/io#fread/2">stdlib/io#fread/2</a>
request is sent to an I/O server).
The client must be prepared for data received as
answers to those requests to be in various forms. However, the I/O
server is to convert the results to binaries whenever possible (that is,
when the function supplied to <strong>get_until</strong> returns a list). This is
done in the example in section
<a href="#example_io_server">An Annotated and Working Example I/O Server</a>.
</p><p>An I/O server in binary mode affects the data sent to the client, so that
it must be able to handle binary data. For convenience, the modes of an
I/O server can be set and retrieved using the following I/O requests:</p><pre>
{setopts, Opts}</pre><ul><li><strong>Opts</strong> is a list of options in the format recognized by the <a href="./proplists">stdlib/proplists</a> module (and by the I/O server).</li></ul><p>As an example, the I/O server for the interactive shell (in
<strong>group.erl</strong>) understands the following options:</p><pre>
{binary, boolean()} (or binary/list)
{echo, boolean()}
{expand_fun, fun()}
{encoding, unicode/latin1} (or unicode/latin1)</pre><p>Options <strong>binary</strong> and <strong>encoding</strong> are common for all I/O servers
in OTP, while <strong>echo</strong> and <strong>expand</strong> are valid only for this I/O
server. Option <strong>unicode</strong> notifies how characters are put on the
physical I/O device, that is, if the terminal itself is Unicode-aware.
It does not affect how characters are sent in the I/O protocol, where
each request contains encoding information for the provided or returned
data.</p><p>The I/O server is to send one of the following as <strong>Reply</strong>:</p><pre>
ok
{error, Error}</pre><p>An error (preferably <strong>enotsup</strong>) is to be expected if the option is
not supported by the I/O server (like if an <strong>echo</strong> option is sent in
a <strong>setopts</strong> request to a plain file).</p><p>To retrieve options, the following request is used:</p><pre>
getopts</pre><p>This request asks for a complete list of all options supported by the
I/O server as well as their current values.</p><p>The I/O server replies:</p><pre>
OptList
{error, Error}</pre><ul><li><strong>OptList</strong> is a list of tuples <strong>{Option, Value}</strong>, where <strong>Option</strong> always is an atom.</li></ul><h3>Multiple I/O Requests</h3><p>The <strong>Request</strong> element can in itself contain many <strong>Request</strong>s
by using the following format:</p><pre>
{requests, Requests}</pre><ul><li><strong>Requests</strong> is a list of valid <strong>io_request</strong> tuples for the protocol. They must be executed in the order that they appear in the list. The execution is to continue until one of the requests results in an error or the list is consumed. The result of the last request is sent back to the client.</li></ul><p>The I/O server can, for a list of requests, send any of the following
valid results in the reply, depending on the requests in the list:</p><pre>
ok
{ok, Data}
{ok, Options}
{error, Error}</pre><h3>Optional I/O Request</h3><p>The following I/O request is optional to implement and a client is to
be prepared for an error return:</p><pre>
{get_geometry, Geometry}</pre><ul><li><strong>Geometry</strong> is the atom <strong>rows</strong> or the atom <strong>columns</strong>.</li></ul><p>The I/O server is to send the <strong>Reply</strong> as:</p><pre>
{ok, N}
{error, Error}</pre><ul><li><strong>N</strong> is the number of character rows or columns that the I/O device has, if applicable to the I/O device handled by the I/O server, otherwise <strong>{error, enotsup}</strong> is a good answer.</li></ul><h3>Unimplemented Request Types</h3><p>If an I/O server encounters a request that it does not recognize (that
is, the <strong>io_request</strong> tuple has the expected format, but the
<strong>Request</strong> is unknown), the I/O server is to send a valid reply with
the error tuple:</p><pre>
{error, request}</pre><p>This makes it possible to extend the protocol with optional requests
and for the clients to be somewhat backward compatible.</p><h3>An Annotated and Working Example I/O Server</h3><a name="example_io_server"></a><p>An I/O server is any process capable of handling the I/O protocol. There
is no generic I/O server behavior, but could well be. The framework is
simple, a process handling incoming requests, usually both I/O-requests
and other I/O device-specific requests (positioning, closing, and so on).
</p><p>The example I/O server stores characters in an ETS table, making
up a fairly crude RAM file.</p><p>The module begins with the usual directives, a function to start the
I/O server and a main loop handling the requests:</p><pre><code class="">
-module(ets_io_server).

-export([start_link/0, init/0, loop/1, until_newline/3, until_enough/3]).

-define(CHARS_PER_REC, 10).

-record(state, {
	  table,
	  position, % absolute
	  mode % binary | list
	 }).

start_link() -&gt;
    spawn_link(?MODULE,init,[]).

init() -&gt;
    Table = ets:new(noname,[ordered_set]),
    ?MODULE:loop(#state{table = Table, position = 0, mode=list}).

loop(State) -&gt;
    receive
	{io_request, From, ReplyAs, Request} -&gt;
	    case request(Request,State) of
		{Tag, Reply, NewState} when Tag =:= ok; Tag =:= error -&gt;
		    reply(From, ReplyAs, Reply),
		    ?MODULE:loop(NewState);
		{stop, Reply, _NewState} -&gt;
		    reply(From, ReplyAs, Reply),
		    exit(Reply)
	    end;
	%% Private message
	{From, rewind} -&gt;
	    From ! {self(), ok},
	    ?MODULE:loop(State#state{position = 0});
	_Unknown -&gt;
	    ?MODULE:loop(State)
    end.</code></pre><p>The main loop receives messages from the client (which can use the
the <a href="./io">stdlib/io</a> module to send
requests). For each request, the function <strong>request/2</strong> is called and a
reply is eventually sent using function <strong>reply/3</strong>.</p><p>The "private" message <strong>{From, rewind}</strong> results in the
current position in the pseudo-file to be reset to <strong>0</strong> (the beginning
of the "file"). This is a typical example of I/O device-specific
messages not being part of the I/O protocol. It is usually a bad idea to
embed such private messages in <strong>io_request</strong> tuples, as that can
confuse the reader.</p><p>First, we examine the reply function:</p><pre><code class="">
reply(From, ReplyAs, Reply) -&gt;
    From ! {io_reply, ReplyAs, Reply}.</code></pre><p>It sends the <strong>io_reply</strong> tuple back to the client, providing element
<strong>ReplyAs</strong> received in the request along with the result of the
request, as described earlier.</p><p>We need to handle some requests. First the requests for writing
characters:</p><pre><code class="">
request({put_chars, Encoding, Chars}, State) -&gt;
    put_chars(unicode:characters_to_list(Chars,Encoding),State);
request({put_chars, Encoding, Module, Function, Args}, State) -&gt;
    try
	request({put_chars, Encoding, apply(Module, Function, Args)}, State)
    catch
	_:_ -&gt;
	    {error, {error,Function}, State}
    end;</code></pre><p>The <strong>Encoding</strong> says how the characters in the request are
represented. We want to store the characters as lists in the ETS
table, so we convert them to lists using function
<a href="../stdlib/unicode#characters_to_list/2">stdlib/unicode#characters_to_list/2</a>.
The conversion function conveniently accepts the encoding types
<strong>unicode</strong> and <strong>latin1</strong>, so we can use <strong>Encoding</strong> directly.</p><p>When <strong>Module</strong>, <strong>Function</strong>, and <strong>Arguments</strong> are provided,
we apply it and do the same with the result as if the data was provided
directly.</p><p>We handle the requests for retrieving data:</p><pre><code class="">
request({get_until, Encoding, _Prompt, M, F, As}, State) -&gt;
    get_until(Encoding, M, F, As, State);
request({get_chars, Encoding, _Prompt, N}, State) -&gt;
    %% To simplify the code, get_chars is implemented using get_until
    get_until(Encoding, ?MODULE, until_enough, [N], State);
request({get_line, Encoding, _Prompt}, State) -&gt;
    %% To simplify the code, get_line is implemented using get_until
    get_until(Encoding, ?MODULE, until_newline, [$\n], State);</code></pre><p>Here we have cheated a little by more or less only implementing
<strong>get_until</strong> and using internal helpers to implement <strong>get_chars</strong>
and <strong>get_line</strong>. In production code, this can be inefficient, but
that depends on the frequency of the different requests. Before we start
implementing functions <strong>put_chars/2</strong> and <strong>get_until/5</strong>, we
examine the few remaining requests:</p><pre><code class="">
request({get_geometry,_}, State) -&gt;
    {error, {error,enotsup}, State};
request({setopts, Opts}, State) -&gt;
    setopts(Opts, State);
request(getopts, State) -&gt;
    getopts(State);
request({requests, Reqs}, State) -&gt;
     multi_request(Reqs, {ok, ok, State});</code></pre><p>Request <strong>get_geometry</strong> has no meaning for this I/O server, so the
reply is <strong>{error, enotsup}</strong>. The only option we handle is
<strong>binary</strong>/<strong>list</strong>, which is done in separate functions.</p><p>The multi-request tag (<strong>requests</strong>) is handled in a separate loop
function applying the requests in the list one after another, returning
the last result.</p><p>We need to handle backward compatibility and the
<a href="./file">kernel/file</a> module (which
uses the old requests until backward compatibility with pre-R13 nodes is
no longer needed). Notice that the I/O server does not work with a simple
<strong>file:write/2</strong> if these are not added:</p><pre><code class="">
request({put_chars,Chars}, State) -&gt;
    request({put_chars,latin1,Chars}, State);
request({put_chars,M,F,As}, State) -&gt;
    request({put_chars,latin1,M,F,As}, State);
request({get_chars,Prompt,N}, State) -&gt;
    request({get_chars,latin1,Prompt,N}, State);
request({get_line,Prompt}, State) -&gt;
    request({get_line,latin1,Prompt}, State);
request({get_until, Prompt,M,F,As}, State) -&gt;
    request({get_until,latin1,Prompt,M,F,As}, State);</code></pre><p><strong>{error, request}</strong> must be returned if the request is not
recognized:</p><pre><code class="">
request(_Other, State) -&gt;
    {error, {error, request}, State}.</code></pre><p>Next we handle the different requests, first the fairly generic
multi-request type:</p><pre><code class="">
multi_request([R|Rs], {ok, _Res, State}) -&gt;
    multi_request(Rs, request(R, State));
multi_request([_|_], Error) -&gt;
    Error;
multi_request([], Result) -&gt;
    Result.</code></pre><p>We loop through the requests one at the time, stopping when we either
encounter an error or the list is exhausted. The last return value is
sent back to the client (it is first returned to the main loop and then
sent back by function <strong>io_reply</strong>).</p><p>Requests <strong>getopts</strong> and <strong>setopts</strong> are also simple to handle.
We only change or read the state record:</p><pre><code class="">
setopts(Opts0,State) -&gt;
    Opts = proplists:unfold(
	     proplists:substitute_negations(
	       [{list,binary}], 
	       Opts0)),
    case check_valid_opts(Opts) of
	true -&gt;
	        case proplists:get_value(binary, Opts) of
		    true -&gt;
			{ok,ok,State#state{mode=binary}};
		    false -&gt;
			{ok,ok,State#state{mode=binary}};
		    _ -&gt;
			{ok,ok,State}
		end;
	false -&gt;
	    {error,{error,enotsup},State}
    end.
check_valid_opts([]) -&gt;
    true;
check_valid_opts([{binary,Bool}|T]) when is_boolean(Bool) -&gt;
    check_valid_opts(T);
check_valid_opts(_) -&gt;
    false.

getopts(#state{mode=M} = S) -&gt;
    {ok,[{binary, case M of
		      binary -&gt;
			  true;
		      _ -&gt;
			  false
		  end}],S}.</code></pre><p>As a convention, all I/O servers handle both <strong>{setopts, [binary]}</strong>,
<strong>{setopts, [list]}</strong>, and <strong>{setopts,[{binary, boolean()}]}</strong>,
hence the trick with <strong>proplists:substitute_negations/2</strong> and
<strong>proplists:unfold/1</strong>. If invalid options are sent to us, we send
<strong>{error, enotsup}</strong> back to the client.</p><p>Request <strong>getopts</strong> is to return a list of <strong>{Option, Value}</strong>
tuples. This has the twofold function of providing both the current values
and the available options of this I/O server. We have only one option, and
hence return that.</p><p>So far this I/O server is fairly generic (except for request
<strong>rewind</strong> handled in the main loop and the creation of an ETS
table). Most I/O servers contain code similar to this one.</p><p>To make the example runnable, we start implementing the reading and
writing of the data to/from the ETS table. First function
<strong>put_chars/3</strong>:</p><pre><code class="">
put_chars(Chars, #state{table = T, position = P} = State) -&gt;
    R = P div ?CHARS_PER_REC,
    C = P rem ?CHARS_PER_REC,
    [ apply_update(T,U) || U &lt;- split_data(Chars, R, C) ],
    {ok, ok, State#state{position = (P + length(Chars))}}.</code></pre><p>We already have the data as (Unicode) lists and therefore only split
the list in runs of a predefined size and put each run in the table at
the current position (and forward). Functions <strong>split_data/3</strong> and
<strong>apply_update/2</strong> are implemented below.</p><p>Now we want to read data from the table. Function <strong>get_until/5</strong>
reads data and applies the function until it says that it is done. The
result is sent back to the client:</p><pre><code class="">
get_until(Encoding, Mod, Func, As, 
	  #state{position = P, mode = M, table = T} = State) -&gt;
    case get_loop(Mod,Func,As,T,P,[]) of
	{done,Data,_,NewP} when is_binary(Data); is_list(Data) -&gt;
	    if
		M =:= binary -&gt; 
		    {ok, 
		     unicode:characters_to_binary(Data, unicode, Encoding),
		     State#state{position = NewP}};
		true -&gt;
		    case check(Encoding, 
		               unicode:characters_to_list(Data, unicode))
                    of
			{error, _} = E -&gt;
			    {error, E, State};
			List -&gt;
			    {ok, List,
			     State#state{position = NewP}}
		    end
	    end;
	{done,Data,_,NewP} -&gt;
	    {ok, Data, State#state{position = NewP}};
	Error -&gt;
	    {error, Error, State}
    end.

get_loop(M,F,A,T,P,C) -&gt;
    {NewP,L} = get(P,T),
    case catch apply(M,F,[C,L|A]) of
	{done, List, Rest} -&gt;
	    {done, List, [], NewP - length(Rest)};
	{more, NewC} -&gt;
	    get_loop(M,F,A,T,NewP,NewC);
	_ -&gt;
	    {error,F}
    end.</code></pre><p>Here we also handle the mode (<strong>binary</strong> or <strong>list</strong>) that can be
set by request <strong>setopts</strong>. By default, all OTP I/O servers send data
back to the client as lists, but switching mode to <strong>binary</strong> can
increase efficiency if the I/O server handles it in an appropriate way.
The implementation of <strong>get_until</strong> is difficult to get efficient, as
the supplied function is defined to take lists as arguments, but
<strong>get_chars</strong> and <strong>get_line</strong> can be optimized for binary mode.
However, this example does not optimize anything.</p><p>It is important though that the returned data is of the correct type
depending on the options set. We therefore convert the lists to binaries
in the correct encoding <em>if possible</em> before returning. The
function supplied in the <strong>get_until</strong> request tuple can, as its final
result return anything, so only functions returning lists can get them
converted to binaries. If the request contains encoding tag
<strong>unicode</strong>, the lists can contain all Unicode code points and the
binaries are to be in UTF-8. If the encoding tag is <strong>latin1</strong>, the
client is only to get characters in the range <strong>0..255</strong>. Function
<strong>check/2</strong> takes care of not returning arbitrary Unicode code points
in lists if the encoding was specified as <strong>latin1</strong>. If the function
does not return a list, the check cannot be performed and the result is
that of the supplied function untouched.</p><p>To manipulate the table we implement the following utility functions:</p><pre><code class="">
check(unicode, List) -&gt;
    List;
check(latin1, List) -&gt;
    try 
	[ throw(not_unicode) || X &lt;- List,
				X &gt; 255 ],
	List
    catch
	throw:_ -&gt;
	    {error,{cannot_convert, unicode, latin1}}
    end.</code></pre><p>The function check provides an error tuple if Unicode code points &gt;
255 are to be returned if the client requested <strong>latin1</strong>.</p><p>The two functions <strong>until_newline/3</strong> and <strong>until_enough/3</strong> are
helpers used together with function <strong>get_until/5</strong> to implement
<strong>get_chars</strong> and <strong>get_line</strong> (inefficiently):</p><pre><code class="">
until_newline([],eof,_MyStopCharacter) -&gt;
    {done,eof,[]};
until_newline(ThisFar,eof,_MyStopCharacter) -&gt;
    {done,ThisFar,[]};
until_newline(ThisFar,CharList,MyStopCharacter) -&gt;
    case
        lists:splitwith(fun(X) -&gt; X =/= MyStopCharacter end,  CharList)
    of
	{L,[]} -&gt;
            {more,ThisFar++L};
	{L2,[MyStopCharacter|Rest]} -&gt;
	    {done,ThisFar++L2++[MyStopCharacter],Rest}
    end.

until_enough([],eof,_N) -&gt;
    {done,eof,[]};
until_enough(ThisFar,eof,_N) -&gt;
    {done,ThisFar,[]};
until_enough(ThisFar,CharList,N) 
  when length(ThisFar) + length(CharList) &gt;= N -&gt;
    {Res,Rest} = my_split(N,ThisFar ++ CharList, []),
    {done,Res,Rest};
until_enough(ThisFar,CharList,_N) -&gt;
    {more,ThisFar++CharList}.</code></pre><p>As can be seen, the functions above are just the type of functions that
are to be provided in <strong>get_until</strong> requests.</p><p>To complete the I/O server, we only need to read and write the table in
an appropriate way:</p><pre><code class="">
get(P,Tab) -&gt;
    R = P div ?CHARS_PER_REC,
    C = P rem ?CHARS_PER_REC,
    case ets:lookup(Tab,R) of
	[] -&gt;
	    {P,eof};
	[{R,List}] -&gt;
	    case my_split(C,List,[]) of
		{_,[]} -&gt;
		    {P+length(List),eof};
		{_,Data} -&gt;
		    {P+length(Data),Data}
	    end
    end.

my_split(0,Left,Acc) -&gt;
    {lists:reverse(Acc),Left};
my_split(_,[],Acc) -&gt;
    {lists:reverse(Acc),[]};
my_split(N,[H|T],Acc) -&gt;
    my_split(N-1,T,[H|Acc]).

split_data([],_,_) -&gt;
    [];
split_data(Chars, Row, Col) -&gt;
    {This,Left} = my_split(?CHARS_PER_REC - Col, Chars, []),
    [ {Row, Col, This} | split_data(Left, Row + 1, 0) ].

apply_update(Table, {Row, Col, List}) -&gt;     
    case ets:lookup(Table,Row) of
	[] -&gt;
	    ets:insert(Table,{Row, lists:duplicate(Col,0) ++ List});
	[{Row, OldData}] -&gt;
	    {Part1,_} = my_split(Col,OldData,[]),
	    {_,Part2} = my_split(Col+length(List),OldData,[]),
	    ets:insert(Table,{Row, Part1 ++ List ++ Part2})
    end.</code></pre><p>The table is read or written in chunks of <strong>?CHARS_PER_REC</strong>,
overwriting when necessary. The implementation is clearly not efficient,
it is just working.</p><p>This concludes the example. It is fully runnable and you can read or
write to the I/O server by using, for example, the
<a href="./io">stdlib/io</a> module or even the
<a href="./file">kernel/file</a> module. It is
as simple as that to implement a fully fledged I/O server in Erlang.</p><h3>Unicode Implementation</h3><p>Implementing support for Unicode character sets is an ongoing process.
The Erlang Enhancement Proposal (EEP) 10 outlined the basics of Unicode
support and specified a default encoding in binaries that all
Unicode-aware modules are to handle in the future.</p><p>Here is an overview what has been done so far:</p><ul><li><p>The functionality described in EEP10 was implemented
in Erlang/OTP R13A.</p></li><li><p>Erlang/OTP R14B01 added support for Unicode
filenames, but it was not complete and was by default
disabled on platforms where no guarantee was given for the
filename encoding.</p></li><li><p>With Erlang/OTP R16A came support for UTF-8 encoded
source code, with enhancements to many of the applications to
support both Unicode encoded filenames and support for UTF-8
encoded files in many circumstances. Most notable is the
support for UTF-8 in files read by <a href="../kernel/file#consult/1">kernel/file#consult/1</a>,
release handler support for UTF-8, and more support for
Unicode character sets in the I/O system.</p></li><li><p>In Erlang/OTP 17.0, the encoding default for Erlang
source files was switched to UTF-8.</p></li><li><p>In Erlang/OTP 20.0, atoms and function can contain
Unicode characters. Module names, application names, and node
names are still restricted to the ISO Latin-1 range.</p> <p>Support was added for normalizations forms in
<strong>unicode</strong> and the <strong>string</strong> module now handles
utf8-encoded binaries.</p></li></ul><p>This section outlines the current Unicode support and gives some
recipes for working with Unicode data.</p><h3>Understanding Unicode</h3><p>Experience with the Unicode support in Erlang has made it clear that
understanding Unicode characters and encodings is not as easy as one
would expect. The complexity of the field and the implications of the
standard require thorough understanding of concepts rarely before
thought of.</p><p>Also, the Erlang implementation requires understanding of
concepts that were never an issue for many (Erlang) programmers. To
understand and use Unicode characters requires that you study the
subject thoroughly, even if you are an experienced programmer.</p><p>As an example, contemplate the issue of converting between upper and
lower case letters. Reading the standard makes you realize that there is
not a simple one to one mapping in all scripts, for example:</p><ul><li> <p>In German, the letter "Ã" (sharp s) is in lower case, but the
uppercase equivalent is "SS".</p> </li><li> <p>In Greek, the letter "Î£" has two different lowercase forms,
"Ï" in word-final position and "Ï" elsewhere.</p> </li><li> <p>In Turkish, both dotted and dotless "i" exist in lower case and
upper case forms.</p> </li><li> <p>Cyrillic "I" has usually no lowercase form.</p> </li><li> <p>Languages with no concept of upper case (or lower case).</p> </li></ul><p>So, a conversion function must know not only one character at a
time, but possibly the whole sentence, the natural language to
translate to, the differences in input and output string length,
and so on.  Erlang/OTP has currently no Unicode
<strong>uppercase</strong>/<strong>lowercase</strong> functionality with language
specific handling, but publicly available libraries address these
issues.</p><p>Another example is the accented characters, where the same
glyph has two different representations. The Swedish letter "Ã¶" is
one example.  The Unicode standard has a code point for it, but
you can also write it as "o" followed by "U+0308" (Combining
Diaeresis, with the simplified meaning that the last letter is to
have "Â¨" above). They have the same glyph, user perceived
character. They are for most purposes the same, but have different
representations. For example, MacOS X converts all filenames to
use Combining Diaeresis, while most other programs (including
Erlang) try to hide that by doing the opposite when, for example,
listing directories.  However it is done, it is usually important
to normalize such characters to avoid confusion.
</p><p>The list of examples can be made long. One need a kind of knowledge that
was not needed when programs only considered one or two languages. The
complexity of human languages and scripts has certainly made this a
challenge when constructing a universal standard. Supporting Unicode
properly in your program will require effort.</p><h3>What Unicode Is</h3><p>Unicode is a standard defining code points (numbers) for all known,
living or dead, scripts. In principle, every symbol used in any
language has a Unicode code point. Unicode code points are defined and
published by the Unicode Consortium, which is a non-profit
organization.</p><p>Support for Unicode is increasing throughout the world of computing, as
the benefits of one common character set are overwhelming when programs
are used in a global environment. Along with the base of the standard,
the code points for all the scripts, some <em>encoding standards</em> are
available.</p><p>It is vital to understand the difference between encodings and Unicode
characters. Unicode characters are code points according to the Unicode
standard, while the encodings are ways to represent such code points. An
encoding is only a standard for representation. UTF-8 can, for example,
be used to represent a very limited part of the Unicode character set
(for example ISO-Latin-1) or the full Unicode range. It is only an
encoding format.</p><p>As long as all character sets were limited to 256 characters, each
character could be stored in one single byte, so there was more or less
only one practical encoding for the characters. Encoding each character
in one byte was so common that the encoding was not even named. With the
Unicode system there are much more than 256 characters, so a common way
is needed to represent these. The common ways of representing the code
points are the encodings. This means a whole new concept to the
programmer, the concept of character representation, which was a
non-issue earlier.</p><p>Different operating systems and tools support different encodings. For
example, Linux and MacOS X have chosen the UTF-8 encoding, which is
backward compatible with 7-bit ASCII and therefore affects programs
written in plain English the least. Windows supports a limited version
of UTF-16, namely all the code planes where the characters can be
stored in one single 16-bit entity, which includes most living
languages.</p><p>The following are the most widely spread encodings:</p><dl><dt>Bytewise representation</dt><dd> <p>This is not a proper Unicode representation, but the representation
used for characters before the Unicode standard. It can still be used
to represent character code points in the Unicode standard with
numbers &lt; 256, which exactly corresponds to the ISO Latin-1
character set. In Erlang, this is commonly denoted <strong>latin1</strong>
encoding, which is slightly misleading as ISO Latin-1 is a
character code range, not an encoding.</p> </dd><dt>UTF-8</dt><dd> <p>Each character is stored in one to four bytes depending on code
point. The encoding is backward compatible with bytewise
representation of 7-bit ASCII, as all 7-bit characters are stored in
one single byte in UTF-8. The characters beyond code point 127 are
stored in more bytes, letting the most significant bit in the first
character indicate a multi-byte character. For details on the
encoding, the RFC is publicly available.</p> <p>Notice that UTF-8 is <em>not</em> compatible with bytewise
representation for code points from 128 through 255, so an ISO
Latin-1 bytewise representation is generally incompatible with
UTF-8.</p> </dd><dt>UTF-16</dt><dd> <p>This encoding has many similarities to UTF-8, but the basic
unit is a 16-bit number. This means that all characters occupy
at least two bytes, and some high numbers four bytes. Some
programs, libraries, and operating systems claiming to use
UTF-16 only allow for characters that can be stored in one
16-bit entity, which is usually sufficient to handle living
languages. As the basic unit is more than one byte, byte-order
issues occur, which is why UTF-16 exists in both a big-endian
and a little-endian variant.</p> <p>In Erlang, the full UTF-16 range is supported when applicable, like
in the <a href="./unicode">stdlib/unicode</a>
module and in the bit syntax.</p> </dd><dt>UTF-32</dt><dd> <p>The most straightforward representation. Each character is stored in
one single 32-bit number. There is no need for escapes or any
variable number of entities for one character. All Unicode code
points can be stored in one single 32-bit entity. As with UTF-16,
there are byte-order issues. UTF-32 can be both big-endian and
little-endian.</p> </dd><dt>UCS-4</dt><dd> <p>Basically the same as UTF-32, but without some Unicode semantics,
defined by IEEE, and has little use as a separate encoding standard.
For all normal (and possibly abnormal) use, UTF-32 and UCS-4 are
interchangeable.</p> </dd></dl><p>Certain number ranges are unused in the Unicode standard and certain
ranges are even deemed invalid. The most notable invalid range is
16#D800-16#DFFF, as the UTF-16 encoding does not allow for encoding of
these numbers. This is possibly because the UTF-16 encoding standard,
from the beginning, was expected to be able to hold all Unicode
characters in one 16-bit entity, but was then extended, leaving a hole
in the Unicode range to handle backward compatibility.</p><p>Code point 16#FEFF is used for Byte Order Marks (BOMs) and use of that
character is not encouraged in other contexts. It is valid though, as
the character "ZWNBS" (Zero Width Non Breaking Space). BOMs are used to
identify encodings and byte order for programs where such parameters are
not known in advance. BOMs are more seldom used than expected, but can
become more widely spread as they provide the means for programs to make
educated guesses about the Unicode format of a certain file.</p><h3>Areas of Unicode Support</h3><p>To support Unicode in Erlang, problems in various areas have been
addressed. This section describes each area briefly and more
thoroughly later in this User's Guide.</p><dl><dt>Representation</dt><dd> <p>To handle Unicode characters in Erlang, a common representation
in both lists and binaries is needed. EEP (10) and the subsequent
initial implementation in Erlang/OTP R13A settled a standard
representation of Unicode characters in Erlang.</p> </dd><dt>Manipulation</dt><dd> <p>The Unicode characters need to be processed by the Erlang
program, which is why library functions must be able to handle
them. In some cases functionality has been added to already
existing interfaces (as the <a href="./string">stdlib/string</a> module now can
handle strings with any code points). In some cases new
functionality or options have been added (as in the <a href="./io">stdlib/io</a> module, the file
handling, the <a href="./unicode">stdlib/unicode</a> module, and
the bit syntax). Today most modules in Kernel and
STDLIB, as well as the VM are Unicode-aware.</p> </dd><dt>File I/O</dt><dd> <p>I/O is by far the most problematic area for Unicode. A file is an
entity where bytes are stored, and the lore of programming has been
to treat characters and bytes as interchangeable. With Unicode
characters, you must decide on an encoding when you want to store
the data in a file. In Erlang, you can open a text file with an
encoding option, so that you can read characters from it rather than
bytes, but you can also open a file for bytewise I/O.</p> <p>The Erlang I/O-system has been designed (or at least used) in a way
where you expect any I/O server to handle any string data.
That is, however, no longer the case when working with Unicode
characters. The Erlang programmer must now know the
capabilities of the device where the data ends up. Also, ports in
Erlang are byte-oriented, so an arbitrary string of (Unicode)
characters cannot be sent to a port without first converting it to an
encoding of choice.</p> </dd><dt>Terminal I/O</dt><dd> <p>Terminal I/O is slightly easier than file I/O. The output is meant
for human reading and is usually Erlang syntax (for example, in the
shell). There exists syntactic representation of any Unicode
character without displaying the glyph (instead written as
<strong>\x</strong>{<strong>HHH</strong>}). Unicode data can therefore usually be
displayed even if the terminal as such does not support the whole
Unicode range.</p> </dd><dt>Filenames</dt><dd> <p>Filenames can be stored as Unicode strings in different ways
depending on the underlying operating system and file system. This
can be handled fairly easy by a program. The problems arise when the
file system is inconsistent in its encodings. For example, Linux
allows files to be named with any sequence of bytes, leaving to each
program to interpret those bytes. On systems where these
"transparent" filenames are used, Erlang must be informed about the
filename encoding by a startup flag. The default is bytewise
interpretation, which is usually wrong, but allows for interpretation
of <em>all</em> filenames.</p> <p>The concept of "raw filenames" can be used to handle wrongly encoded
filenames if one enables Unicode filename translation (<strong>+fnu</strong>)
on platforms where this is not the default.</p> </dd><dt>Source code encoding</dt><dd> <p>The Erlang source code has support for the UTF-8 encoding
and bytewise encoding. The default in Erlang/OTP R16B was bytewise
(<strong>latin1</strong>) encoding. It was changed to UTF-8 in Erlang/OTP 17.0.
You can control the encoding by a comment like the following in the
beginning of the file:</p> <pre><code class="">
%% -*- coding: utf-8 -*-</code></pre> <p>This of course requires your editor to support UTF-8 as well. The
same comment is also interpreted by functions like
<a href="../kernel/file#consult/1">kernel/file#consult/1</a>,
the release handler, and so on, so that you can have all text files
in your source directories in UTF-8 encoding.</p> </dd><dt>The language</dt><dd> <p>Having the source code in UTF-8 also allows you to write string
literals, function names, and atoms containing Unicode
characters with code points &gt; 255.
Module names, application names, and node names are still restricted
to the ISO Latin-1 range. Binary literals, where you use type
<strong>/utf8</strong>, can also be expressed using Unicode characters &gt; 255.
Having module names or application names using characters other than
7-bit ASCII can cause
trouble on operating systems with inconsistent file naming schemes,
and can hurt portability, so it is not recommended.</p> <p>EEP 40 suggests that the language is also to allow for Unicode
characters &gt; 255 in variable names. Whether to implement that EEP
is yet to be decided.</p> </dd></dl><h3>Standard Unicode Representation</h3><p>In Erlang, strings are lists of integers. A string was until
Erlang/OTP R13 defined to be encoded in the ISO Latin-1 (ISO 8859-1)
character set, which is, code point by code point, a subrange of the
Unicode character set.</p><p>The standard list encoding for strings was therefore easily extended to
handle the whole Unicode range. A Unicode string in Erlang is a list
containing integers, where each integer is a valid Unicode code point and
represents one character in the Unicode character set.</p><p>Erlang strings in ISO Latin-1 are a subset of Unicode strings.</p><p>Only if a string contains code points &lt; 256, can it be directly
converted to a binary by using, for example,
<a href="../erts/erlang#iolist_to_binary/1">erts/erlang#iolist_to_binary/1</a>
or can be sent directly to a port. If the string contains Unicode
characters &gt; 255, an encoding must be decided upon and the string is to
be converted to a binary in the preferred encoding using
<a href="../stdlib/unicode#characters_to_binary/1">stdlib/unicode#characters_to_binary/1</a>.
Strings are not generally lists of bytes, as they were before
Erlang/OTP R13, they are lists of characters. Characters are not
generally bytes, they are Unicode code points.</p><p>Binaries are more troublesome. For performance reasons, programs often
store textual data in binaries instead of lists, mainly because they are
more compact (one byte per character instead of two words per character,
as is the case with lists). Using
<a href="../erts/erlang#list_to_binary/1">erts/erlang#list_to_binary/1</a>,
an ISO Latin-1 Erlang string can be converted into a binary, effectively
using bytewise encoding: one byte per character. This was convenient for
those limited Erlang strings, but cannot be done for arbitrary Unicode
lists.</p><p>As the UTF-8 encoding is widely spread and provides some backward
compatibility in the 7-bit ASCII range, it is selected as the standard
encoding for Unicode characters in binaries for Erlang.</p><p>The standard binary encoding is used whenever a library function in
Erlang is to handle Unicode data in binaries, but is of course not
enforced when communicating externally. Functions and bit syntax exist to
encode and decode both UTF-8, UTF-16, and UTF-32 in binaries. However,
library functions dealing with binaries and Unicode in general only deal
with the default encoding.</p><p>Character data can be combined from many sources, sometimes available in
a mix of strings and binaries. Erlang has for long had the concept of
<strong>iodata</strong> or <strong>iolist</strong>s, where binaries and lists can be combined
to represent a sequence of bytes. In the same way, the Unicode-aware
modules often allow for combinations of binaries and lists, where the
binaries have characters encoded in UTF-8 and the lists contain such
binaries or numbers representing Unicode code points:</p><pre><code class="">
unicode_binary() = binary() with characters encoded in UTF-8 coding standard

chardata() = charlist() | unicode_binary()

charlist() = maybe_improper_list(char() | unicode_binary() | charlist(),
  unicode_binary() | nil())</code></pre><p>The module <a href="./unicode">stdlib/unicode</a>
even supports similar mixes with binaries containing other encodings than
UTF-8, but that is a special case to allow for conversions to and from
external data:</p><pre><code class="">
external_unicode_binary() = binary() with characters coded in a user-specified
  Unicode encoding other than UTF-8 (UTF-16 or UTF-32)

external_chardata() = external_charlist() | external_unicode_binary()

external_charlist() = maybe_improper_list(char() | external_unicode_binary() |
  external_charlist(), external_unicode_binary() | nil())</code></pre><h3>Basic Language Support</h3><p><a name="unicode_in_erlang"></a>As from Erlang/OTP R16, Erlang
source files can be written in UTF-8 or bytewise (<strong>latin1</strong>)
encoding. For information about how to state the encoding of an
Erlang source file, see the <a href="../stdlib/epp#encoding">stdlib/epp#encoding</a> module.  As
from Erlang/OTP R16, strings and comments can be written using
Unicode.  As from Erlang/OTP 20, also atoms and functions can be
written using Unicode. Modules, applications, and nodes must still be
named using characters from the ISO Latin-1 character set.  (These
restrictions in the language are independent of the encoding of
the source file.)</p><h3>Bit Syntax</h3><p>The bit syntax contains types for handling binary data in the
three main encodings. The types are named <strong>utf8</strong>, <strong>utf16</strong>,
and <strong>utf32</strong>. The <strong>utf16</strong> and <strong>utf32</strong> types can be in a
big-endian or a little-endian variant:</p><pre><code class="">
&lt;&lt;Ch/utf8,_/binary&gt;&gt; = Bin1,
&lt;&lt;Ch/utf16-little,_/binary&gt;&gt; = Bin2,
Bin3 = &lt;&lt;$H/utf32-little, $e/utf32-little, $l/utf32-little, $l/utf32-little,
$o/utf32-little&gt;&gt;,</code></pre><p>For convenience, literal strings can be encoded with a Unicode
encoding in binaries using the following (or similar) syntax:</p><pre><code class="">
Bin4 = &lt;&lt;"Hello"/utf16&gt;&gt;,</code></pre><h3>String and Character Literals</h3><p>For source code, there is an extension to syntax <strong>\</strong>OOO
(backslash followed by three octal numbers) and <strong>\x</strong>HH (backslash
followed by <strong>x</strong>, followed by two hexadecimal characters), namely
<strong>\x{</strong>H ...<strong>}</strong> (backslash followed by <strong>x</strong>, followed by
left curly bracket, any number of hexadecimal digits, and a terminating
right curly bracket). This allows for entering characters of any code
point literally in a string even when the encoding of the source file
is bytewise (<strong>latin1</strong>).</p><p>In the shell, if using a Unicode input device, or in source code
stored in UTF-8, <strong>$</strong> can be followed directly by a Unicode
character producing an integer. In the following example, the code
point of a Cyrillic <strong>Ñ</strong> is output:</p><pre>
7&gt; <span class="input">$Ñ.</span>
1089</pre><h3>Heuristic String Detection</h3><p>In certain output functions and in the output of return values in
the shell, Erlang tries to detect string data in lists and binaries
heuristically. Typically you will see heuristic detection in a
situation like this:</p><pre>
1&gt; <span class="input">[97,98,99].</span>
"abc"
2&gt; <span class="input">&lt;&lt;97,98,99&gt;&gt;.</span>
&lt;&lt;"abc"&gt;&gt;    
3&gt; <span class="input">&lt;&lt;195,165,195,164,195,182&gt;&gt;.</span>
&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;</pre><p>Here the shell detects lists containing printable characters or
binaries containing printable characters in bytewise or UTF-8 encoding.
But what is a printable character? One view is that anything the Unicode
standard thinks is printable, is also printable according to the
heuristic detection. The result is then that almost any list of
integers are deemed a string, and all sorts of characters are printed,
maybe also characters that your terminal lacks in its font set
(resulting in some unappreciated generic output). 
Another way is to keep it backward compatible so that only the ISO
Latin-1 character set is used to detect a string. A third way is to let
the user decide exactly what Unicode ranges that are to be viewed as
characters.</p><p>As from Erlang/OTP R16B you can select the ISO Latin-1 range or the
whole Unicode range by supplying startup flag <strong>+pc latin1</strong> or
<strong>+pc unicode</strong>, respectively. For backward compatibility,
<strong>latin1</strong> is default. This only controls how heuristic string
detection is done. More ranges are expected to be added in the future,
enabling tailoring of the heuristics to the language and region
relevant to the user.</p><p>The following examples show the two startup options:</p><pre>
$ <span class="input">erl +pc latin1</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)  
1&gt; <span class="input">[1024].</span>
[1024]
2&gt; <span class="input">[1070,1085,1080,1082,1086,1076].</span>
[1070,1085,1080,1082,1086,1076]
3&gt; <span class="input">[229,228,246].</span>
"Ã¥Ã¤Ã¶"
4&gt; <span class="input">&lt;&lt;208,174,208,189,208,184,208,186,208,190,208,180&gt;&gt;.</span>
&lt;&lt;208,174,208,189,208,184,208,186,208,190,208,180&gt;&gt;
5&gt; <span class="input">&lt;&lt;229/utf8,228/utf8,246/utf8&gt;&gt;.</span>
&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;</pre><pre>
$ <span class="input">erl +pc unicode</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)  
1&gt; <span class="input">[1024].</span>
"Ð"
2&gt; <span class="input">[1070,1085,1080,1082,1086,1076].</span>
"Ð®Ð½Ð¸ÐºÐ¾Ð´"
3&gt; <span class="input">[229,228,246].</span>
"Ã¥Ã¤Ã¶"
4&gt; <span class="input">&lt;&lt;208,174,208,189,208,184,208,186,208,190,208,180&gt;&gt;.</span>
&lt;&lt;"Ð®Ð½Ð¸ÐºÐ¾Ð´"/utf8&gt;&gt;
5&gt; <span class="input">&lt;&lt;229/utf8,228/utf8,246/utf8&gt;&gt;.</span>
&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;</pre><p>In the examples, you can see that the default Erlang shell interprets
only characters from the ISO Latin1 range as printable and only detects
lists or binaries with those "printable" characters as containing
string data. The valid UTF-8 binary containing the Russian word
"Ð®Ð½Ð¸ÐºÐ¾Ð´", is not printed as a string. When started with all Unicode
characters printable (<strong>+pc unicode</strong>), the shell outputs anything
containing printable Unicode data (in binaries, either UTF-8 or
bytewise encoded) as string data.</p><p>These heuristics are also used by
<a href="../stdlib/io#format/2">stdlib/io#format/2</a>,
<a href="../stdlib/io_lib#format/2">stdlib/io_lib#format/2</a>,
and friends when modifier <strong>t</strong> is used with <strong>~p</strong> or
<strong>~P</strong>:</p><pre>
$ <span class="input">erl +pc latin1</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)  
1&gt; <span class="input">io:format("~tp~n",[{&lt;&lt;"Ã¥Ã¤Ã¶"&gt;&gt;, &lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;, &lt;&lt;208,174,208,189,208,184,208,186,208,190,208,180&gt;&gt;}]).</span>
{&lt;&lt;"Ã¥Ã¤Ã¶"&gt;&gt;,&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;,&lt;&lt;208,174,208,189,208,184,208,186,208,190,208,180&gt;&gt;}
ok</pre><pre>
$ <span class="input">erl +pc unicode</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)  
1&gt; <span class="input">io:format("~tp~n",[{&lt;&lt;"Ã¥Ã¤Ã¶"&gt;&gt;, &lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;, &lt;&lt;208,174,208,189,208,184,208,186,208,190,208,180&gt;&gt;}]).</span>
{&lt;&lt;"Ã¥Ã¤Ã¶"&gt;&gt;,&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;,&lt;&lt;"Ð®Ð½Ð¸ÐºÐ¾Ð´"/utf8&gt;&gt;}
ok</pre><p>Notice that this only affects <em>heuristic</em> interpretation of
lists and binaries on output. For example, the <strong>~ts</strong> format
sequence always outputs a valid list of characters, regardless of the
<strong>+pc</strong> setting, as the programmer has explicitly requested string
output.</p><h3>The Interactive Shell</h3><p>The interactive Erlang shell, when started to a terminal or started
using command <strong>werl</strong> on Windows, can support Unicode input and
output.</p><p>On Windows, proper operation requires that a suitable font is
installed and selected for the Erlang application to use. If no suitable
font is available on your system, try installing the
<a href="http://dejavu-fonts.org">DejaVu fonts</a>, which are freely
available, and then select that font in the Erlang shell application.</p><p>On Unix-like operating systems, the terminal is to be able to handle
UTF-8 on input and output (this is done by, for example, modern versions
of XTerm, KDE Konsole, and the Gnome terminal)
and your locale settings must be proper. As
an example, a <strong>LANG</strong> environment variable can be set as follows:</p><pre>
$ <span class="input">echo $LANG</span>
en_US.UTF-8</pre><p>Most systems handle variable <strong>LC_CTYPE</strong> before <strong>LANG</strong>, so if
that is set, it must be set to <strong>UTF-8</strong>:</p><pre>
$ echo <span class="input">$LC_CTYPE</span>
en_US.UTF-8</pre><p>The <strong>LANG</strong> or <strong>LC_CTYPE</strong> setting are to be consistent with
what the terminal is capable of. There is no portable way for Erlang to
ask the terminal about its UTF-8 capacity, we have to rely on the
language and character type settings.</p><p>To investigate what Erlang thinks about the terminal, the call
<a href="../stdlib/io#getopts/1">stdlib/io#getopts/1</a>
can be used when the shell is started:</p><pre>
$ <span class="input">LC_CTYPE=en_US.ISO-8859-1 erl</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)
1&gt; <span class="input">lists:keyfind(encoding, 1, io:getopts()).</span>
{encoding,latin1}
2&gt; <span class="input">q().</span>
ok
$ <span class="input">LC_CTYPE=en_US.UTF-8 erl</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)
1&gt; <span class="input">lists:keyfind(encoding, 1, io:getopts()).</span>
{encoding,unicode}
2&gt;</pre><p>When (finally?) everything is in order with the locale settings, fonts.
and the terminal emulator, you have probably found a way to input
characters in the script you desire. For testing, the simplest way is to
add some keyboard mappings for other languages, usually done with some
applet in your desktop environment.</p><p>In a KDE environment, select <em>KDE Control Center (Personal Settings)</em> &gt; <em>Regional and Accessibility</em> &gt; <em>Keyboard Layout</em>.</p><p>On Windows XP, select <em>Control Panel</em> &gt; <em>Regional and Language Options</em>, select tab <em>Language</em>, and click button
<em>Details...</em> in the square named <em>Text Services and Input Languages</em>.</p><p>Your environment
probably provides similar means of changing the keyboard layout. Ensure
that you have a way to switch back and forth between keyboards easily if
you are not used to this. For example, entering commands using a Cyrillic
character set is not easily done in the Erlang shell.</p><p>Now you are set up for some Unicode input and output. The simplest thing
to do is to enter a string in the shell:</p><pre>
$ <span class="input">erl</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)
1&gt; <span class="input">lists:keyfind(encoding, 1, io:getopts()).</span>
{encoding,unicode}
2&gt; <span class="input">"Ð®Ð½Ð¸ÐºÐ¾Ð´".</span>
"Ð®Ð½Ð¸ÐºÐ¾Ð´"
3&gt; <span class="input">io:format("~ts~n", [v(2)]).</span>
Ð®Ð½Ð¸ÐºÐ¾Ð´
ok
4&gt;</pre><p>While strings can be input as Unicode characters, the language elements
are still limited to the ISO Latin-1 character set. Only character
constants and strings are allowed to be beyond that range:</p><pre>
$ <span class="input">erl</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)
1&gt; <span class="input">$Î¾.</span>
958
2&gt; <span class="input">Ð®Ð½Ð¸ÐºÐ¾Ð´.</span>
* 1: illegal character
2&gt; </pre><a name="unicode_file_names"></a><h3>Unicode Filenames</h3><p>Most modern operating systems support Unicode filenames in some way.
There are many different ways to do this and Erlang by default treats the
different approaches differently:</p><dl><dt>Mandatory Unicode file naming</dt><dd> <p>Windows and, for most common uses, MacOS X enforce Unicode support
for filenames. All files created in the file system have names that
can consistently be interpreted. In MacOS X, all filenames are
retrieved in UTF-8 encoding. In Windows, each system call handling
filenames has a special Unicode-aware variant, giving much the same
effect. There are no filenames on these systems that are not Unicode
filenames. So, the default behavior of the Erlang VM is to work in
"Unicode filename translation mode". This means that a
filename can be specified as a Unicode list, which is automatically
translated to the proper name encoding for the underlying operating
system and file system.</p> <p>Doing, for example, a
<a href="../kernel/file#list_dir/1">kernel/file#list_dir/1</a>
on one of these systems can return Unicode lists with code points
&gt; 255, depending on the content of the file system.</p> </dd><dt>Transparent file naming</dt><dd> <p>Most Unix operating systems have adopted a simpler approach, namely
that Unicode file naming is not enforced, but by convention. Those
systems usually use UTF-8 encoding for Unicode filenames, but do not
enforce it. On such a system, a filename containing characters with
code points from 128 through 255 can be named as plain ISO Latin-1 or
use UTF-8 encoding. As no consistency is enforced, the Erlang VM
cannot do consistent translation of all filenames.</p> <p>By default on such systems, Erlang starts in <strong>utf8</strong> filename
mode if the terminal supports UTF-8, otherwise in <strong>latin1</strong>
mode.</p> <p>In <strong>latin1</strong> mode, filenames are bytewise encoded. This allows
for list representation of all filenames in the system. However, a
a file named "Ãstersund.txt", appears in
<a href="../kernel/file#list_dir/1">kernel/file#list_dir/1</a>
either as "Ãstersund.txt" (if the filename was encoded in bytewise
ISO Latin-1 by the program creating the file) or more probably as
<strong>[195,150,115,116,101,114,115,117,110,100]</strong>, which is a list
containing UTF-8 bytes (not what you want). If you use Unicode
filename translation on such a system, non-UTF-8 filenames are
ignored by functions like <strong>file:list_dir/1</strong>. They can be
retrieved with function
<a href="../kernel/file#list_dir_all/1">kernel/file#list_dir_all/1</a>,
but wrongly encoded filenames appear as "raw filenames".
</p> </dd></dl><p>The Unicode file naming support was introduced in Erlang/OTP
R14B01.  A VM operating in Unicode filename translation mode can
work with files having names in any language or character set (as
long as it is supported by the underlying operating system and
file system). The Unicode character list is used to denote
filenames or directory names. If the file system content is
listed, you also get Unicode lists as return value. The support
lies in the Kernel and STDLIB modules, which is why
most applications (that do not explicitly require the filenames
to be in the ISO Latin-1 range) benefit from the Unicode support
without change.</p><p>On operating systems with mandatory Unicode filenames, this means that
you more easily conform to the filenames of other (non-Erlang)
applications. You can also process filenames that, at least on Windows,
were inaccessible (because of having names that could not be represented
in ISO Latin-1). Also, you avoid creating incomprehensible filenames
on MacOS X, as the <strong>vfs</strong> layer of the operating system accepts all
your filenames as UTF-8 does not rewrite them.</p><p>For most systems, turning on Unicode filename translation is no problem
even if it uses transparent file naming. Very few systems have mixed
filename encodings. A consistent UTF-8 named system works perfectly in
Unicode filename mode. It was still, however, considered experimental in
Erlang/OTP R14B01 and is still not the default on such systems.</p><p>Unicode filename translation is turned on with switch <strong>+fnu</strong>. On
Linux, a VM started without explicitly stating the filename translation
mode defaults to <strong>latin1</strong> as the native filename encoding. On
Windows and MacOS X, the default behavior is that of Unicode filename
translation. Therefore
<a href="../kernel/file#native_name_encoding/0">kernel/file#native_name_encoding/0</a>
by default returns <strong>utf8</strong> on those systems (Windows does not use
UTF-8 on the file system level, but this can safely be ignored by the
Erlang programmer). The default behavior can, as stated earlier, be
changed using option <strong>+fnu</strong> or <strong>+fnl</strong> to the VM, see the
<a href="./erl">erts/erl</a> program. If the VM is
started in Unicode filename translation mode,
<strong>file:native_name_encoding/0</strong> returns atom <strong>utf8</strong>. Switch
<strong>+fnu</strong> can be followed by <strong>w</strong>, <strong>i</strong>, or <strong>e</strong> to control
how wrongly encoded filenames are to be reported.</p><ul><li> <p><strong>w</strong> means that a warning is sent to the <strong>error_logger</strong>
whenever a wrongly encoded filename is "skipped" in directory
listings. <strong>w</strong> is the default.</p> </li><li> <p><strong>i</strong> means that wrongly encoded filenames are silently ignored.
</p> </li><li> <p><strong>e</strong> means that the API function returns an error whenever a
wrongly encoded filename (or directory name) is encountered.</p> </li></ul><p>Notice that
<a href="../kernel/file#read_link/1">kernel/file#read_link/1</a>
always returns an error if the link points to an invalid filename.</p><p>In Unicode filename mode, filenames given to BIF <strong>open_port/2</strong> with
option <strong>{spawn_executable,...}</strong> are also interpreted as Unicode. So
is the parameter list specified in option <strong>args</strong> available when
using <strong>spawn_executable</strong>. The UTF-8 translation of arguments can be
avoided using binaries, see section
<a href="#notes-about-raw-filenames">Notes About Raw Filenames</a>.
</p><p>Notice that the file encoding options specified when opening a file has
nothing to do with the filename encoding convention. You can very well
open files containing data encoded in UTF-8, but having filenames in
bytewise (<strong>latin1</strong>) encoding or conversely.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>Erlang drivers and NIF-shared objects still cannot be named with
names containing code points &gt; 127. This limitation will be removed in
a future release. However, Erlang modules can, but it is definitely not a
good idea and is still considered experimental.</p></div><a name="notes-about-raw-filenames"></a><h3>Notes About Raw Filenames</h3><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>
Note that raw filenames <em>not</em> necessarily are encoded the
same way as on the OS level.
</p></div><p>Raw filenames were introduced together with Unicode filename support
in ERTS 5.8.2 (Erlang/OTP R14B01). The reason "raw
filenames" were introduced in the system was
to be able to represent
filenames, specified in different encodings on the same system,
consistently. It can seem practical to have the VM automatically
translate a filename that is not in UTF-8 to a list of Unicode
characters, but this would open up for both duplicate filenames and
other inconsistent behavior.</p><p>Consider a directory containing a file named "bjÃ¶rn" in ISO
Latin-1, while the Erlang VM is operating in Unicode filename mode (and
therefore expects UTF-8 file naming). The ISO Latin-1 name is not valid
UTF-8 and one can be tempted to think that automatic conversion in, for
example,
<a href="../kernel/file#list_dir/1">kernel/file#list_dir/1</a>
is a good idea. But what would happen if we later tried to open the file
and have the name as a Unicode list (magically converted from the ISO
Latin-1 filename)? The VM converts the filename to UTF-8, as this is
the encoding expected. Effectively this means trying to open the file
named &lt;&lt;"bjÃ¶rn"/utf8&gt;&gt;. This file does not exist,
and even if it existed it would not be the same file as the one that was
listed. We could even create two files named "bjÃ¶rn", one
named in UTF-8 encoding and one not. If <strong>file:list_dir/1</strong> would
automatically convert the ISO Latin-1 filename to a list, we would get
two identical filenames as the result. To avoid this, we must
differentiate between filenames that are properly encoded according to
the Unicode file naming convention (that is, UTF-8) and filenames that
are invalid under the encoding. By the common function
<strong>file:list_dir/1</strong>, the wrongly encoded filenames are ignored in
Unicode filename translation mode, but by function
<a href="../kernel/file#list_dir_all/1">kernel/file#list_dir_all/1</a>
the filenames with invalid encoding are returned as "raw"
filenames, that is, as binaries.</p><p>The <strong>file</strong> module accepts raw filenames as input.
<strong>open_port({spawn_executable, ...} ...)</strong> also accepts them. As
mentioned earlier, the arguments specified in the option list to
<strong>open_port({spawn_executable, ...}  ...)</strong> undergo the same
conversion as the filenames, meaning that the executable is provided
with arguments in UTF-8 as well. This translation is avoided
consistently with how the filenames are treated, by giving the argument
as a binary.</p><p>To force Unicode filename translation mode on systems where this is not
the default was considered experimental in Erlang/OTP R14B01. This was
because the initial implementation did not ignore wrongly encoded
filenames, so that raw filenames could spread unexpectedly throughout
the system. As from Erlang/OTP R16B, the wrongly encoded
filenames are only retrieved by special functions (such as
<strong>file:list_dir_all/1</strong>). Since the impact on existing code is
therefore much lower it is now supported.
Unicode filename translation is
expected to be default in future releases.</p><p>Even if you are operating without Unicode file naming translation
automatically done by the VM, you can access and create files with
names in UTF-8 encoding by using raw filenames encoded as UTF-8.
Enforcing the UTF-8 encoding regardless of the mode the Erlang VM is
started in can in some circumstances be a good idea, as the convention
of using UTF-8 filenames is spreading.</p><h3>Notes About MacOS X</h3><p>The <strong>vfs</strong> layer of MacOS X enforces UTF-8 filenames in an
aggressive way. Older versions did this by refusing to create non-UTF-8
conforming filenames, while newer versions replace offending bytes with
the sequence "%HH", where HH is the original character in
hexadecimal notation. As Unicode translation is enabled by default on
MacOS X, the only way to come up against this is to either start the VM
with flag <strong>+fnl</strong> or to use a raw filename in bytewise
(<strong>latin1</strong>) encoding. If using a raw filename, with a bytewise
encoding containing characters from 127 through 255, to create a file,
the file cannot be opened using the same name as the one used to create
it. There is no remedy for this behavior, except keeping the filenames
in the correct encoding.</p><p>MacOS X reorganizes the filenames so that the representation of
accents, and so on, uses the "combining characters". For example,
character <strong>Ã¶</strong> is represented as code points <strong>[111,776]</strong>,
where <strong>111</strong> is character <strong>o</strong> and <strong>776</strong> is the special
accent character "Combining Diaeresis". This way of normalizing Unicode
is otherwise very seldom used. Erlang normalizes those filenames in the
opposite way upon retrieval, so that filenames using combining accents
are not passed up to the Erlang application. In Erlang, filename
"bjÃ¶rn" is retrieved as <strong>[98,106,246,114,110]</strong>, not as
<strong>[98,106,117,776,114,110]</strong>, although the file system can think
differently. The normalization into combining accents is redone when
accessing files, so this can usually be ignored by the Erlang
programmer.</p><h3>Unicode in Environment and Parameters</h3><a name="unicode_in_environment_and_parameters"></a><p>Environment variables and their interpretation are handled much in the
same way as filenames. If Unicode filenames are enabled, environment
variables as well as parameters to the Erlang VM are expected to be in
Unicode.</p><p>If Unicode filenames are enabled, the calls to
<a href="../kernel/os#getenv/0">kernel/os#getenv/0</a>,
<a href="../kernel/os#putenv/2">kernel/os#putenv/2</a>, and
<a href="../kernel/os#unsetenv/1">kernel/os#unsetenv/1</a>
handle Unicode strings. On Unix-like platforms, the built-in functions
translate environment variables in UTF-8 to/from Unicode strings, possibly
with code points &gt; 255. On Windows, the Unicode versions of the
environment system API are used, and code points &gt; 255 are allowed.</p><p>On Unix-like operating systems, parameters are expected to be UTF-8
without translation if Unicode filenames are enabled.</p><h3>Unicode-Aware Modules</h3><p>Most of the modules in Erlang/OTP are Unicode-unaware in the sense that
they have no notion of Unicode and should not have. Typically they handle
non-textual or byte-oriented data (such as <strong>gen_tcp</strong>).</p><p>Modules handling textual data (such as
<a href="./io_lib">stdlib/io_lib</a> and
<a href="./string">stdlib/string</a> are sometimes
subject to conversion or extension to be able to handle Unicode
characters.</p><p>Fortunately, most textual data has been stored in lists and range
checking has been sparse, so modules like <strong>string</strong> work well for
Unicode strings with little need for conversion or extension.</p><p>Some modules are, however, changed to be explicitly Unicode-aware. These
modules include:</p><dl><dt><strong>unicode</strong></dt><dd> <p>The <a href="./unicode">stdlib/unicode</a>
module is clearly Unicode-aware. It contains functions for conversion
between different Unicode formats and some utilities for identifying
byte order marks. Few programs handling Unicode data survive without
this module.</p> </dd><dt><strong>io</strong></dt><dd> <p>The <a href="./io">stdlib/io</a> module has been
extended along with the actual I/O protocol to handle Unicode data.
This means that many functions require binaries to be in UTF-8, and
there are modifiers to format control sequences to allow for output
of Unicode strings.</p> </dd><dt><strong>file</strong>, <strong>group</strong>, <strong>user</strong></dt><dd> <p>I/O-servers throughout the system can handle Unicode data and have
options for converting data upon output or input to/from the device.
As shown earlier, the
<a href="./shell">stdlib/shell</a> module has
support for Unicode terminals and the
<a href="./file">kernel/file</a> module
allows for translation to and from various Unicode formats on
disk.</p> <p>Reading and writing of files with Unicode data is, however, not best
done with the <strong>file</strong> module, as its interface is
byte-oriented. A file opened with a Unicode encoding (like UTF-8) is
best read or written using the
<a href="./io">stdlib/io</a> module.</p> </dd><dt><strong>re</strong></dt><dd> <p>The <a href="./re">stdlib/re</a> module allows
for matching Unicode strings as a special option. As the library is
centered on matching in binaries, the Unicode support is
UTF-8-centered.</p> </dd><dt><strong>wx</strong></dt><dd> <p>The graphical library <a href="./wx">wx/wx</a>
has extensive support for Unicode text.</p></dd></dl><p>The <a href="./string">stdlib/string</a>
module works perfectly for Unicode strings and ISO Latin-1
strings, except the language-dependent functions <a href="../stdlib/string#uppercase/1">stdlib/string#uppercase/1</a>
and <a href="../stdlib/string#lowercase/1">stdlib/string#lowercase/1</a>.
These two functions can never function correctly for Unicode
characters in their current form, as there are language and locale
issues to consider when converting text between cases.  Converting
case in an international environment is a large subject not yet
addressed in OTP.</p><h3>Unicode Data in Files</h3><p>Although Erlang can handle Unicode data in many forms does not
automatically mean that the content of any file can be Unicode text. The
external entities, such as ports and I/O servers, are not generally
Unicode capable.</p><p>Ports are always byte-oriented, so before sending data that you are not
sure is bytewise-encoded to a port, ensure to encode it in a proper
Unicode encoding. Sometimes this means that only part of the data must
be encoded as, for example, UTF-8. Some parts can be binary data (like a
length indicator) or something else that must not undergo character
encoding, so no automatic translation is present.</p><p>I/O servers behave a little differently. The I/O servers connected to
terminals (or <strong>stdout</strong>) can usually cope with Unicode data
regardless of the encoding option. This is convenient when one expects
a modern environment but do not want to crash when writing to an archaic
terminal or pipe.</p><p>A file can have an encoding option that makes it generally usable by the
<a href="./io">stdlib/io</a> module (for example
<strong>{encoding,utf8}</strong>), but is by default opened as a byte-oriented file.
The <a href="./file">kernel/file</a> module is
byte-oriented, so only ISO Latin-1 characters can be written using that
module. Use the <strong>io</strong> module if Unicode data is to be output to a
file with other <strong>encoding</strong> than <strong>latin1</strong> (bytewise encoding).
It is slightly confusing that a file opened with, for example,
<strong>file:open(Name,[read,{encoding,utf8}])</strong> cannot be properly read
using <strong>file:read(File,N)</strong>, but using the <strong>io</strong> module to retrieve
the Unicode data from it. The reason is that <strong>file:read</strong> and
<strong>file:write</strong> (and friends) are purely byte-oriented, and should be,
as that is the way to access files other than text files, byte by byte.
As with ports, you can write encoded data into a file by "manually"
converting the data to the encoding of choice (using the
<a href="./unicode">stdlib/unicode</a> module or the
bit syntax) and then output it on a bytewise (<strong>latin1</strong>) encoded
file.</p><p>Recommendations:</p><ul><li><p>Use the
<a href="./file">kernel/file</a> module for
files opened for bytewise access (<strong>{encoding,latin1}</strong>).</p> </li><li><p>Use the <a href="./io">stdlib/io</a> module
when accessing files with any other encoding (for example
<strong>{encoding,uf8}</strong>).</p> </li></ul><p>Functions reading Erlang syntax from files recognize the <strong>coding:</strong>
comment and can therefore handle Unicode data on input. When writing
Erlang terms to a file, you are advised to insert such comments when
applicable:</p><pre>
$ <span class="input">erl +fna +pc unicode</span>
Erlang R16B (erts-5.10.1) [source]  [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1  (abort with ^G)
1&gt; <span class="input">file:write_file("test.term",&lt;&lt;"%% coding: utf-8\n[{\"Ð®Ð½Ð¸ÐºÐ¾Ð´\",4711}].\n"/utf8&gt;&gt;).</span>
ok
2&gt; <span class="input">file:consult("test.term").</span>   
{ok,[[{"Ð®Ð½Ð¸ÐºÐ¾Ð´",4711}]]}</pre><h3>Summary of Options</h3><a name="unicode_options_summary"></a><p>The Unicode support is controlled by both command-line switches, some
standard environment variables, and the OTP version you are using. Most
options affect mainly how Unicode data is displayed, not the
functionality of the APIs in the standard libraries. This means that
Erlang programs usually do not need to concern themselves with these
options, they are more for the development environment. An Erlang program
can be written so that it works well regardless of the type of system or
the Unicode options that are in effect.</p><p>Here follows a summary of the settings affecting Unicode:</p><dl><dt>The <strong>LANG</strong> and <strong>LC_CTYPE</strong> environment variables</dt><dd> <p>The language setting in the operating system mainly affects the
shell. The terminal (that is, the group leader) operates with
<strong>{encoding, unicode}</strong> only if the environment tells it that
UTF-8 is allowed. This setting is to correspond to the terminal you
are using.</p> <p>The environment can also affect filename interpretation, if Erlang
is started with flag <strong>+fna</strong> (which is default from
Erlang/OTP 17.0).</p> <p>You can check the setting of this by calling
<a href="../stdlib/io#getopts/1">stdlib/io#getopts/1</a>,
which gives you an option list containing <strong>{encoding,unicode}</strong>
or <strong>{encoding,latin1}</strong>.</p> </dd><dt>The <strong>+pc</strong> {<strong>unicode</strong>|<strong>latin1</strong>} flag to <a href="./erl">erts/erl</a></dt><dd> <p>This flag affects what is interpreted as string data when doing
heuristic string detection in the shell and in
<a href="./io">stdlib/io</a>/
<a href="../stdlib/io_lib#format/2">stdlib/io_lib#format/2</a>
with the <strong>"~tp"</strong> and <strong>~tP</strong> formatting instructions, as
described earlier.</p> <p>You can check this option by calling
<a href="../stdlib/io#printable_range/0">stdlib/io#printable_range/0</a>,
which returns <strong>unicode</strong> or <strong>latin1</strong>. To be compatible with
future (expected) extensions to the settings, rather use
<a href="../stdlib/io_lib#printable_list/1">stdlib/io_lib#printable_list/1</a>
to check if a list is printable according to the setting. That
function takes into account new possible settings returned from
<strong>io:printable_range/0</strong>.</p> </dd><dt>The <strong>+fn</strong>{<strong>l</strong>|<strong>u</strong>|<strong>a</strong>} [{<strong>w</strong>|<strong>i</strong>|<strong>e</strong>}] flag to  <a href="./erl">erts/erl</a></dt><dd> <p>This flag affects how the filenames are to be interpreted. On
operating systems with transparent file naming, this must be
specified to allow for file naming in Unicode characters (and for
correct interpretation of filenames containing characters &gt; 255).
</p> <ul><li> <p><strong>+fnl</strong> means bytewise interpretation of filenames, which was
the usual way to represent ISO Latin-1 filenames before UTF-8
file naming got widespread.</p> </li><li> <p><strong>+fnu</strong> means that filenames are encoded in UTF-8, which is
nowadays the common scheme (although not enforced).</p> </li><li> <p><strong>+fna</strong> means that you automatically select between
<strong>+fnl</strong> and <strong>+fnu</strong>, based on environment variables
<strong>LANG</strong> and <strong>LC_CTYPE</strong>. This is optimistic
heuristics indeed, nothing enforces a user to have a terminal with
the same encoding as the file system, but this is usually the
case. This is the default on all Unix-like operating systems,
except MacOS X.</p> </li></ul> <p>The filename translation mode can be read with function
<a href="../kernel/file#native_name_encoding/0">kernel/file#native_name_encoding/0</a>,
which returns <strong>latin1</strong> (bytewise encoding) or <strong>utf8</strong>.</p> </dd><dt><a href="../stdlib/epp#default_encoding/0">stdlib/epp#default_encoding/0</a></dt><dd> <p>This function returns the default encoding for Erlang source files
(if no encoding comment is present) in the currently running release.
In Erlang/OTP R16B, <strong>latin1</strong> (bytewise encoding) was returned.
As from Erlang/OTP 17.0, <strong>utf8</strong> is returned.</p> <p>The encoding of each file can be specified using comments as
described in the
<a href="../stdlib/epp#encoding">stdlib/epp#encoding</a> module.
</p> </dd><dt><a href="../stdlib/io#setopts/1">stdlib/io#setopts/1</a> and flags <strong>-oldshell</strong>/<strong>-noshell</strong></dt><dd> <p>When Erlang is started with <strong>-oldshell</strong> or <strong>-noshell</strong>, the
I/O server for <strong>standard_io</strong> is by default set to bytewise
encoding, while an interactive shell defaults to what the
environment variables says.</p> <p>You can set the encoding of a file or other I/O server with function
<a href="../stdlib/io#setopts/1">stdlib/io#setopts/1</a>.
This can also be set when opening a file. Setting the terminal (or
other <strong>standard_io</strong> server) unconditionally to option
<strong>{encoding,utf8}</strong> implies that UTF-8 encoded characters are
written to the device, regardless of how Erlang was started or the
user's environment.</p> <p>Opening files with option <strong>encoding</strong> is convenient when
writing or reading text files in a known encoding.</p> <p>You can retrieve the <strong>encoding</strong> setting for an I/O server with
function
<a href="../stdlib/io#getopts/1">stdlib/io#getopts/1</a>.
</p> </dd></dl><h3>Recipes</h3><p>When starting with Unicode, one often stumbles over some common issues.
This section describes some methods of dealing with Unicode data.</p><h3>Byte Order Marks</h3><p>A common method of identifying encoding in text files is to put a Byte
Order Mark (BOM) first in the file. The BOM is the code point 16#FEFF
encoded in the same way as the remaining file. If such a file is to be
read, the first few bytes (depending on encoding) are not part of the
text. This code outlines how to open a file that is believed to
have a BOM, and sets the files encoding and position for further
sequential reading (preferably using the
<a href="./io">stdlib/io</a> module).</p><p>Notice that error handling is omitted from the code:</p><pre><code class="">
open_bom_file_for_reading(File) -&gt;
    {ok,F} = file:open(File,[read,binary]),
    {ok,Bin} = file:read(F,4),
    {Type,Bytes} = unicode:bom_to_encoding(Bin),
    file:position(F,Bytes),
    io:setopts(F,[{encoding,Type}]),
    {ok,F}.</code></pre><p>Function
<a href="../stdlib/unicode#bom_to_encoding/1">stdlib/unicode#bom_to_encoding/1</a>
identifies the encoding from a binary of at least four bytes. It
returns, along with a term suitable for setting the encoding of the
file, the byte length of the BOM, so that the file position can be set
accordingly. Notice that function
<a href="../kernel/file#position/2">kernel/file#position/2</a>
always works on byte-offsets, so that the byte length of the BOM is
needed.</p><p>To open a file for writing and place the BOM first is even simpler:</p><pre><code class="">
open_bom_file_for_writing(File,Encoding) -&gt;
    {ok,F} = file:open(File,[write,binary]),
    ok = file:write(File,unicode:encoding_to_bom(Encoding)),
    io:setopts(F,[{encoding,Encoding}]),
    {ok,F}.</code></pre><p>The file is in both these cases then best processed using the
<a href="./io">stdlib/io</a> module, as the functions
in that module can handle code points beyond the ISO Latin-1 range.</p><h3>Formatted I/O</h3><p>When reading and writing to Unicode-aware entities, like a
file opened for Unicode translation, you probably want to format text
strings using the functions in the
<a href="./io">stdlib/io</a> module or the
<a href="./io_lib">stdlib/io_lib</a> module. For
backward compatibility reasons, these functions do not accept any list
as a string, but require a special <em>translation modifier</em> when
working with Unicode texts. The modifier is <strong>t</strong>. When applied to
control character <strong>s</strong> in a formatting string, it accepts all
Unicode code points and expects binaries to be in UTF-8:</p><pre>
1&gt; <span class="input">io:format("~ts~n",[&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;]).</span>
Ã¥Ã¤Ã¶
ok
2&gt; <span class="input">io:format("~s~n",[&lt;&lt;"Ã¥Ã¤Ã¶"/utf8&gt;&gt;]).</span>
ÃÂ¥ÃÂ¤ÃÂ¶
ok</pre><p>Clearly, the second <strong>io:format/2</strong> gives undesired output, as the
UTF-8 binary is not in <strong>latin1</strong>. For backward compatibility, the
non-prefixed control character <strong>s</strong> expects bytewise-encoded ISO
Latin-1 characters in binaries and lists containing only code points
&lt; 256.</p><p>As long as the data is always lists, modifier <strong>t</strong> can be used for
any string, but when binary data is involved, care must be taken to
make the correct choice of formatting characters. A bytewise-encoded
binary is also interpreted as a string, and printed even when using
<strong>~ts</strong>, but it can be mistaken for a valid UTF-8 string. Avoid
therefore using the <strong>~ts</strong> control if the binary contains
bytewise-encoded characters and not UTF-8.</p><p>Function
<a href="../stdlib/io_lib#format/2">stdlib/io_lib#format/2</a>
behaves similarly. It is defined to return a deep list of characters
and the output can easily be converted to binary data for outputting on
any device by a simple
<a href="../erts/erlang#list_to_binary/1">erts/erlang#list_to_binary/1</a>.
When the translation modifier is used, the list can, however, contain
characters that cannot be stored in one byte. The call to
<strong>erlang:list_to_binary/1</strong> then fails. However, if the I/O server
you want to communicate with is Unicode-aware, the returned list can
still be used directly:</p><pre>
$ <span class="input">erl +pc unicode</span>
Erlang R16B (erts-5.10.1) [source] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.10.1 (abort with ^G)
1&gt; <span class="input">io_lib:format("~ts~n", ["ÎÎ¹Î¿ÏÎ½Î¹ÎºÎ¿Î½Ï"]).</span>
["ÎÎ¹Î¿ÏÎ½Î¹ÎºÎ¿Î½Ï","\n"]
2&gt; <span class="input">io:put_chars(io_lib:format("~ts~n", ["ÎÎ¹Î¿ÏÎ½Î¹ÎºÎ¿Î½Ï"])).</span>
ÎÎ¹Î¿ÏÎ½Î¹ÎºÎ¿Î½Ï
ok</pre><p>The Unicode string is returned as a Unicode list, which is recognized
as such, as the Erlang shell uses the Unicode encoding (and is started
with all Unicode characters considered printable). The Unicode list is
valid input to function
<a href="../stdlib/io#put_chars/2">stdlib/io#put_chars/2</a>,
so data can be output on any Unicode-capable device. If the device is a
terminal, characters are output in format <strong>\x{</strong>H...<strong>}</strong> if
encoding is <strong>latin1</strong>. Otherwise in UTF-8 (for the non-interactive
terminal: "oldshell" or "noshell") or whatever is suitable to show the
character properly (for an interactive terminal: the regular shell).</p><p>So, you can always send Unicode data to the <strong>standard_io</strong> device.
Files, however, accept only Unicode code points beyond ISO Latin-1 if
<strong>encoding</strong> is set to something else than <strong>latin1</strong>.</p><h3>Heuristic Identification of UTF-8</h3><p>While it is strongly encouraged that the encoding of characters
in binary data is known before processing, that is not always possible.
On a typical Linux system, there is a mix of UTF-8 and ISO Latin-1 text
files, and there are seldom any BOMs in the files to identify them.</p><p>UTF-8 is designed so that ISO Latin-1 characters with numbers beyond
the 7-bit ASCII range are seldom considered valid when decoded as UTF-8.
Therefore one can usually use heuristics to determine if a file is in
UTF-8 or if it is encoded in ISO Latin-1 (one byte per character).
The <a href="./unicode">stdlib/unicode</a>
module can be used to determine if data can be interpreted as UTF-8:</p><pre><code class="">
heuristic_encoding_bin(Bin) when is_binary(Bin) -&gt;
    case unicode:characters_to_binary(Bin,utf8,utf8) of
	Bin -&gt;
	    utf8;
	_ -&gt;
	    latin1
    end.</code></pre><p>If you do not have a complete binary of the file content, you can
instead chunk through the file and check part by part. The return-tuple
<strong>{incomplete,Decoded,Rest}</strong> from function
<a href="../stdlib/unicode#characters_to_binary/1">stdlib/unicode#characters_to_binary/1</a>
comes in handy. The incomplete rest from one chunk of data read from the
file is prepended to the next chunk and we therefore avoid the problem
of character boundaries when reading chunks of bytes in UTF-8
encoding:</p><pre><code class="">
heuristic_encoding_file(FileName) -&gt;
    {ok,F} = file:open(FileName,[read,binary]),
    loop_through_file(F,&lt;&lt;&gt;&gt;,file:read(F,1024)).

loop_through_file(_,&lt;&lt;&gt;&gt;,eof) -&gt;
    utf8;
loop_through_file(_,_,eof) -&gt;
    latin1;
loop_through_file(F,Acc,{ok,Bin}) when is_binary(Bin) -&gt;
    case unicode:characters_to_binary([Acc,Bin]) of
	{error,_,_} -&gt;
	    latin1;
	{incomplete,_,Rest} -&gt;
	    loop_through_file(F,Rest,file:read(F,1024));
	Res when is_binary(Res) -&gt;
	    loop_through_file(F,&lt;&lt;&gt;&gt;,file:read(F,1024))
    end.</code></pre><p>Another option is to try to read the whole file in UTF-8 encoding and
see if it fails. Here we need to read the file using function
<a href="../stdlib/io#get_chars/3">stdlib/io#get_chars/3</a>,
as we have to read characters with a code point &gt; 255:</p><pre><code class="">
heuristic_encoding_file2(FileName) -&gt;
    {ok,F} = file:open(FileName,[read,binary,{encoding,utf8}]),
    loop_through_file2(F,io:get_chars(F,'',1024)).

loop_through_file2(_,eof) -&gt;
    utf8;
loop_through_file2(_,{error,_Err}) -&gt;
    latin1;
loop_through_file2(F,Bin) when is_binary(Bin) -&gt;
    loop_through_file2(F,io:get_chars(F,'',1024)).</code></pre><h3>Lists of UTF-8 Bytes</h3><p>For various reasons, you can sometimes have a list of UTF-8
bytes. This is not a regular string of Unicode characters, as each list
element does not contain one character. Instead you get the "raw" UTF-8
encoding that you have in binaries. This is easily converted to a proper
Unicode string by first converting byte per byte into a binary, and then
converting the binary of UTF-8 encoded characters back to a Unicode
string:</p><pre><code class="">
utf8_list_to_string(StrangeList) -&gt;
  unicode:characters_to_list(list_to_binary(StrangeList)).</code></pre><h3>Double UTF-8 Encoding</h3><p>When working with binaries, you can get the horrible "double UTF-8
encoding", where strange characters are encoded in your binaries or
files. In other words, you can get a UTF-8 encoded binary that for the
second time is encoded as UTF-8. A common situation is where you read a
file, byte by byte, but the content is already UTF-8. If you then
convert the bytes to UTF-8, using, for example, the
<a href="./unicode">stdlib/unicode</a> module, or by
writing to a file opened with option <strong>{encoding,utf8}</strong>, you have
each <em>byte</em> in the input file encoded as UTF-8, not each
character of the original text (one character can have been encoded in
many bytes). There is no real remedy for this other than to be sure of
which data is encoded in which format, and never convert UTF-8 data
(possibly read byte by byte from a file) into UTF-8 again.</p><p>By far the most common situation where this occurs, is when you get
lists of UTF-8 instead of proper Unicode strings, and then convert them
to UTF-8 in a binary or on a file:</p><pre><code class="">
wrong_thing_to_do() -&gt;
  {ok,Bin} = file:read_file("an_utf8_encoded_file.txt"),
  MyList = binary_to_list(Bin), %% Wrong! It is an utf8 binary!
  {ok,C} = file:open("catastrophe.txt",[write,{encoding,utf8}]), 
  io:put_chars(C,MyList), %% Expects a Unicode string, but get UTF-8
                          %% bytes in a list!
  file:close(C). %% The file catastrophe.txt contains more or less unreadable
                 %% garbage!</code></pre><p>Ensure you know what a binary contains before converting it to a
string. If no other option exists, try heuristics:</p><pre><code class="">
if_you_can_not_know() -&gt;
  {ok,Bin} = file:read_file("maybe_utf8_encoded_file.txt"),
  MyList = case unicode:characters_to_list(Bin) of
    L when is_list(L) -&gt;
      L;
    _ -&gt;
      binary_to_list(Bin) %% The file was bytewise encoded
  end,
  %% Now we know that the list is a Unicode string, not a list of UTF-8 bytes
  {ok,G} = file:open("greatness.txt",[write,{encoding,utf8}]), 
  io:put_chars(G,MyList), %% Expects a Unicode string, which is what it gets!
  file:close(G). %% The file contains valid UTF-8 encoded Unicode characters!</code></pre></body></html>