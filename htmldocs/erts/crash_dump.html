<!doctype html>
<html><head><meta charset="utf-8"><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.0/css/bootstrap.min.css"></head><body style="margin: 4em 10%"><h1>How to Interpret the Erlang Crash Dumps</h1><p>This section describes the <strong>erl_crash.dump</strong> file
generated upon abnormal exit of the Erlang runtime system.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>The Erlang crash dump had a major facelift in Erlang/OTP R9C. The
information in this section is therefore not directly applicable for
older dumps. However, if you use <a href="./crashdump_viewer">observer/crashdump_viewer</a> on older dumps,
the crash dumps are translated into a format similar to this.</p></div><p>The system writes the crash dump in the current directory of
the emulator or in the file pointed out by the environment variable
(whatever that means on the current operating system)
<strong>ERL_CRASH_DUMP</strong>. For a crash dump to be written, a
writable file system must be mounted.</p><p>Crash dumps are written mainly for one of two reasons: either the
built-in function <strong>erlang:halt/1</strong> is called explicitly
with a string argument from running Erlang code, or the runtime
system has detected an error that cannot be handled. The most
usual reason that the system cannot handle the error is that the
cause is external limitations, such as running out of memory. A
crash dump caused by an internal error can be caused by the system
reaching limits in the emulator itself (like the number of atoms
in the system, or too many simultaneous ETS tables). Usually the
emulator or the operating system can be reconfigured to avoid the
crash, which is why interpreting the crash dump correctly is
important.</p><p>On systems that support OS signals, it is also possible to stop
the runtime system and generate a crash dump by sending the <strong>SIGUSR1</strong>
signal.</p><p>The Erlang crash dump is a readable text file, but it can be difficult
to read. Using the Crashdump Viewer tool in the
<strong>Observer</strong> application simplifies the task. This is a
wx-widget-based tool for browsing Erlang crash dumps.</p><a name="general_info"></a><h2>General Information</h2><p>The first part of the crash dump shows the following:</p><ul><li>The creation time for the dump</li><li>A slogan indicating the reason for the dump</li><li>The system version of the node from which the dump originates</li><li>The compile time of the emulator running the originating node</li><li>The number of atoms in the atom table</li><li>The runtime system thread that caused the crash dump</li></ul><h2>Reasons for Crash Dumps (Slogan)</h2><p>The reason for the dump is shown in the beginning of the file as:</p><pre>
Slogan: &lt;reason&gt;</pre><p>If the system is halted by the BIF
<strong>erlang:halt/1</strong>, the slogan is the string parameter
passed to the BIF, otherwise it is a description generated by
the emulator or the (Erlang) kernel. Normally the message
is enough to understand the problem, but
some messages are described here. Notice that the
suggested reasons for the crash are <em>only suggestions</em>.
The exact reasons for the errors can vary
depending on the local applications and the underlying
operating system.</p><dl><dt><em>&lt;A&gt;: Cannot allocate &lt;N&gt; bytes of memory (of type "&lt;T&gt;")</em></dt><dd> <p>The system has run out of memory. &lt;A&gt; is the allocator that
failed to allocate memory, &lt;N&gt; is the number of bytes that
&lt;A&gt; tried to allocate, and &lt;T&gt; is the memory block
type that the memory was needed for. The most common case is
that a process stores huge amounts of data. In this case
&lt;T&gt; is most often <strong>heap</strong>,
<strong>old_heap</strong>, <strong>heap_frag</strong>, or
<strong>binary</strong>. For more information on allocators, see
<a href="erts_alloc">erts_alloc</a>.</p> </dd><dt><em>&lt;A&gt;: Cannot reallocate &lt;N&gt; bytes of memory (of type "&lt;T&gt;")</em></dt><dd> <p>Same as above except that memory was reallocated
instead of allocated when the system ran out of memory.</p> </dd><dt><em>Unexpected op code &lt;N&gt;</em></dt><dd> <p>Error in compiled code, <strong>beam</strong> file damaged, or
error in the compiler.</p> </dd><dt><em>Module &lt;Name&gt; undefined | Function &lt;Name&gt; undefined | No function &lt;Name&gt;:&lt;Name&gt;/1 | No function &lt;Name&gt;:start/2</em></dt><dd> <p>The Kernel/STDLIB applications are
damaged or the start script is damaged.</p> </dd><dt><em>Driver_select called with too large file descriptor N</em></dt><dd> <p>The number of file descriptors for sockets
exceeds 1024 (Unix only). The limit on file descriptors in
some Unix flavors can be set to over 1024, but only 1024
sockets/pipes can be used simultaneously by Erlang (because of
limitations in the Unix <strong>select</strong> call). The number
of open regular files is not affected by this.</p> </dd><dt><em>Received SIGUSR1</em></dt><dd> <p>Sending the <strong>SIGUSR1</strong> signal to an Erlang machine (Unix only)
forces a crash dump. This slogan reflects that the Erlang machine
crash-dumped because of receiving that signal.</p> </dd><dt><em>Kernel pid terminated (&lt;Who&gt;) (&lt;Exit reason&gt;)</em></dt><dd> <p>The kernel supervisor has detected a failure, usually that the
<strong>application_controller</strong> has shut down
(<strong>Who</strong> = <strong>application_controller</strong>,
<strong>Why</strong> = <strong>shutdown</strong>).
The application controller
can have shut down for many reasons, the most usual
is that the node name of the distributed Erlang node is
already in use. A complete supervisor tree "crash" (that is,
the top supervisors have exited) gives about the same
result. This message comes from the Erlang code and not from
the virtual machine itself. It is always because of some
failure in an application, either within OTP or a
"user-written" one. Looking at the error log for your
application is probably the first step to take.</p> </dd><dt><em>Init terminating in do_boot ()</em></dt><dd> <p>The primitive Erlang boot sequence was terminated, most probably
because the boot script has errors or cannot be read. This is
usually a configuration error; the system can have been started
with a faulty <strong>-boot</strong> parameter or with a boot
script from the wrong OTP version.</p> </dd><dt><em>Could not start kernel pid (&lt;Who&gt;) ()</em></dt><dd> <p>One of the kernel processes could not start. This is probably
because of faulty arguments (like errors in a
<strong>-config</strong> argument)
or faulty configuration files. Check that all files are in
their correct location and that the configuration files (if
any) are not damaged. Usually messages are also
written to the controlling terminal and/or the error log
explaining what is wrong.</p> </dd></dl><p>Other errors than these can occur, as the
<strong>erlang:halt/1</strong> BIF can generate any message. If the
message is not generated by the BIF and does not occur in the
list above, it can be because of an error in the emulator. There
can however be unusual messages, not mentioned here, which
are still connected to an application failure. There is much
more information available, so a thorough reading of the
crash dump can reveal the crash reason. The size of processes,
the number of ETS tables, and the Erlang data on each process
stack can be useful to find the problem.</p><h2>Number of Atoms</h2><p>The number of atoms in the system at the time of the crash is
shown as <em>Atoms: &lt;number&gt;</em>. Some ten thousands atoms is
perfectly normal, but more can indicate that the BIF
<strong>erlang:list_to_atom/1</strong> is used to generate many
<em>different</em> atoms dynamically, which is never a good idea.</p><a name="scheduler"></a><h2>Scheduler Information</h2><p>Under the tag <em>=scheduler</em> is shown information about the current
state and statistics of the schedulers in the runtime system. On
operating systems that allow suspension of other threads, the
data within this section reflects what the runtime system looks like
when a crash occurs.</p><p>The following fields can exist for a process:</p><dl><dt><em>=scheduler:id</em></dt><dd> <p>Heading. States the scheduler identifier.</p> </dd><dt><em>Scheduler Sleep Info Flags</em></dt><dd> <p>If empty, the scheduler was doing some work.
If not empty, the scheduler is either in some state of sleep,
or suspended. This entry is only present in an SMP-enabled
emulator.</p> </dd><dt><em>Scheduler Sleep Info Aux Work</em></dt><dd> <p>If not empty, a scheduler internal auxiliary work is scheduled
to be done.</p> </dd><dt><em>Current Port</em></dt><dd> <p>The port identifier of the port that is currently
executed by the scheduler.</p> </dd><dt><em>Current Process</em></dt><dd> <p>The process identifier of the process that is currently
executed by the scheduler. If there is such a process, this entry is
followed by the <em>State</em>, <em>Internal State</em>,
<em>Program Counter</em>, and <em>CP</em> of that same process.
The entries are described in section
<a href="#processes">Process Information</a>.</p> <p>Notice that this is a snapshot of what the entries are exactly when
the crash dump is starting to be generated. Therefore they are most
likely different (and more telling) than the entries for the same
processes found in the <em>=proc</em> section. If there is no
currently running process, only the <em>Current Process</em> entry is
shown.</p> </dd><dt><em>Current Process Limited Stack Trace</em></dt><dd> <p>This entry is shown only if there is a current process. It is
similar to <a href="#proc_data">proc_data</a>, except that only the function frames
are shown (that is, the stack variables are omitted).
Also, only the top and bottom part of the stack are shown. If the
stack is small (&lt; 512 slots), the entire stack is shown. Otherwise
the entry <em>skipping ## slots</em> is shown, where <strong>##</strong>
is replaced by the number of slots that has been skipped.</p> </dd><dt><em>Run Queue</em></dt><dd> <p>Shows statistics about how many processes and ports
of different priorities are scheduled on this scheduler.</p> </dd><dt><em>** crashed **</em></dt><dd> <p>This entry is normally not shown. It signifies that getting the rest
of the information about this scheduler failed for some reason.</p> </dd></dl><a name="memory"></a><h2>Memory Information</h2><p>Under the tag <em>=memory</em> is shown information similar
to what can be obtainted on a living node with
<a href="../erts/erlang#memory/0">erts/erlang#memory/0</a>.</p><a name="internal_tables"></a><h2>Internal Table Information</h2><p>Under the tags <em>=hash_table:&lt;table_name&gt;</em> and
<em>=index_table:&lt;table_name&gt;</em> is shown internal
tables. These are mostly of interest for runtime system developers.</p><a name="allocated_areas"></a><h2>Allocated Areas</h2><p>Under the tag <em>=allocated_areas</em> is shown information
similar to what can be obtained on a living node with
<a href="../erts/erlang#system_info_allocated_areas">erts/erlang#system_info_allocated_areas</a>.</p><a name="allocator"></a><h2>Allocator</h2><p>Under the tag <em>=allocator:&lt;A&gt;</em> is shown
various information about allocator &lt;A&gt;. The information
is similar to what can be obtained on a living node with
<a href="../erts/erlang#system_info_allocator_tuple">erts/erlang#system_info_allocator_tuple</a>.
For more information, see also
<a href="erts_alloc">erts_alloc</a>.</p><a name="processes"></a><h2>Process Information</h2><p>The Erlang crashdump contains a listing of each living Erlang
process in the system. The following fields can exist for a process:</p><dl><dt><em>=proc:&lt;pid&gt;</em></dt><dd> <p>Heading. States the process identifier.</p> </dd><dt><em>State</em></dt><dd> <p>The state of the process. This can be one of the following:</p> <dl><dt><em>Scheduled</em></dt><dd>The process was scheduled to run but is currently not running ("in the run queue").</dd><dt><em>Waiting</em></dt><dd>The process was waiting for something (in <strong>receive</strong>).</dd><dt><em>Running</em></dt><dd>The process was currently running. If the BIF <strong>erlang:halt/1</strong> was called, this was the process calling it.</dd><dt><em>Exiting</em></dt><dd>The process was on its way to exit.</dd><dt><em>Garbing</em></dt><dd>This is bad luck, the process was garbage collecting when the crash dump was written. The rest of the information for this process is limited.</dd><dt><em>Suspended</em></dt><dd>The process is suspended, either by the BIF <strong>erlang:suspend_process/1</strong> or because it tries to write to a busy port.</dd></dl> </dd><dt><em>Registered name</em></dt><dd> <p>The registered name of the process, if any.</p> </dd><dt><em>Spawned as</em></dt><dd> <p>The entry point of the process, that is, what function was
referenced in the <strong>spawn</strong> or
<strong>spawn_link</strong> call that
started the process.</p> </dd><dt><em>Last scheduled in for | Current call</em></dt><dd> <p>The current function of the process. These fields do not
always exist.</p> </dd><dt><em>Spawned by</em></dt><dd> <p>The parent of the process, that is, the process that executed
<strong>spawn</strong> or <strong>spawn_link</strong>.</p> </dd><dt><em>Started</em></dt><dd> <p>The date and time when the process was started.</p> </dd><dt><em>Message queue length</em></dt><dd> <p>The number of messages in the process' message queue.</p> </dd><dt><em>Number of heap fragments</em></dt><dd> <p>The number of allocated heap fragments.</p> </dd><dt><em>Heap fragment data</em></dt><dd> <p>Size of fragmented heap data. This is data either created by
messages sent to the process or by the Erlang BIFs. This
amount depends on so many things that this field is utterly
uninteresting.</p> </dd><dt><em>Link list</em></dt><dd> <p>Process IDs of processes linked to this one. Can also contain
ports. If process monitoring is used, this field also tells in
which direction the monitoring is in effect. That is, a link
"to" a process tells you that the "current" process was
monitoring the other, and a link "from" a process tells you
that the other process was monitoring the current one.</p> </dd><dt><em>Reductions</em></dt><dd> <p>The number of reductions consumed by the process.</p> </dd><dt><em>Stack+heap</em></dt><dd> <p>The size of the stack and heap (they share memory segment).</p> </dd><dt><em>OldHeap</em></dt><dd> <p>The size of the "old heap". The Erlang virtual machine uses
generational garbage collection with two generations. There is
one heap for new data items and one for the data that has
survived two garbage collections. The assumption (which is
almost always correct) is that data surviving two garbage
collections can be "tenured" to a heap more seldom garbage
collected, as they will live for a long period. This is a
usual technique in virtual machines. The sum of the
heaps and stack together constitute most of the
allocated memory of the process.</p> </dd><dt><em>Heap unused, OldHeap unused</em></dt><dd> <p>The amount of unused memory on each heap. This information is
usually useless.</p> </dd><dt><em>Memory</em></dt><dd> <p>The total memory used by this process. This includes call stack,
heap, and internal structures. Same as
<a href="./erlang#process_info-2">erlang#process_info-2</a>.</p> </dd><dt><em>Program counter</em></dt><dd> <p>The current instruction pointer. This is only of interest for
runtime system developers. The function into which the program
counter points is the current function of the process.</p> </dd><dt><em>CP</em></dt><dd> <p>The continuation pointer, that is, the return address for the
current call. Usually useless for other than runtime system
developers. This can be followed by the function into which
the CP points, which is the function calling the current
function.</p> </dd><dt><em>Arity</em></dt><dd> <p>The number of live argument registers. The argument registers
if any are live will follow. These can contain the arguments
of the function if they are not yet moved to the stack.</p> </dd><dt><em>Internal State</em></dt><dd> <p>A more detailed internal representation of the state of
this process.</p> </dd></dl><p>See also section <a href="#proc_data">Process Data</a>.</p><a name="ports"></a><h2>Port Information</h2><p>This section lists the open ports, their owners, any linked
processes, and the name of their driver or external process.</p><a name="ets_tables"></a><h2>ETS Tables</h2><p>This section contains information about all the ETS tables in
the system. The following fields are of interest for each table:</p><dl><dt><em>=ets:&lt;owner&gt;</em></dt><dd> <p>Heading. States the table owner (a process identifier).</p> </dd><dt><em>Table</em></dt><dd> <p>The identifier for the table. If the table is a
<strong>named_table</strong>, this is the name.</p> </dd><dt><em>Name</em></dt><dd> <p>The table name, regardless of if it is a
<strong>named_table</strong> or not.</p> </dd><dt><em>Hash table, Buckets</em></dt><dd> <p>If the table is a hash table, that is, if it is not an
<strong>ordered_set</strong>.</p> </dd><dt><em>Hash table, Chain Length</em></dt><dd> <p>If the table is a hash table. Contains statistics about the
table, such as the maximum, minimum, and average chain length.
Having a maximum much larger than the average, and a standard
deviation much larger than the expected standard deviation is
a sign that the hashing of the terms
behaves badly for some reason.</p> </dd><dt><em>Ordered set (AVL tree), Elements</em></dt><dd> <p>If the table is an <strong>ordered_set</strong>. (The
number of elements is the same as the number of objects in the
table.)</p> </dd><dt><em>Fixed</em></dt><dd> <p>If the table is fixed using
<a href="../stdlib/ets#safe_fixtable/2">stdlib/ets#safe_fixtable/2</a> or some internal mechanism.</p> </dd><dt><em>Objects</em></dt><dd> <p>The number of objects in the table.</p> </dd><dt><em>Words</em></dt><dd> <p>The number of words (usually 4 bytes/word) allocated to data
in the table.</p> </dd><dt><em>Type</em></dt><dd> <p>The table type, that is, <strong>set</strong>, <strong>bag</strong>,
<strong>dublicate_bag</strong>, or <strong>ordered_set</strong>.</p> </dd><dt><em>Compressed</em></dt><dd> <p>If the table was compressed.</p> </dd><dt><em>Protection</em></dt><dd> <p>The protection of the table.</p> </dd><dt><em>Write Concurrency</em></dt><dd> <p>If <strong>write_concurrency</strong> was enabled for the table.</p> </dd><dt><em>Read Concurrency</em></dt><dd> <p>If <strong>read_concurrency</strong> was enabled for the table.</p> </dd></dl><a name="timers"></a><h2>Timers</h2><p>This section contains information about all the timers started
with the BIFs <strong>erlang:start_timer/3</strong> and
<strong>erlang:send_after/3</strong>. The following fields exist
for each timer:</p><dl><dt><em>=timer:&lt;owner&gt;</em></dt><dd> <p>Heading. States the timer owner (a process identifier),
that is, the process to receive the message when the timer
expires.</p> </dd><dt><em>Message</em></dt><dd> <p>The message to be sent.</p> </dd><dt><em>Time left</em></dt><dd> <p>Number of milliseconds left until the message would have been
sent.</p> </dd></dl><a name="distribution_info"></a><h2>Distribution Information</h2><p>If the Erlang node was alive, that is, set up for communicating
with other nodes, this section lists the connections that were
active. The following fields can exist:</p><dl><dt><em>=node:&lt;node_name&gt;</em></dt><dd> <p>The node name.</p> </dd><dt><em>no_distribution</em></dt><dd> <p>If the node was not distributed.</p> </dd><dt><em>=visible_node:&lt;channel&gt;</em></dt><dd> <p>Heading for a visible node, that is, an alive node with a
connection to the node that crashed. States the channel number
for the node.</p> </dd><dt><em>=hidden_node:&lt;channel&gt;</em></dt><dd> <p>Heading for a hidden node. A hidden node is the same as a
visible node, except that it is started with the <strong>"-hidden"</strong>
flag. States the channel number for the node.</p> </dd><dt><em>=not_connected:&lt;channel&gt;</em></dt><dd> <p>Heading for a node that was connected to the crashed
node earlier. References (that is, process or port identifiers)
to the not connected node existed at the time of the crash.
States the channel number for the node.</p> </dd><dt><em>Name</em></dt><dd> <p>The name of the remote node.</p> </dd><dt><em>Controller</em></dt><dd> <p>The port controlling communication with the remote node.</p> </dd><dt><em>Creation</em></dt><dd> <p>An integer (1-3) that together with the node name identifies
a specific instance of the node.</p> </dd><dt><em>Remote monitoring: &lt;local_proc&gt;  &lt;remote_proc&gt;</em> </dt><dd> <p>The local process was monitoring the remote process at the
time of the crash.</p> </dd><dt><em>Remotely monitored by: &lt;local_proc&gt; &lt;remote_proc&gt;</em></dt><dd> <p>The remote process was monitoring the local process at the
time of the crash.</p> </dd><dt><em>Remote link: &lt;local_proc&gt; &lt;remote_proc&gt;</em></dt><dd> <p>A link existed between the local process and the remote
process at the time of the crash.</p> </dd></dl><a name="loaded_modules"></a><h2>Loaded Module Information</h2><p>This section contains information about all loaded modules.</p><p>First, the memory use by the loaded code is summarized:</p><dl><dt><em>Current code</em></dt><dd> <p>Code that is the current latest version of the modules.</p> </dd><dt><em>Old code</em></dt><dd> <p>Code where there exists a newer version in the
system, but the old version is not yet purged.</p> </dd></dl><p>The memory use is in bytes.</p><p>Then, all loaded modules are listed. The following fields exist:</p><dl><dt><em>=mod:&lt;module_name&gt;</em></dt><dd> <p>Heading. States the module name.</p> </dd><dt><em>Current size</em></dt><dd> <p>Memory use for the loaded code, in bytes.</p> </dd><dt><em>Old size</em></dt><dd> <p>Memory use for the old code, if any.</p> </dd><dt><em>Current attributes</em></dt><dd> <p>Module attributes for the current code. This field is decoded
when looked at by the Crashdump Viewer tool.</p> </dd><dt><em>Old attributes</em></dt><dd> <p>Module attributes for the old code, if any. This field is
decoded when looked at by the Crashdump Viewer tool.</p> </dd><dt><em>Current compilation info</em></dt><dd> <p>Compilation information (options) for the current code. This
field is decoded when looked at by the Crashdump Viewer tool.</p> </dd><dt><em>Old compilation info</em></dt><dd> <p>Compilation information (options) for the old code, if
any. This field is decoded when looked at by the Crashdump
Viewer tool.</p> </dd></dl><a name="funs"></a><h2>Fun Information</h2><p>This section lists all funs. The following fields exist for each fun:</p><dl><dt><em>=fun</em></dt><dd> <p>Heading.</p> </dd><dt><em>Module</em></dt><dd> <p>The name of the module where the fun was defined.</p> </dd><dt><em>Uniq, Index</em></dt><dd> <p>Identifiers.</p> </dd><dt><em>Address</em></dt><dd> <p>The address of the fun's code.</p> </dd><dt><em>Native_address</em></dt><dd> <p>The address of the fun's code when HiPE is enabled.</p> </dd><dt><em>Refc</em></dt><dd> <p>The number of references to the fun.</p> </dd></dl><a name="proc_data"></a><h2>Process Data</h2><p>For each process there is at least one <em>=proc_stack</em>
and one <em>=proc_heap</em> tag, followed by the raw memory
information for the stack and heap of the process.</p><p>For each process there is also a <em>=proc_messages</em>
tag if the process message queue is non-empty, and a
<em>=proc_dictionary</em> tag if the process dictionary (the
<strong>put/2</strong> and <strong>get/1</strong> thing) is
non-empty.</p><p>The raw memory information can be decoded by the Crashdump
Viewer tool. You can then see the stack dump, the
message queue (if any), and the dictionary (if any).</p><p>The stack dump is a dump of the Erlang process stack. Most of
the live data (that is, variables currently in use) are placed on
the stack; thus this can be interesting. One has to
"guess" what is what, but as the information is symbolic,
thorough reading of this information can be useful. As an
example, we can find the state variable of the Erlang primitive
loader online <strong>(5)</strong> and <strong>(6)</strong>
in the following example:</p><pre><code class="">
(1)  3cac44   Return addr 0x13BF58 (&lt;terminate process normally&gt;)
(2)  y(0)     ["/view/siri_r10_dev/clearcase/otp/erts/lib/kernel/ebin",
(3)            "/view/siri_r10_dev/clearcase/otp/erts/lib/stdlib/ebin"]
(4)  y(1)     &lt;0.1.0&gt;
(5)  y(2)     {state,[],none,#Fun&lt;erl_prim_loader.6.7085890&gt;,undefined,#Fun&lt;erl_prim_loader.7.9000327&gt;,
(6)            #Fun&lt;erl_prim_loader.8.116480692&gt;,#Port&lt;0.2&gt;,infinity,#Fun&lt;erl_prim_loader.9.10708760&gt;}
(7)  y(3)     infinity    </code></pre><p>When interpreting the data for a process, it is helpful to know
that anonymous function objects (funs) are given the following:</p><ul><li>A name constructed from the name of the function in which they are created </li><li>A number (starting with 0) indicating the number of that fun within that function </li></ul><a name="atoms"></a><h2>Atoms</h2><p>This section presents all the atoms in the system. This is only
of interest if one suspects that dynamic generation of atoms can
be a problem, otherwise this section can be ignored.</p><p>Notice that the last created atom is shown first.</p><h2>Disclaimer</h2><p>The format of the crash dump evolves between OTP releases.
Some information described here may not apply to your
version. A description like this will never be complete; it is meant as
an explanation of the crash dump in general and as a help
when trying to find application errors, not as a complete
specification.</p></body></html>