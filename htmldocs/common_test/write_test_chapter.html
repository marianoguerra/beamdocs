<!doctype html>
<html><head><meta charset="utf-8"><link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.0/css/bootstrap.min.css"></head><body style="margin: 4em 10%"><h1>Writing Test Suites</h1><a name="intro"></a><h2>Support for Test Suite Authors</h2><p>The <a href="ct">ct</a> module provides the main 
interface for writing test cases. This includes for example, the following:</p><ul><li>Functions for printing and logging</li><li>Functions for reading configuration data</li><li>Function for terminating a test case with error reason</li><li>Function for adding comments to the HTML overview page</li></ul><p>For details about these functions, see module <a href="ct">ct</a>.</p><p>The <strong>Common Test</strong> application also includes other modules named 
<strong>ct_&lt;component&gt;</strong>, which
provide various support, mainly simplified use of communication
protocols such as RPC, SNMP, FTP, Telnet, and others.</p><h2>Test Suites</h2><p>A test suite is an ordinary Erlang module that contains test
cases. It is recommended that the module has a name on the form
<strong>*_SUITE.erl</strong>. Otherwise, the directory and auto compilation 
function in <strong>Common Test</strong> cannot locate it (at least not by default).
</p><p>It is also recommended that the <strong>ct.hrl</strong> header file is included
in all test suite modules.
</p><p>Each test suite module must export function 
<a href="./common_test#Module:all-0">common_test#Module:all-0</a>,
which returns the list of all test case groups and test cases 
to be executed in that module. 
</p><p>The callback functions to be implemented by the test suite are
all listed in module <a href="common_test">common_test </a>. They are also described in more detail later in this User's Guide.
</p><h2>Init and End per Suite</h2><p>Each test suite module can contain the optional configuration functions
<a href="./common_test#Module:init_per_suite-1">common_test#Module:init_per_suite-1</a>
and <a href="./common_test#Module:end_per_suite-1">common_test#Module:end_per_suite-1</a>. 
If the init function is defined, so must the end function be.
</p><p>If <strong>init_per_suite</strong> exists, it is called initially before the
test cases are executed. It typically contains initializations common
for all test cases in the suite, which are only to be performed once. 
<strong>init_per_suite</strong> is recommended for setting up and verifying state 
and environment on the System Under Test (SUT) or the <strong>Common Test</strong> 
host node, or both, so that the test cases in the suite executes correctly. 
The following are examples of initial configuration operations:
</p><ul><li>Opening a connection to the SUT</li><li>Initializing a database</li><li>Running an installation script</li></ul><p><strong>end_per_suite</strong> is called as the final stage of the test suite execution
(after the last test case has finished). The function is meant to be used 
for cleaning up after <strong>init_per_suite</strong>. 
</p><p><strong>init_per_suite</strong> and <strong>end_per_suite</strong> execute on dedicated
Erlang processes, just like the test cases do. The result of these functions
is however not included in the test run statistics of successful, failed, and
skipped cases.
</p><p>The argument to <strong>init_per_suite</strong> is <strong>Config</strong>, that is, the
same key-value list of runtime configuration data that each test case takes
as input argument. <strong>init_per_suite</strong> can modify this parameter with 
information that the test cases need. The possibly modified <strong>Config</strong>
list is the return value of the function.
</p><p>If <strong>init_per_suite</strong> fails, all test cases in the test
suite are skipped automatically (so called <em>auto skipped</em>), 
including <strong>end_per_suite</strong>.
</p><p>Notice that if <strong>init_per_suite</strong> and <strong>end_per_suite</strong> do not exist
in the suite, <strong>Common Test</strong> calls dummy functions (with the same names)
instead, so that output generated by hook functions can be saved to the log
files for these dummies. For details, see
<a href="./ct_hooks_chapter#manipulating">Common Test Hooks</a>.
</p><a name="per_testcase"></a><h2>Init and End per Test Case</h2><p>Each test suite module can contain the optional configuration functions
<a href="./common_test#Module:init_per_testcase-2">common_test#Module:init_per_testcase-2</a>
and <a href="./common_test#Module:end_per_testcase-2">common_test#Module:end_per_testcase-2</a>. 
If the init function is defined, so must the end function be.</p><p>If <strong>init_per_testcase</strong> exists, it is called before each
test case in the suite. It typically contains initialization that
must be done for each test case (analog to <strong>init_per_suite</strong> for the 
suite).</p><p><strong>end_per_testcase/2</strong> is called after each test case has
finished, enabling cleanup after <strong>init_per_testcase</strong>.</p><p>The first argument to these functions is the name of the test
case. This value can be used with pattern matching in function clauses
or conditional expressions to choose different initialization and cleanup
routines for different test cases, or perform the same routine for many,
or all, test cases.</p><p>The second argument is the <strong>Config</strong> key-value list of runtime
configuration data, which has the same value as the list returned by
<strong>init_per_suite</strong>. <strong>init_per_testcase/2</strong> can modify this
parameter or return it "as is". The return value of <strong>init_per_testcase/2</strong> 
is passed as parameter <strong>Config</strong> to the test case itself.</p><p>The return value of <strong>end_per_testcase/2</strong> is ignored by the
test server, with exception of the 
<a href="./dependencies_chapter#save_config">dependencies_chapter#save_config</a>
and <strong>fail</strong> tuple.</p><p><strong>end_per_testcase</strong> can check if the test case was successful. 
(which in turn can determine how cleanup is to be performed). 
This is done by reading the value tagged with <strong>tc_status</strong> from 
<strong>Config</strong>. The value is one of the following:
</p><ul><li> <p><strong>ok</strong></p> </li><li> <p><strong>{failed,Reason}</strong></p> <p>where <strong>Reason</strong> is <strong>timetrap_timeout</strong>, information from <strong>exit/1</strong>, 
or details of a runtime error</p></li><li> <p><strong>{skipped,Reason}</strong></p> <p>where <strong>Reason</strong> is a user-specific term</p></li></ul><p>Function <strong>end_per_testcase/2</strong> is even called if a
test case terminates because of a call to 
<a href="./ct#abort_current_testcase-1">ct#abort_current_testcase-1</a>,
or after a timetrap time-out. However, <strong>end_per_testcase</strong>
then executes on a different process than the test case
function. In this situation, <strong>end_per_testcase</strong> cannot
change the reason for test case termination by returning <strong>{fail,Reason}</strong>
or save data with <strong>{save_config,Data}</strong>.</p><p>The test case is skipped in the following two cases:
</p><ul><li>If <strong>init_per_testcase</strong> crashes (called <em>auto skipped</em>).</li><li>If <strong>init_per_testcase</strong> returns a tuple <strong>{skip,Reason}</strong>  (called <em>user skipped</em>).</li></ul><p>The test case can also be marked as failed without executing it
by returning a tuple <strong>{fail,Reason}</strong> from <strong>init_per_testcase</strong>.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>If <strong>init_per_testcase</strong> crashes, or returns <strong>{skip,Reason}</strong>
or <strong>{fail,Reason}</strong>, function <strong>end_per_testcase</strong> is not called.
</p></div><p>If it is determined during execution of <strong>end_per_testcase</strong> that
the status of a successful test case is to be changed to failed, 
<strong>end_per_testcase</strong> can return the tuple <strong>{fail,Reason}</strong>
(where <strong>Reason</strong> describes why the test case fails).</p><p>As <strong>init_per_testcase</strong> and <strong>end_per_testcase</strong> execute on the
same Erlang process as the test case, printouts from these
configuration functions are included in the test case log file.</p><a name="test_cases"></a><h2>Test Cases</h2><p>The smallest unit that the test server is concerned with is a
test case. Each test case can test many things, for
example, make several calls to the same interface function with
different parameters.
</p><p>The author can choose to put many or few tests into each test
case. Some things to keep in mind follows:
</p><ul><li><p>Many small test cases tend to result in extra, and possibly
duplicated code, as well as slow test execution because of
large overhead for initializations and cleanups. Avoid duplicated 
code, for example, by using common help functions. Otherwise,
the resulting suite becomes difficult to read and understand, and
expensive to maintain.
</p></li><li><p>Larger test cases make it harder to tell what went wrong if it
fails. Also, large portions of test code risk being skipped
when errors occur.</p> </li><li><p>Readability and maintainability suffer 
when test cases become too large and extensive. It is not certain 
that the resulting log files reflect very well the  number of tests 
performed.
</p></li></ul><p>The test case function takes one argument, <strong>Config</strong>, which
contains configuration information such as <strong>data_dir</strong> and
<strong>priv_dir</strong>. (For details about these, see section 
<a href="#data_priv_dir">Data and Private Directories</a>.
The value of <strong>Config</strong> at the time of the call, is the same 
as the return value from <strong>init_per_testcase</strong>, mentioned earlier.
</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>The test case function argument <strong>Config</strong> is not to be 
confused with the information that can be retrieved from the
configuration files (using <a href="./ct#get_config-1">ct#get_config-1</a>). The test case argument <strong>Config</strong>
is to be used for runtime configuration of the test suite and the 
test cases, while configuration files are to contain data 
related to the SUT. These two types of configuration data are handled 
differently.</p></div><p>As parameter <strong>Config</strong> is a list of key-value tuples, that is,
a data type called a property list, it can be handled by the
<a href="./proplists">stdlib/proplists</a> module.
A value can, for example, be searched for and returned with function 
<a href="../stdlib/proplists#get_value-2">stdlib/proplists#get_value-2</a>.
Also, or alternatively, the general <a href="./lists">stdlib/lists</a>
module contains useful functions. Normally, the only operations 
performed on <strong>Config</strong> is insert (adding a tuple to the head of the list) 
and lookup. <strong>Common Test</strong> provides a simple macro named <strong>?config</strong>, 
which returns a value of an item in <strong>Config</strong> given the key (exactly like 
<strong>proplists:get_value</strong>). Example: <strong>PrivDir = ?config(priv_dir, Config)</strong>.
</p><p>If the test case function crashes or exits purposely, it is considered 
<em>failed</em>. If it returns a value (no matter what value), it is 
considered successful. An exception to this rule is the return value 
<strong>{skip,Reason}</strong>. If this tuple is returned, the test case is considered 
skipped and is logged as such.</p><p>If the test case returns the tuple <strong>{comment,Comment}</strong>, the case
is considered successful and <strong>Comment</strong> is printed in the overview 
log file. This is equal to calling 
<a href="./ct#comment-1">ct#comment-1</a>.
</p><a name="info_function"></a><h2>Test Case Information Function</h2><p>For each test case function there can be an extra function
with the same name but without arguments. This is the test case
information function. It is expected to return a list of tagged 
tuples that specifies various properties regarding the test case.
</p><p>The following tags have special meaning:</p><dl><dt><strong>timetrap</strong></dt><dd> <p>
Sets the maximum time the test case is allowed to execute. If
this time is exceeded, the test case fails with
reason <strong>timetrap_timeout</strong>. Notice that <strong>init_per_testcase</strong> 
and <strong>end_per_testcase</strong> are included in the timetrap time.
For details, see section 
<a href="./write_test_chapter#timetraps">Timetrap Time-Outs</a>.
</p> </dd><dt><strong>userdata</strong></dt><dd> <p>
Specifies any data related to the test case. This
data can be retrieved at any time using the 
<a href="./ct#userdata-3">ct#userdata-3</a>
utility function.
</p> </dd><dt><strong>silent_connections</strong></dt><dd> <p>
For details, see section 
<a href="./run_test_chapter#silent_connections">Silent Connections</a>.
</p> </dd><dt><strong>require</strong></dt><dd> <p>
Specifies configuration variables required by the
test case. If the required configuration variables are not
found in any of the test system configuration files, the test case is
skipped.</p>  <p>
A required variable can also be given a default value to 
be used if the variable is not found in any configuration file. To specify 
a default value, add a tuple on the form 
<strong>{default_config,ConfigVariableName,Value}</strong> to the test case information list 
(the position in the list is irrelevant).
</p> <p><em>Examples:</em></p> <pre>
 testcase1() -&gt; 
     [{require, ftp},
      {default_config, ftp, [{ftp, "my_ftp_host"},
                             {username, "aladdin"},
                             {password, "sesame"}]}}].</pre> <pre>
 testcase2() -&gt; 
     [{require, unix_telnet, unix},
      {require, {unix, [telnet, username, password]}},
      {default_config, unix, [{telnet, "my_telnet_host"},
                              {username, "aladdin"},
                              {password, "sesame"}]}}].</pre> </dd></dl><p>For more information about <strong>require</strong>, see section
<a href="./config_file_chapter#require_config_data"> Requiring and Reading Configuration Data</a>
in section External Configuration Data and function 
<a href="./ct#require-1">ct#require-1</a>.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>Specifying a default value for a required variable can result
in a test case always getting executed. This might not be a desired behavior.</p></div><p>If <strong>timetrap</strong> or <strong>require</strong>, or both, is not set specifically for
a particular test case, default values specified by function
<a href="./common_test#Module:suite-0">common_test#Module:suite-0</a> 
are used.
</p><p>Tags other than the earlier mentioned are ignored by the test server.
</p><p>
An example of a test case information function follows:
</p><pre>
 reboot_node() -&gt;
     [
      {timetrap,{seconds,60}},
      {require,interfaces},
      {userdata,
          [{description,"System Upgrade: RpuAddition Normal RebootNode"},
           {fts,"http://someserver.ericsson.se/test_doc4711.pdf"}]}                  
     ].</pre><a name="suite"></a><h2>Test Suite Information Function</h2><p>Function <a href="./common_test#Module:suite-0">common_test#Module:suite-0</a> 
can, for example, be used in a test suite module to set a default 
<strong>timetrap</strong> value and to <strong>require</strong> external configuration data. 
If a test case, or a group information function also specifies any of the information tags, it
overrides the default values set by <strong>suite/0</strong>. For details, 
see 
<a href="#info_function">Test Case Information Function</a> and
<a href="#test_case_groups">Test Case Groups</a>.
</p><p>The following options can also be specified with the suite information list:</p><ul><li><strong>stylesheet</strong>,  see <a href="./run_test_chapter#html_stylesheet">HTML Style Sheets</a></li><li><strong>userdata</strong>,  see <a href="#info_function">Test Case Information Function</a></li><li><strong>silent_connections</strong>,  see <a href="./run_test_chapter#silent_connections">Silent Connections</a></li></ul><p>
An example of the suite information function follows:
</p><pre>
 suite() -&gt;
     [
      {timetrap,{minutes,10}},
      {require,global_names},
      {userdata,[{info,"This suite tests database transactions."}]},
      {silent_connections,[telnet]},
      {stylesheet,"db_testing.css"}
     ].</pre><a name="test_case_groups"></a><h2>Test Case Groups</h2><p>A test case group is a set of test cases sharing configuration 
functions and execution properties. Test case groups are defined by
function 
<a href="./common_test#Module:groups-0">common_test#Module:groups-0</a>
according to the following syntax:</p><pre>
 groups() -&gt; GroupDefs

 Types:

 GroupDefs = [GroupDef]
 GroupDef = {GroupName,Properties,GroupsAndTestCases}
 GroupName = atom()
 GroupsAndTestCases = [GroupDef | {group,GroupName} | TestCase |
                      {testcase,TestCase,TCRepeatProps}]
 TestCase = atom()
 TCRepeatProps = [{repeat,N} | {repeat_until_ok,N} | {repeat_until_fail,N}]</pre><p><strong>GroupName</strong> is the name of the group and must be unique within
the test suite module. Groups can be nested, by including a group definition 
within the <strong>GroupsAndTestCases</strong> list of another group. 
<strong>Properties</strong> is the list of execution 
properties for the group. The possible values are as follows:</p><pre>
 Properties = [parallel | sequence | Shuffle | {GroupRepeatType,N}]
 Shuffle = shuffle | {shuffle,Seed}
 Seed = {integer(),integer(),integer()}
 GroupRepeatType = repeat | repeat_until_all_ok | repeat_until_all_fail |
                   repeat_until_any_ok | repeat_until_any_fail
 N = integer() | forever</pre><p><em>Explanations:</em></p><dl><dt><strong>parallel</strong></dt><dd><p><strong>Common Test</strong> executes all test cases in the group in parallel.</p></dd><dt><strong>sequence</strong></dt><dd><p>The cases are executed in a sequence as described in section
<a href="./dependencies_chapter#sequences">Sequences</a> in section
Dependencies Between Test Cases and Suites.</p></dd><dt><strong>shuffle</strong></dt><dd><p>The cases in the group are executed in random order.</p></dd><dt><strong>repeat, repeat_until_*</strong></dt><dd><p>Orders <strong>Common Test</strong> to repeat execution of all the cases in the 
group a given number of times, or until any, or all, cases fail or succeed.</p></dd></dl><p><em>Example:</em></p><pre>
 groups() -&gt; [{group1, [parallel], [test1a,test1b]},
              {group2, [shuffle,sequence], [test2a,test2b,test2c]}].</pre><p>To specify in which order groups are to be executed (also with respect
to test cases that are not part of any group), add tuples on the form 
<strong>{group,GroupName}</strong> to the <strong>all/0</strong> list.</p><p><em>Example:</em></p><pre>
 all() -&gt; [testcase1, {group,group1}, {testcase,testcase2,[{repeat,10}]}, {group,group2}].</pre><p>Execution properties with a group tuple in 
<strong>all/0</strong>: <strong>{group,GroupName,Properties}</strong> can also be specified. 
These properties override those specified in the group definition (see
<strong>groups/0</strong> earlier). This way, the same set of tests can be run,
but with different properties, without having to make copies of the group
definition in question.</p><p>If a group contains subgroups, the execution properties for these can
also be specified in the group tuple:
<strong>{group,GroupName,Properties,SubGroups}</strong>
Where, <strong>SubGroups</strong> is a list of tuples, <strong>{GroupName,Properties}</strong> or
<strong>{GroupName,Properties,SubGroups}</strong> representing the subgroups.
Any subgroups defined in <strong>group/0</strong> for a group, that are not specified
in the <strong>SubGroups</strong> list, executes with their predefined
properties.</p><p><em>Example:</em></p><pre>
 groups() -&gt; {tests1, [], [{tests2, [], [t2a,t2b]},
                           {tests3, [], [t31,t3b]}]}.</pre><p>To execute group <strong>tests1</strong> twice with different properties for <strong>tests2</strong>
each time:</p><pre>
 all() -&gt;
    [{group, tests1, default, [{tests2, [parallel]}]},
     {group, tests1, default, [{tests2, [shuffle,{repeat,10}]}]}].</pre><p>This is equivalent to the following specification:</p><pre>
 all() -&gt;
    [{group, tests1, default, [{tests2, [parallel]},
                               {tests3, default}]},
     {group, tests1, default, [{tests2, [shuffle,{repeat,10}]},
                               {tests3, default}]}].</pre><p>Value <strong>default</strong> states that the predefined properties
are to be used.</p><p>The following example shows how to override properties in a scenario
with deeply nested groups:</p><pre>
 groups() -&gt;
    [{tests1, [], [{group, tests2}]},
     {tests2, [], [{group, tests3}]},
     {tests3, [{repeat,2}], [t3a,t3b,t3c]}].

 all() -&gt;
    [{group, tests1, default, 
      [{tests2, default,
        [{tests3, [parallel,{repeat,100}]}]}]}].</pre><p>The described syntax can also be used in test specifications
to change group properties at the time of execution,
without having to edit the test suite. For more information, see
section <a href="./run_test_chapter#test_specifications">Test Specifications</a> in section Running Tests and Analyzing Results.</p><p>As illustrated, properties can be combined. If, for example,
<strong>shuffle</strong>, <strong>repeat_until_any_fail</strong>, and <strong>sequence</strong>
are all specified, the test cases in the group are executed
repeatedly, and in random order, until a test case fails. Then
execution is immediately stopped and the remaining cases are skipped.</p><p>Before execution of a group begins, the configuration function
<a href="./common_test#Module:init_per_group-2">common_test#Module:init_per_group-2</a> 
is called. The list of tuples returned from this function is passed to the 
test cases in the usual manner by argument <strong>Config</strong>. 
<strong>init_per_group/2</strong> is meant to be used for initializations common 
for the test cases in the group. After execution of the group is finished, function
<a href="./common_test#Module:end_per_group-2">common_test#Module:end_per_group-2</a> 
is called. This function is meant to be used for cleaning up after 
<strong>init_per_group/2</strong>. If the init function is defined, so must the end function be.</p><p>Whenever a group is executed, if <strong>init_per_group</strong> and
<strong>end_per_group</strong> do not exist in the suite, <strong>Common Test</strong> calls
dummy functions (with the same names) instead. Output generated by
hook functions are saved to the log files for these dummies.
For more information, see section 
<a href="./ct_hooks_chapter#manipulating">Manipulating Tests</a>
in section Common Test Hooks.
</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p><strong>init_per_testcase/2</strong> and <strong>end_per_testcase/2</strong>
are always called for each individual test case, no matter if the case 
belongs to a group or not.</p></div><p>The properties for a group are always printed in the top of the HTML log 
for <strong>init_per_group/2</strong>. The total execution time for a group is
included at the bottom of the log for <strong>end_per_group/2</strong>.</p><p>Test case groups can be nested so sets of groups can be 
configured with the same <strong>init_per_group/2</strong> and <strong>end_per_group/2</strong>
functions. Nested groups can be defined by including a group definition,
or a group name reference, in the test case list of another group.</p><p><em>Example:</em></p><pre>
 groups() -&gt; [{group1, [shuffle], [test1a,
                                   {group2, [], [test2a,test2b]},
                                   test1b]},
              {group3, [], [{group,group4},
                            {group,group5}]},
              {group4, [parallel], [test4a,test4b]},
              {group5, [sequence], [test5a,test5b,test5c]}].</pre><p>In the previous example, if <strong>all/0</strong> returns group name references
in the order <strong>[{group,group1},{group,group3}]</strong>, the order of the 
configuration functions and test cases becomes the following (notice that
<strong>init_per_testcase/2</strong> and <strong>end_per_testcase/2:</strong> are also
always called, but not included in this example for simplification):</p><pre>
 init_per_group(group1, Config) -&gt; Config1  (*)
      test1a(Config1)
      init_per_group(group2, Config1) -&gt; Config2
           test2a(Config2), test2b(Config2)
      end_per_group(group2, Config2)
      test1b(Config1)
 end_per_group(group1, Config1) 
 init_per_group(group3, Config) -&gt; Config3
      init_per_group(group4, Config3) -&gt; Config4
           test4a(Config4), test4b(Config4)  (**)
      end_per_group(group4, Config4)
      init_per_group(group5, Config3) -&gt; Config5
           test5a(Config5), test5b(Config5), test5c(Config5)
      end_per_group(group5, Config5)
 end_per_group(group3, Config3)</pre><p>(*) The order of test case <strong>test1a</strong>, <strong>test1b</strong>, and <strong>group2</strong> is
undefined, as <strong>group1</strong> has a shuffle property.</p><p>(**) These cases are not executed in order, but in parallel.</p><p>Properties are not inherited from top-level groups to nested 
subgroups. For instance, in the previous example, the test cases in <strong>group2</strong> 
are not executed in random order (which is the property of <strong>group1</strong>).</p><h2>Parallel Property and Nested Groups</h2><p>If a group has a parallel property, its test cases are spawned
simultaneously and get executed in parallel. However, a test case is not 
allowed to execute in parallel with <strong>end_per_group/2</strong>, which means
that the time to execute a parallel group is equal to the
execution time of the slowest test case in the group. A negative side
effect of running test cases in parallel is that the HTML summary pages
are not updated with links to the individual test case logs until function 
<strong>end_per_group/2</strong> for the group has finished.</p><p>A group nested under a parallel group starts executing in parallel 
with previous (parallel) test cases (no matter what properties the nested 
group has). However, as test cases are never executed in parallel with 
<strong>init_per_group/2</strong> or <strong>end_per_group/2</strong> of the same group, it is 
only after a nested group has finished that remaining parallel cases 
in the previous group become spawned.</p><h2>Parallel Test Cases and I/O</h2><p>A parallel test case has a private I/O server as its group leader. 
(For a description of the group leader concept, see
<a href="./index">ERTS</a>).
The central I/O server process, which handles the output from 
regular test cases and configuration functions, does not respond to I/O messages
during execution of parallel groups. This is important to understand
to avoid certain traps, like the following:</p><p>If a process, <strong>P</strong>, is spawned during execution of, for example,
<strong>init_per_suite/1</strong>, it inherits the group leader of the
<strong>init_per_suite</strong> process. This group leader is the central I/O server
process mentioned earlier. If, at a later time, <em>during parallel test case execution</em>, some event triggers process <strong>P</strong> to call
<strong>io:format/1/2</strong>, that call never returns (as the group leader
is in a non-responsive state) and causes <strong>P</strong> to hang.
</p><h2>Repeated Groups</h2><a name="repeated_groups"></a><p>A test case group can be repeated a certain number of times
(specified by an integer) or indefinitely (specified by <strong>forever</strong>).
The repetition can also be stopped too early if any or all cases
fail or succeed, that is, if any of the properties <strong>repeat_until_any_fail</strong>,
<strong>repeat_until_any_ok</strong>, <strong>repeat_until_all_fail</strong>, or 
<strong>repeat_until_all_ok</strong> is used. If the basic <strong>repeat</strong>
property is used, status of test cases is irrelevant for the repeat 
operation.</p><p>The status of a subgroup can be returned (<strong>ok</strong> or
<strong>failed</strong>), to affect the execution of the group on the level above. 
This is accomplished by, in <strong>end_per_group/2</strong>, looking up the value
of <strong>tc_group_properties</strong> in the <strong>Config</strong> list and checking the
result of the test cases in the group. If status <strong>failed</strong> is to be
returned from the group as a result, <strong>end_per_group/2</strong> is to return
the value <strong>{return_group_result,failed}</strong>. The status of a subgroup
is taken into account by <strong>Common Test</strong> when evaluating if execution of a
group is to be repeated or not (unless the basic <strong>repeat</strong>
property is used).</p><p>The value of <strong>tc_group_properties</strong> is a list of status tuples, 
each with the key <strong>ok</strong>, <strong>skipped</strong>, and <strong>failed</strong>. The
value of a status tuple is a list with names of test cases 
that have been executed with the corresponding status as result.</p><p>The following is an example of how to return the status from a group:</p><pre>
 end_per_group(_Group, Config) -&gt;
     Status = ?config(tc_group_result, Config),
     case proplists:get_value(failed, Status) of
         [] -&gt;                                   % no failed cases 
             {return_group_result,ok};
         _Failed -&gt;                              % one or more failed
             {return_group_result,failed}
     end.</pre><p>It is also possible, in <strong>end_per_group/2</strong>, to check the status of
a subgroup (maybe to determine what status the current group is to
return). This is as simple as illustrated in the previous example, only the
group name is stored in a tuple <strong>{group_result,GroupName}</strong>,
which can be searched for in the status lists.</p><p><em>Example:</em></p><pre>
 end_per_group(group1, Config) -&gt;
     Status = ?config(tc_group_result, Config),
     Failed = proplists:get_value(failed, Status),
     case lists:member({group_result,group2}, Failed) of
           true -&gt;
               {return_group_result,failed};
           false -&gt;                                                    
               {return_group_result,ok}
     end; 
 ...</pre><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>When a test case group is repeated, the configuration 
functions <strong>init_per_group/2</strong> and <strong>end_per_group/2</strong> are 
also always called with each repetition.</p></div><h2>Shuffled Test Case Order</h2><p>The order in which test cases in a group are executed is under normal
circumstances the same as the order specified in the test case list 
in the group definition. With property <strong>shuffle</strong> set, however,
<strong>Common Test</strong> instead executes the test cases in random order.</p><p>You can provide a seed value (a tuple of three integers) with
the shuffle property <strong>{shuffle,Seed}</strong>. This way, the same shuffling
order can be created every time the group is executed. If no seed value
is specified, <strong>Common Test</strong> creates a "random" seed for the shuffling operation 
(using the return value of <strong>erlang:timestamp/0</strong>). The seed value is always
printed to the <strong>init_per_group/2</strong> log file so that it can be used to
recreate the same execution order in a subsequent test run.</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>If a shuffled test case group is repeated, the seed is not
reset between turns.</p></div><p>If a subgroup is specified in a group with a <strong>shuffle</strong> property,
the execution order of this subgroup in relation to the test cases 
(and other subgroups) in the group, is random. The order of the
test cases in the subgroup is however not random (unless the 
subgroup has a <strong>shuffle</strong> property).</p><a name="group_info"></a><h2>Group Information Function</h2><p>The test case group information function, <strong>group(GroupName)</strong>,
serves the same purpose as the suite- and test case information
functions previously described. However, the scope for
the group information function, is all test cases and subgroups in the
group in question (<strong>GroupName</strong>).</p><p><em>Example:</em></p><pre>
 group(connection_tests) -&gt;
    [{require,login_data},
     {timetrap,1000}].</pre><p>The group information properties override those set with the
suite information function, and can in turn be overridden by test
case information properties. For a list of valid information properties 
and more general information, see the
<a href="#info_function">Test Case Information Function</a>.
</p><h2>Information Functions for Init- and End-Configuration</h2><p>Information functions can also be used for functions <strong>init_per_suite</strong>,
<strong>end_per_suite</strong>, <strong>init_per_group</strong>, and <strong>end_per_group</strong>,
and they work the same way as with the
<a href="#info_function">Test Case Information Function</a>. 
This is useful, for example, for setting timetraps and requiring 
external configuration data relevant only for the configuration 
function in question (without affecting properties set for groups 
and test cases in the suite).</p><p>The information function <strong>init/end_per_suite()</strong> is called for
<strong>init/end_per_suite(Config)</strong>, and information function
<strong>init/end_per_group(GroupName)</strong> is called for
<strong>init/end_per_group(GroupName,Config)</strong>. However, information functions
cannot be used with <strong>init/end_per_testcase(TestCase, Config)</strong>,
as these configuration functions execute on the test case process
and use the same properties as the test case (that is, the properties
set by the test case information function, <strong>TestCase()</strong>). For a list 
of valid information properties and more general information, see the
<a href="#info_function">Test Case Information Function</a>.
</p><a name="data_priv_dir"></a><h2>Data and Private Directories</h2><p>In the data directory, <strong>data_dir</strong>, the test module has 
its own files needed for the testing. The name of <strong>data_dir</strong> 
is the the name of the test suite followed by <strong>"_data"</strong>. 
For example, <strong>"some_path/foo_SUITE.beam"</strong> has the data directory
<strong>"some_path/foo_SUITE_data/"</strong>. Use this directory for portability,
that is, to avoid hardcoding directory names in your suite. As the data
directory is stored in the same directory as your test suite, you can
rely on its existence at runtime, even if the path to your
test suite directory has changed between test suite implementation and
execution.
</p><p>
<strong>priv_dir</strong> is the private directory for the test cases.
This directory can be used whenever a test case (or configuration function)
needs to write something to file. The name of the private directory is
generated by <strong>Common Test</strong>, which also creates the directory.
</p><p>By default, <strong>Common Test</strong> creates one central private directory
per test run, shared by all test cases. This is not always suitable.
Especially if the same test cases are executed multiple times during
a test run (that is, if they belong to a test case group with property
<strong>repeat</strong>) and there is a risk that files in the private directory get
overwritten. Under these circumstances, <strong>Common Test</strong> can be 
configured to create one dedicated private directory per
test case and execution instead. This is accomplished with
the flag/option <strong>create_priv_dir</strong> (to be used with the
<a href="ct_run">ct_run</a> program, the 
<a href="./ct#run_test-1">ct#run_test-1</a> function, or
as test specification term). There are three possible values
for this option as follows:
</p><ul><li><strong>auto_per_run</strong></li><li><strong>auto_per_tc</strong></li><li><strong>manual_per_tc</strong></li></ul><p>
The first value indicates the default <strong>priv_dir</strong> behavior, that is,
one private directory created per test run. The two latter
values tell <strong>Common Test</strong> to generate a unique test directory name
per test case and execution. If the auto version is used, <em>all</em>
private directories are created automatically. This can become very 
inefficient for test runs with many test cases or repetitions, or both. 
Therefore, if the manual version is used instead, the test case must tell 
<strong>Common Test</strong> to create <strong>priv_dir</strong> when it needs it.
It does this by calling the function 
<a href="./ct#make_priv_dir-0">ct#make_priv_dir-0</a>.
</p><div class="alert alert-info"><h4 class="alert-heading">Note</h4><p>Do not depend on the current working directory for
reading and writing data files, as this is not portable. All 
scratch files are to be written in the <strong>priv_dir</strong> and all 
data files are to be located in <strong>data_dir</strong>. Also, 
the <strong>Common Test</strong> server sets the current working directory to 
the test case log directory at the start of every case.
</p></div><h2>Execution Environment</h2><p>Each test case is executed by a dedicated Erlang process. The
process is spawned when the test case starts, and terminated when
the test case is finished. The configuration functions 
<strong>init_per_testcase</strong> and <strong>end_per_testcase</strong> execute on the 
same process as the test case.
</p><p>The configuration functions <strong>init_per_suite</strong> and 
<strong>end_per_suite</strong> execute, like test cases, on dedicated Erlang
processes.
</p><a name="timetraps"></a><h2>Timetrap Time-Outs</h2><p>The default time limit for a test case is 30 minutes, unless a
<strong>timetrap</strong> is specified either by the suite-, group-,
or test case information function. The timetrap time-out value defined by
<strong>suite/0</strong> is the value that is used for each test case
in the suite (and for the configuration functions
<strong>init_per_suite/1</strong>, <strong>end_per_suite/1</strong>, <strong>init_per_group/2</strong>,
and <strong>end_per_group/2</strong>). A timetrap value defined by
<strong>group(GroupName)</strong> overrides one defined by <strong>suite()</strong>
and is used for each test case in group <strong>GroupName</strong>, and any
of its subgroups. If a timetrap value is defined by <strong>group/1</strong>
for a subgroup, it overrides that of its higher level groups. Timetrap
values set by individual test cases (by the test case information
function) override both group- and suite- level timetraps.</p><p>A timetrap can also be set or reset dynamically during the
execution of a test case, or configuration function. 
This is done by calling
<a href="./ct#timetrap-1">ct#timetrap-1</a>. 
This function cancels the current timetrap and starts a new one 
(that stays active until time-out, or end of the current function).</p><p>Timetrap values can be extended with a multiplier value specified at
startup with option <strong>multiply_timetraps</strong>. It is also possible
to let the test server decide to scale up timetrap time-out values
automatically. That is, if tools such as <strong>cover</strong> or <strong>trace</strong> 
are running during the test. This feature is disabled by default and 
can be enabled with start option <strong>scale_timetraps</strong>.</p><p>If a test case needs to suspend itself for a time that also gets
multipled by <strong>multiply_timetraps</strong> (and possibly also scaled up if
<strong>scale_timetraps</strong> is enabled), the function 
<a href="./ct#sleep-1">ct#sleep-1</a>
can be used (instead of, for example, <strong>timer:sleep/1</strong>).</p><p>A function (<strong>fun/0</strong> or <strong>{Mod,Func,Args}</strong> (MFA) tuple) can be 
specified as timetrap value in the suite-, group- and test case information 
function, and as argument to function 
<a href="./ct#timetrap-1">ct#timetrap-1</a>.</p><p><em>Examples:</em></p><p><strong>{timetrap,{my_test_utils,timetrap,[?MODULE,system_start]}}</strong></p><p><strong>ct:timetrap(fun() -&gt; my_timetrap(TestCaseName, Config) end)</strong></p><p>The user timetrap function can be used for two things as follows:</p><ul><li>To act as a timetrap. The time-out is triggered when the function returns.</li><li>To return a timetrap time value (other than a function).</li></ul><p>Before execution of the timetrap function (which is performed
on a parallel, dedicated timetrap process), <strong>Common Test</strong> cancels
any previously set timer for the test case or configuration function.    
When the timetrap function returns, the time-out is triggered, <em>unless</em>
the return value is a valid timetrap time, such as an integer,
or a <strong>{SecMinOrHourTag,Time}</strong> tuple (for details, see module
<a href="common_test">common_test</a>). If a time value 
is returned, a new timetrap is started to generate a time-out after 
the specified time.</p><p>The user timetrap function can return a time value after a delay.
The effective timetrap time is then the delay time <em>plus</em> the
returned time.</p><a name="logging"></a><h2>Logging - Categories and Verbosity Levels</h2><p><strong>Common Test</strong> provides the following three main functions for 
printing strings:</p><ul><li><strong>ct:log(Category, Importance, Format, FormatArgs, Opts)</strong></li><li><strong>ct:print(Category, Importance, Format, FormatArgs)</strong></li><li><strong>ct:pal(Category, Importance, Format, FormatArgs)</strong></li></ul><p>The <a href="./ct#log-1">ct#log-1</a> function 
prints a string to the test case log file. 
The <a href="./ct#print-1">ct#print-1</a> function 
prints the string to screen.
The <a href="./ct#pal-1">ct#pal-1</a> function 
prints the same string both to file and screen. The functions are described 
in module <a href="ct">ct</a>.
</p><p>The optional <strong>Category</strong> argument can be used to categorize the
log printout. Categories can be used for two things as follows:</p><ul><li>To compare the importance of the printout to a specific verbosity level.</li><li>To format the printout according to a user-specific HTML Style Sheet (CSS).</li></ul><p>Argument <strong>Importance</strong> specifies a level of importance
that, compared to a verbosity level (general and/or set per category),
determines if the printout is to be visible. <strong>Importance</strong>
is any integer in the range 0..99. Predefined constants
exist in the <strong>ct.hrl</strong> header file. The default importance level,
<strong>?STD_IMPORTANCE</strong> (used if argument <strong>Importance</strong> is not
provided), is 50. This is also the importance used for standard I/O,
for example, from printouts made with <strong>io:format/2</strong>, 
<strong>io:put_chars/1</strong>, and so on.</p><p><strong>Importance</strong> is compared to a verbosity level set by the
<strong>verbosity</strong> start flag/option. The level can be set per
category or generally, or both. If <strong>verbosity</strong> is not set by the user,
a level of 100 (<strong>?MAX_VERBOSITY</strong> = all printouts visible) is used as
default value. <strong>Common Test</strong> performs the following test:</p><pre>
Importance &gt;= (100-VerbosityLevel)</pre><p>The constant <strong>?STD_VERBOSITY</strong> has value 50 (see <strong>ct.hrl</strong>).
At this level, all standard I/O gets printed. If a lower verbosity level
is set, standard I/O printouts are ignored. Verbosity level 0 effectively
turns all logging off (except from printouts made by <strong>Common Test</strong>
itself).</p><p>The general verbosity level is not associated with any particular
category. This level sets the threshold for the standard I/O printouts,
uncategorized <strong>ct:log/print/pal</strong> printouts, and
printouts for categories with undefined verbosity level.</p><p><em>Examples:</em></p><p>Some printouts during test case execution:</p><pre>
 io:format("1. Standard IO, importance = ~w~n", [?STD_IMPORTANCE]),
 ct:log("2. Uncategorized, importance = ~w", [?STD_IMPORTANCE]),
 ct:log(info, "3. Categorized info, importance = ~w", [?STD_IMPORTANCE]),
 ct:log(info, ?LOW_IMPORTANCE, "4. Categorized info, importance = ~w", [?LOW_IMPORTANCE]),
 ct:log(error, ?HI_IMPORTANCE, "5. Categorized error, importance = ~w", [?HI_IMPORTANCE]),
 ct:log(error, ?MAX_IMPORTANCE, "6. Categorized error, importance = ~w", [?MAX_IMPORTANCE]),</pre><p>If starting the test with a general verbosity level of 50 (<strong>?STD_VERBOSITY</strong>):</p><pre>
 $ ct_run -verbosity 50</pre><p>the following is printed:</p><pre>
 1. Standard IO, importance = 50
 2. Uncategorized, importance = 50
 3. Categorized info, importance = 50
 5. Categorized error, importance = 75
 6. Categorized error, importance = 99</pre><p>If starting the test with:</p><pre>
 $ ct_run -verbosity 1 and info 75</pre><p>the following is printed:</p><pre>
 3. Categorized info, importance = 50
 4. Categorized info, importance = 25
 6. Categorized error, importance = 99</pre><p>Note that the category argument is not required in order to only specify the
importance of a printout. Example:</p><pre>
ct:pal(?LOW_IMPORTANCE, "Info report: ~p", [Info])</pre><p>Or perhaps in combination with constants:</p><pre>
-define(INFO, ?LOW_IMPORTANCE).
-define(ERROR, ?HI_IMPORTANCE).

ct:log(?INFO, "Info report: ~p", [Info])
ct:pal(?ERROR, "Error report: ~p", [Error])</pre><p>The functions <a href="./ct#set_verbosity-2">ct#set_verbosity-2</a>
and <a href="./ct#get_verbosity-1">ct#get_verbosity-1</a> may be used
to modify and read verbosity levels during test execution.</p><p>The arguments <strong>Format</strong> and <strong>FormatArgs</strong> in <strong>ct:log/print/pal</strong> are
always passed on to the STDLIB function <strong>io:format/3</strong> (For details,
see the <a href="./io">stdlib/io</a> manual page).</p><p><strong>ct:pal/4</strong> and <strong>ct:log/5</strong> add headers to strings being printed to the
log file. The strings are also wrapped in div tags with a CSS class
attribute, so that stylesheet formatting can be applied. To disable this feature for
a printout (i.e. to get a result similar to using <strong>io:format/2</strong>),
call <strong>ct:log/5</strong> with the <strong>no_css</strong> option.</p><p>How categories can be mapped to CSS tags is documented in section
<a href="./run_test_chapter#html_stylesheet">HTML Style Sheets</a>
in section Running Tests and Analyzing Results.</p><p>Common Test will escape special HTML characters (&lt;, &gt; and &amp;) in printouts
to the log file made with <strong>ct:pal/4</strong> and <strong>io:format/2</strong>. In order to print
strings with HTML tags to the log, use the <strong>ct:log/3,4,5</strong> function. The character
escaping feature is per default disabled for <strong>ct:log/3,4,5</strong> but can be enabled with
the <strong>esc_chars</strong> option in the <strong>Opts</strong> list, see <a href="./ct#log-5">ct#log-5</a>.</p><p>If the character escaping feature needs to be disabled (typically for backwards
compatibility reasons), use the <strong>ct_run</strong> start flag <strong>-no_esc_chars</strong>, or the
<strong>ct:run_test/1</strong> start option <strong>{esc_chars,Bool}</strong> (this start option is also
supported in test specifications).</p><p>For more information about log files, see section
<a href="./run_test_chapter#log_files">Log Files</a> 
in section Running Tests and Analyzing Results.</p><h2>Illegal Dependencies</h2><p>Even though it is highly efficient to write test suites with
the <strong>Common Test</strong> framework, mistakes can be made,
mainly because of illegal dependencies. Some of the 
more frequent mistakes from our own experience with running the 
Erlang/OTP test suites follows:</p><ul><li><p>Depending on current directory, and writing there:</p> <p>This is a common error in test suites. It is assumed that
the current directory is the same as the author used as
current directory when the test case was developed. Many test
cases even try to write scratch files to this directory. Instead
<strong>data_dir</strong> and <strong>priv_dir</strong> are to be used to locate 
data and for writing scratch files.
</p> </li><li><p>Depending on execution order:</p> <p>During development of test suites, make no assumptions on the 
execution order of the test cases or suites. For example, a test 
case must not assume that a server it depends on is already 
started by a previous test case. Reasons for this follows:
</p> <ul><li>The user/operator can specify the order at will, and maybe a different execution order is sometimes more relevant or  efficient.</li><li>If the user specifies a whole directory of test suites  for the test, the execution order of the suites depends on  how the files are listed by the operating system, which varies  between systems.</li><li>If a user wants to run only a subset of a test suite,  there is no way one test case could successfully depend on  another.</li></ul> </li><li><p>Depending on Unix:</p> <p>Running Unix commands through <strong>os:cmd</strong> are likely 
not to work on non-Unix platforms.
</p> </li><li><p>Nested test cases:</p> <p>Starting a test case from another not only tests the same
thing twice, but also makes it harder to follow what is being 
tested. Also, if the called test case fails for some
reason, so do the caller. This way, one error gives cause to
several error reports, which is to be avoided.
</p> <p>Functionality common for many test case functions can be 
implemented in common help functions. If these functions are 
useful for test cases across suites, put the help functions 
into common help modules.
</p> </li><li><p>Failure to crash or exit when things go wrong:</p> <p>Making requests without checking that the return value
indicates success can be OK if the test case fails
later, but it is never acceptable just to print an error
message (into the log file) and return successfully. Such test 
cases do harm, as they create a false sense of security when 
overviewing the test results.
</p> </li><li><p>Messing up for subsequent test cases:</p> <p>Test cases are to restore as much of the execution
environment as possible, so that subsequent test cases
do not crash because of their execution order. 
The function 
<a href="./common_test#Module:end_per_testcase-2">common_test#Module:end_per_testcase-2</a> 
is suitable for this.
</p> </li></ul></body></html>